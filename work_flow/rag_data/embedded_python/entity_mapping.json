{
  "entity_to_id": {
    "\"hog\"则结果不太准确，但在 CPU 上运行更快；\"cnn\"是更准确的深度学习模型，需要 GPU 加速": 0,
    "-D WITH_QT=OFF 禁用了 Qt5 支持": 1,
    "/etc/apt/sources.list": 2,
    "/usr/bin/python": 3,
    "128核 NVIDIA Maxwell 架构的 GPU": 4,
    "330欧姆电阻": 5,
    "3个Conv2D和2个MaxPooling2D层": 6,
    "40 针 GPIO 扩展接口": 7,
    "40个 GPIO 引脚，其中26个引脚可以用作数字输入或输出，另外14个引脚用于其他功能": 8,
    "40个GPIO引脚，包括电源接口、I2C接口、SPI接口、UART串口接口、PWM接口等": 9,
    "40个引脚，其中26个可用作数字输入或输出，14个用于其他功能": 10,
    "4GB 的内存并不能完全使用，其中有一部分（1GB 左右）是和显存共享的": 11,
    "5V 电源输入": 12,
    "64位四核ARM Cortex-A57 CPU、128核NVIDIA Maxwell架构GPU、4GB内存": 13,
    "64位四核的 ARM Cortex-A57": 14,
    "800万像素、感光芯片为索尼IMX219": 15,
    "AC8265": 16,
    "ARM Cortex-A72": 17,
    "AUTOTUNE": 18,
    "Adam": 19,
    "Android": 20,
    "Android、iOS和Linux等移动/嵌入式平台": 21,
    "B02版本有两路": 22,
    "BCM编号": 23,
    "BCM编号方式": 24,
    "BCM编号模式": 25,
    "CSI 摄像头": 26,
    "CSI 相机接口": 27,
    "CSI端口": 28,
    "CUDA": 29,
    "Conv2D": 30,
    "Conv2D, MaxPooling2D, Flatten, Dense层": 31,
    "Conv2D层、MaxPooling2D层、Flatten层和Dense层": 32,
    "Dense": 33,
    "Display Port 接口": 34,
    "Etcher": 35,
    "Face Recognition": 36,
    "GND": 37,
    "GPIO": 38,
    "GPIO.cleanup()方法": 39,
    "GPIO.setup()方法": 40,
    "GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP)": 41,
    "GPIO21": 42,
    "GPIO口": 43,
    "GPIO库": 44,
    "GPIO库、I2C库、SPI库、UART库和软件PWM库等": 45,
    "GPIO引脚": 46,
    "GPIO引脚编号模式的一种": 47,
    "GPIO端口": 48,
    "GStreamer": 49,
    "Google Edge TPU Coral Dev Board": 50,
    "HDMI 接口": 51,
    "HIGH电平": 52,
    "Haar特征的cascade分类器": 53,
    "Hello AI World": 54,
    "I2C库": 55,
    "I2C接口(SCL、SDA)": 56,
    "ImageDataGenerator": 57,
    "Intel Neural Compute Stick 2": 58,
    "JetBot": 59,
    "JetPack": 60,
    "JetPack SDK": 61,
    "Jetson": 62,
    "Jetson Nano": 63,
    "Jetson Nano CPU": 64,
    "Jetson Nano 开发板": 65,
    "Jetson 项目社区": 66,
    "Jupyter Notebook": 67,
    "Jupyter Notebook、文本编辑器、终端以及各种个性化组件": 68,
    "Jupyter Notebook的全面升级版本": 69,
    "Jupyter lab": 70,
    "JupyterLab": 71,
    "LED": 72,
    "LED灯": 73,
    "LED的控制引脚": 74,
    "LOW电平": 75,
    "Linux 开发环境": 76,
    "Linux平台": 77,
    "Linux系统": 78,
    "MIPI": 79,
    "MIPI CSI-2 摄像头接口": 80,
    "MIPI的相机串行接口（CSI）端口": 81,
    "MIPI联盟发起的为移动应用处理器制定的开放标准": 82,
    "MaxPooling2D": 83,
    "Micro USB 接口，用来传输数据或使用电源供电": 84,
    "NVIDIA Jetson Nano": 85,
    "NVIDIA Jetson Nano 开发板": 86,
    "NVIDIA Jetson 开发者专区": 87,
    "NVIDIA Jetson 论坛": 88,
    "OpenCV": 89,
    "OpenCV 安装": 90,
    "OpenCV 编译": 91,
    "PWM接口": 92,
    "Python": 93,
    "Python 2.7": 94,
    "Python 官方集成的包管理工具": 95,
    "Python 模块": 96,
    "Python 源码包": 97,
    "Python 生态系统": 98,
    "Python 的包管理工具": 99,
    "Python 相关程序模块": 100,
    "Python开发环境": 101,
    "Python程序": 102,
    "RPI.GPIO 库": 103,
    "RandomFlip": 104,
    "RandomRotation": 105,
    "Raspberry Camera V2": 106,
    "Raspberry Pi": 107,
    "Raspberry Pi 4": 108,
    "Raspbian 软件仓库镜像": 109,
    "SPI库": 110,
    "SPI接口（MISO、MOSI、CLK、CS片选信号SPICE0_N）": 111,
    "SavedModel": 112,
    "SparseCategoricalCrossentropy": 113,
    "TFLite": 114,
    "TFLite 算子库": 115,
    "TFLite模型": 116,
    "TFLite模型转换器": 117,
    "TFLite解释器": 118,
    "TensorBoard": 119,
    "TensorFlow": 120,
    "TensorFlow GPU 版本": 121,
    "TensorFlow Lite": 122,
    "TensorFlow Lite API": 123,
    "TensorFlow Lite 推理": 124,
    "TensorFlow Lite 解释器": 125,
    "TensorFlow Lite 解释器(Interpreter)、TensorFlow Lite 转换器(Converter)、算子库(Op kernels)、硬件加速代理(Hardware accelerator delegate)": 126,
    "TensorFlow Lite 转换器": 127,
    "TensorFlow Lite工作流程": 128,
    "TensorFlow Lite支持库": 129,
    "TensorFlow Lite的简称，用于在移动和嵌入式设备上运行机器学习模型": 130,
    "TensorFlow, PyTorch, Caffe / Caffe2, Keras, MXNet 等深度学习框架": 131,
    "UART串口接口（TXD、RXD）": 132,
    "UART库": 133,
    "USB": 134,
    "VNC Viewer": 135,
    "VNC 服务器": 136,
    "Wiring Pi": 137,
    "Wiring Pi编号": 138,
    "Wiring Pi编号模式": 139,
    "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']": 140,
    "add_event_detect()函数": 141,
    "allocate_tensors": 142,
    "batch_size": 143,
    "class_names": 144,
    "compare_faces": 145,
    "converter": 146,
    "daisy, dandelion, roses, sunflowers, tulips": 147,
    "dlib 这一 C++ 图形库": 148,
    "face_cascade.detectMultiScale": 149,
    "face_distance": 150,
    "face_encodings": 151,
    "face_locations": 152,
    "face_recognition": 153,
    "filters参数、kernel_size参数、padding参数和activation参数": 154,
    "flow_from_directory": 155,
    "get_input_details": 156,
    "get_output_details": 157,
    "get_tensor()": 158,
    "gpio readall命令": 159,
    "iOS": 160,
    "input_details": 161,
    "interpreter": 162,
    "interpreter.get_tensor()": 163,
    "invoke": 164,
    "jtop 命令": 165,
    "jupyter": 166,
    "jupyter_notebook_config.py": 167,
    "lambda x, y: (normalization_layer(x), y)": 168,
    "layers.Flatten()": 169,
    "load_image_file": 170,
    "make install": 171,
    "make 命令": 172,
    "microSD 卡": 173,
    "microSD 卡作为启动设备和主存储器": 174,
    "microSD 卡插槽，可以进行系统镜像烧写": 175,
    "minNeighbors": 176,
    "model": 177,
    "model.compile": 178,
    "model.fit": 179,
    "model.tflite": 180,
    "nano": 181,
    "normalization_layer": 182,
    "number_of_times_to_upsample": 183,
    "output_data": 184,
    "output_details": 185,
    "pip": 186,
    "pip install": 187,
    "pip3": 188,
    "pip3 是 pip 的 Python 3 版本": 189,
    "print(\"button pressed!\")": 190,
    "python": 191,
    "saved_model_dir": 192,
    "set_tensor": 193,
    "target_size": 194,
    "tensor()": 195,
    "tensorboard_callback": 196,
    "tf.keras.losses.SparseCategoricalCrossentropy": 197,
    "tf.keras.optimizers.Adam()": 198,
    "tf.lite.TFLiteConverter.from_saved_model": 199,
    "tf.nn.softmax": 200,
    "tf.nn.softmax()": 201,
    "tf.saved_model.save": 202,
    "tflite_model": 203,
    "time.sleep()方法": 204,
    "train_ds": 205,
    "units参数和activation参数": 206,
    "val_ds": 207,
    "val_ds.map": 208,
    "vi": 209,
    "wait_for_edge()函数": 210,
    "x—images, y—labels": 211,
    "一个使用数据流图进行数值计算的开源软件库": 212,
    "一个函数": 213,
    "一个功能强大的交互式Python开发环境": 214,
    "一个多媒体框架，用于后端处理任务": 215,
    "一个强大、简单、易上手的人脸识别开源项目": 216,
    "一个用于构建卷积神经网络的层，输出三维张量": 217,
    "一个用于构建卷积神经网络的池化层，输出三维张量": 218,
    "一个软链接": 219,
    "一款功能强大的边缘计算设备": 220,
    "一款设计用于教育的廉价开发板，目前已进化到第4代": 221,
    "一种功能强大的编程语言": 222,
    "一种应对快速变化需求的软件开发模式": 223,
    "一种有效的物品检测方法": 224,
    "一种有效的物品检测方法，通过许多正负样例中训练得到cascade方程": 225,
    "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型": 226,
    "一组工具，帮助开发者在移动设备、嵌入式设备和IoT设备上运行TensorFlow模型": 227,
    "一组数字引脚，可用于将树莓派连接到其他电子设备": 228,
    "上拉电阻": 229,
    "下载 OpenCV": 230,
    "下载、安装并启动 Etcher": 231,
    "下载时选择特定版本": 232,
    "下载解压": 233,
    "不支持 CUDA": 234,
    "不支持 CUDA 且版本是固定搭配的": 235,
    "不需要原始模型构建代码就可以运行": 236,
    "与NVIDIA Jetson Nano相比，树莓派更廉价且周边设备多": 237,
    "与树莓派结合可以将项目与现实世界轻松的联系起来": 238,
    "两种模式：5W（低功耗模式；可以使用 USB 口供电）和10W（必须使用 Power Jack 外接5V 电源供电）": 239,
    "为LED提供电源": 240,
    "人脸检测": 241,
    "人脸检测、检测面部特征点、给脸部编码、从编码中找出人的名字": 242,
    "人脸识别": 243,
    "人脸识别与商品识别": 244,
    "从 Python 官网下载": 245,
    "以 ldconfig 结束": 246,
    "以依赖项的安装开始": 247,
    "优化数据加载性能": 248,
    "优化模型参数": 249,
    "体积小，采用核心板可拆的设计，核心板的大小只有70 x 45 mm，可以很方便的集成在各种嵌入式应用中": 250,
    "作为LED灯的限流电阻": 251,
    "作为优化器用于模型训练": 252,
    "作为损失函数用于多分类任务": 253,
    "使用 Etcher 将镜像写入 microSD 卡": 254,
    "使用3×3的卷积核，并在输出上使用Relu激活函数": 255,
    "使用C++和Python提供的TensorFlow Lite API运行推断": 256,
    "使用C、C++开发并且可以被其他语言包使用": 257,
    "使用GIT工具下载代码，然后编译安装": 258,
    "使用GPIO.setmod()方法指定引脚编号系统": 259,
    "使用GPIO.setup()方法设置引脚为输入或输出": 260,
    "使用Java或C++ API执行TensorFlow Lite推理": 261,
    "使用Swift和Objective-C编写的原生iOS库执行TensorFlow Lite推理": 262,
    "使用系统设置应用程序来启用自动登录": 263,
    "使输出宽度和高度收缩": 264,
    "保存完整的TensorFlow程序，包括权重值和计算": 265,
    "保存训练好的模型": 266,
    "修改软件源的配置文件/etc/apt/sources.list": 267,
    "修改运行服务监听的 IP 地址，端口，用于 notebooks 内核的目录，是否打开浏览器": 268,
    "全连接层": 269,
    "全连接层，等同于Full Connected层": 270,
    "关闭LED灯": 271,
    "准备好所有编译指令后开始编译": 272,
    "创建 GStreamer 管道，将管道绑定 opencv 的视频流，逐帧提取和显示": 273,
    "创建解释器、分配张量等功能": 274,
    "利用计算机对图像进行处理、分析和理解，以识别各种不同模式的目标和对象的技术": 275,
    "功耗要求苛刻": 276,
    "功耗非常低": 277,
    "功能强大，交互式、富文本，还有丰富的插件、主题修改、多语言支持": 278,
    "加载和运行TFLite模型": 279,
    "加载面孔照片": 280,
    "千兆以太网端口": 281,
    "单击“Flash!”（闪存！）": 282,
    "单击“Select drive”（选择驱动器），并选择正确设备": 283,
    "单击“Select image”（选择镜像），然后选择先前下载的压缩镜像文件": 284,
    "卷积层": 285,
    "卷积层与全连接层": 286,
    "卷积层输入": 287,
    "卷积神经网络模型": 288,
    "受限于GPU内存的大小": 289,
    "只有 Ethernet 有线网络，不包括无线网卡": 290,
    "只有在本地登录到 Jetson 之后才可用": 291,
    "可以从同一网络上的另一台计算机控制 Jetson Nano 开发板": 292,
    "可以使用树莓派摄像头，IMX219模组800万像素": 293,
    "可以创建了一个安装脚本": 294,
    "可以利用手机上的加速器，比如 GPU 或者 DSP 等": 295,
    "可以配置为输入或输出": 296,
    "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型": 297,
    "商品流通过程中，特别是无人货架、智能零售柜等无人零售领域": 298,
    "商品识别": 299,
    "四引脚按键": 300,
    "图像识别": 301,
    "图像识别、对象检测和定位、姿势估计、语义分割、视频增强和智能分析等": 302,
    "图像识别技术": 303,
    "图片形状是(224,224,3)": 304,
    "在 Jetson Nano 开发板上手动编译与安装": 305,
    "在18号引脚处设置上拉电阻": 306,
    "在C语言中使用": 307,
    "在Python程序中控制硬件": 308,
    "在图像中检测面部": 309,
    "在图像分类、物体检测、分割和语音处理等应用程序中并行运行多个神经网络": 310,
    "在官网下载安装包后安装": 311,
    "在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型": 312,
    "在树莓派浏览器中输入 http://": 313,
    "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化": 314,
    "在设备端运行TFLite模型，调用不同的硬件加速器": 315,
    "在靠近物或数据源头的一侧，采用网络、计算、存储、应用核心能力为一体的开放平台，就近提供最近端服务": 316,
    "基于现有模型构建Interpreter": 317,
    "增加一个事件的检测函数": 318,
    "处理媒体应用程序，如格式修改、显示驱动程序协调和数据处理": 319,
    "多种编程语言": 320,
    "大量易于学习的教程": 321,
    "大量的由活跃开发者社区打造的开源项目": 322,
    "如果提示 Python 模块无法编译，需要按照错误提示排查原因，通常是没安装相应的依赖包": 323,
    "如果通过 USB3 连接，Etcher 写入和验证镜像需要10 分钟": 324,
    "存储模型推理结果": 325,
    "安全检查、身份核验与移动支付": 326,
    "安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB": 327,
    "安装 OpenCV 项目": 328,
    "安装 vino，可以用 dpkg -l |grep vino 查看是否已经安装": 329,
    "安装依赖项": 330,
    "安装依赖项，安装 TensorFlow 所需的系统包，安装和升级 pip3，安装 Python 包依赖项，确认 CUDA 已经被正常安装，安装 TensorFlow，验证安装": 331,
    "安装其它版本的 Python": 332,
    "完成分类任务": 333,
    "官方已经停止维护": 334,
    "官方推荐的无线网卡": 335,
    "定位图像中的人脸位置": 336,
    "实现 headless 远程桌面访问 Jetson Nano": 337,
    "实现刷脸登录的功能": 338,
    "对x进行归一化处理": 339,
    "对图像数据进行归一化处理": 340,
    "对训练图像随机变换以增加数据多样性": 341,
    "对训练图像随机旋转以增加数据多样性": 342,
    "将 Python 相关程序模块拷贝到/opt/python": 343,
    "将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能": 344,
    "将LED灯通过限流电阻连接到GPIO21，负极连接到GND形成回路": 345,
    "将SavedModel转换为TFLite兼容格式": 346,
    "将TensorFlow模型转换为TFLite文件格式(FlatBuffers格式)": 347,
    "将三维张量展开到一维": 348,
    "将三维张量展开到一维以便传入Dense层": 349,
    "将人脸编码列表与候选编码进行比较，以查看它们是否匹配": 350,
    "将已写入系统映像的 microSD 卡插入 Jetson Nano 模块底部的插槽中": 351,
    "将彩色图像转换为灰度图像，检测图像中是否包含人脸，在边界周围绘制矩形": 352,
    "将所有图像加载到一个模型需要的特定的大小": 353,
    "将模型加载到内存中": 354,
    "将模型转换为TFLite格式": 355,
    "将给定人脸编码列表与已知的人脸编码进行比较，并得到每个比较人脸的欧氏距离": 356,
    "将输入数据转换成模型接收的形式或排布，如resize原始图像到模型输入大小": 357,
    "将需要大约两个半小时": 358,
    "嵌入式开发平台": 359,
    "已经训练好的分类器，其中包括面部，眼睛，微笑等": 360,
    "常开触点": 361,
    "常闭触点": 362,
    "应用于树莓派的GPIO控制库函数": 363,
    "应用深度学习算法的一种实践应用": 364,
    "应用程序在边缘侧发起，产生更快的网络服务响应，满足行业在实时业务、应用智能、安全与隐私保护等方面的基本需求": 365,
    "廉价且周边设备多，互联网上有丰富的接口设备和项目案例资料": 366,
    "延迟一秒钟": 367,
    "开机前先安装CSI摄像头，系统才能识别": 368,
    "张量形状是(image_height, image_width, color_channels)": 369,
    "强调自组织的跨功能团队协作、进化开发、提前交付与持续改进": 370,
    "当压力撤销时电路恢复": 371,
    "当压力施压时电路接通": 372,
    "快速的启动并运行一组深度学习推理演示，体验 Jetson 的强大功能": 373,
    "手动下载安装需要的 Package 后用 pip 安装": 374,
    "打开终端窗口，执行python来测试是否安装了Python开发环境，并查看当前的Python版本": 375,
    "执行TensorFlow Lite模型推理": 376,
    "执行推理": 377,
    "执行推理以识别输入图像": 378,
    "执行模型推理": 379,
    "把 microSD 卡插到读卡器上之后插到电脑，使用 SD Memory Card Formatter 格式化 microSD 卡": 380,
    "控制GPIO引脚": 381,
    "控制GPIO管脚": 382,
    "控制GPIO管脚，可以在Shell脚本中使用": 383,
    "控制外部硬件设备": 384,
    "提供电路回路的地线连接": 385,
    "提问或分享项目": 386,
    "插入 microSD 卡": 387,
    "搭建电路原型": 388,
    "摄像头预捕获的图像宽度、高度，窗口显示的图像宽度、高度，捕获帧率，是否旋转图像": 389,
    "支持1080p30, 720p60以及640 × 480p90视频录像": 390,
    "支持Raspberry Pi、Arducam等常见的相机模块": 391,
    "支持设备端机器学习推断，延迟较低，并且二进制文件很小": 392,
    "支持预装驱动程序的RPi相机，可以很容易地用作即插即用外围设备": 393,
    "敏捷开发": 394,
    "数值计算": 395,
    "数据转换": 396,
    "整个安装需要两个小时才能完成": 397,
    "易于使用，易于阅读和编写": 398,
    "易于设置和使用，并且与许多流行的配件兼容": 399,
    "普通GPIO口": 400,
    "更新系统需要 root 权限": 401,
    "最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口": 402,
    "有两种方式可以与 Jetson Nano 开发板进行交互，一个是连接显示器、键盘和鼠标，二是通过 SSH 或 VNC 服务从另一台计算机远程访问": 403,
    "有两种编号模式：BCM编号模式和物理引脚Broad编号模式": 404,
    "杜邦线公对母": 405,
    "构建小型移动机器人、人脸签到打卡、口罩识别、智能门锁、智能音箱等复杂 AI 系统": 406,
    "构成检测目标的相邻矩形的最小个数": 407,
    "查看开发板系统信息": 408,
    "查看树莓派的GPIO引脚信息": 409,
    "树莓派": 410,
    "树莓派接口": 411,
    "树莓派的GPIO端口": 412,
    "树莓派系统": 413,
    "树莓派通用输入/输出接口（GPIO）": 414,
    "检测面部、眼睛、微笑等": 415,
    "模型推理": 416,
    "模型训练": 417,
    "涉及许多内容": 418,
    "添加--no-cache-dir 参数": 419,
    "清华源": 420,
    "清理GPIO引脚的设置": 421,
    "演示使用计算机视觉相关的模型，包括实时摄像机的使用，使用带有 JetPack SDK 和 NVIDIA TensorRT 的 Jetson 开发工具包上的预训练模型进行实时图像分类和对象检测": 422,
    "激活、设置为输出状态、写入1以点亮LED": 423,
    "灵活的架构可以将模型部署到桌面、服务器或移动设备中的 CPU 或 GPU 上": 424,
    "点亮LED灯": 425,
    "版本变化后API函数会改变": 426,
    "物理引脚Broad编号": 427,
    "物联网与人工智能项目开发": 428,
    "生成一个批次的图片，以生成器的形式给模型训练": 429,
    "用于在Jetson Nano开发板上识别花卉图片": 430,
    "用于控制LED灯的亮暗的按键": 431,
    "用于电路中的发光元件": 432,
    "用于训练模型": 433,
    "用于连接显示设备的接口": 434,
    "用于验证模型": 435,
    "由 jupyter 软件生成": 436,
    "由常开触点、常闭触点组合而成": 437,
    "电信号从低电平到高电平，或从高电平到低电平状态的改变": 438,
    "电源接口（5V）": 439,
    "电阻": 440,
    "目前有130个左右，它与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化": 441,
    "直接在Objective-C代码中使用C API执行TensorFlow Lite推理": 442,
    "直接更新树莓派系统": 443,
    "直流桶式插座": 444,
    "移动和嵌入式设备": 445,
    "第一个卷积层": 446,
    "第一次请连接显示器，键盘和鼠标，然后连接的 Micro-USB 电源，开发板将自动开机并启动": 447,
    "第二、三卷积层": 448,
    "简化图像预处理和模型输出处理": 449,
    "编译 OpenCV": 450,
    "编译模型、设置损失函数、设置优化器、设置评估指标": 451,
    "编辑工具": 452,
    "能够在图像分类、物体检测等应用程序中并行运行多个神经网络，运行功率仅为5瓦": 453,
    "花卉数据集": 454,
    "花卉识别模型": 455,
    "获取一些非常有意思的项目": 456,
    "获取分类结果的概率": 457,
    "获取张量的指针": 458,
    "获取张量的数据": 459,
    "获取更多的 Jetson 平台信息": 460,
    "获取模型输入张量信息": 461,
    "获取模型输出张量信息": 462,
    "观测开关去抖效果": 463,
    "解释器、转换器、算子库和硬件加速代理": 464,
    "计算分类损失": 465,
    "计算分类概率": 466,
    "计算已知人脸和未知人脸特征向量的距离": 467,
    "计算机视觉应用，如物体检测、人脸识别、图像分割等": 468,
    "计算能力不高，勉强可以使用一些小规模、并且优化过的网络进行推理，训练的话还是不够用的": 469,
    "计算预测结果的概率分布": 470,
    "训练时从数据集中的不同类中随机选出的图像数量": 471,
    "训练模型并记录训练和验证准确性/损失": 472,
    "训练模型并验证": 473,
    "记录训练日志用于可视化": 474,
    "记录训练过程数据": 475,
    "设备端机器学习推断，延迟较低，二进制文件很小": 476,
    "设置 VNC 密码 thepassword 修改为你的密码": 477,
    "设置GPIO引脚模式": 478,
    "设置上拉电阻": 479,
    "设置对图像进行多少次上采样以查找人脸": 480,
    "设置访问密码": 481,
    "设置输入张量值": 482,
    "识别图像里的空间模式，例如线条和物体局部": 483,
    "读取传感器数据，控制 LED 等外部设备": 484,
    "读取传感器数据，控制LED等外部设备": 485,
    "读取输出张量值": 486,
    "资源有限，训练网络时可能出现内存溢出错误": 487,
    "资源限制严重": 488,
    "跟换源": 489,
    "软件PWM库": 490,
    "软件源的配置文件": 491,
    "输入 IP 地址后点击 OK，双击对应的 VNC 用户输入密码，最后进入到 VNC 界面": 492,
    "输出三维张量，形状为(height, width, channels)": 493,
    "输出控制信号": 494,
    "输出模式": 495,
    "输出电压约为3.3V": 496,
    "输出的通道数量取决于声明层时的filters参数": 497,
    "输出通道数为32": 498,
    "输出通道数为64": 499,
    "边做边学的理想工具": 500,
    "边缘": 501,
    "边缘计算": 502,
    "运行功率仅为 5 瓦": 503,
    "运行各种深度学习模型": 504,
    "运行配置后需要检查输出结果": 505,
    "返回图像中每张人脸的 128 维人脸编码": 506,
    "返回张量数据的副本": 507,
    "还可以使用 C++ 编写自己的易于理解的识别程序": 508,
    "连接 DP 屏幕": 509,
    "连接摄像头": 510,
    "连接电路元件": 511,
    "选择模型、转换模型、部署到设备、优化模型": 512,
    "逐步加载单个数据集的图像": 513,
    "通用输入/输出接口，一组数字引脚，可用于将树莓派连接到其他电子设备": 514,
    "通过GPIO控制展示基础硬件控制能力": 515,
    "通过pip安装，网络环境差时可考虑更换源": 516,
    "通过下载源代码来安装": 517,
    "通过几个交互式教程展示如何利用 AI 的力量来教 JetBot 跟随物体、避免碰撞等": 518,
    "通过文件读写操作控制外设": 519,
    "通过许多正负样例中训练得到cascade方程，然后将其应用于其他图片": 520,
    "通过软件编程进行控制，例如使用 Python 或其他编程语言编写程序": 521,
    "郁金香(tulips)、玫瑰(roses)、浦公英(dandelion)、向日葵(sunflowers)、雏菊(daisy)": 522,
    "部署TensorFlow Lite模型": 523,
    "部署到嵌入式设备": 524,
    "配置 Jupyter lab": 525,
    "配置 VNC 服务": 526,
    "配置优化器、损失函数和评估指标": 527,
    "采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能": 528,
    "重启树莓派后尝试启动": 529,
    "错误的连接和编程可能会导致设备损坏或故障": 530,
    "镜像写入 microSD 卡": 531,
    "阻塞函数，会阻塞程序执行，直到检测到一个边沿": 532,
    "降低卷积层对位置的敏感": 533,
    "限制电流以保护LED和GPIO引脚": 534,
    "限流电阻": 535,
    "集Jupyter Notebook、文本编辑器、终端以及各种个性化组件于一体的全能IDE": 536,
    "需要 5V⎓2A 的高品质电源供电": 537,
    "需要使用 Gstreamer 读取视频流": 538,
    "需要小心谨慎，建议在使用之前仔细阅读相关文档，并确保采取适当的安全措施": 539,
    "需要设置 OpenCV 的内容、位置和方式": 540,
    "静态图片分辨率为3280 × 2464": 541,
    "面包板": 542,
    "面向有兴趣学习 AI 和构建有趣应用程序的创客、学生和爱好者": 543,
    "首先到英伟达官方下载官方镜像，也可以去开源社区下载配置好的镜像": 544,
    "首先需要查询 ip 地址": 545,
    "默认为3个": 546
  },
  "id_to_entity": {
    "0": "\"hog\"则结果不太准确，但在 CPU 上运行更快；\"cnn\"是更准确的深度学习模型，需要 GPU 加速",
    "1": "-D WITH_QT=OFF 禁用了 Qt5 支持",
    "2": "/etc/apt/sources.list",
    "3": "/usr/bin/python",
    "4": "128核 NVIDIA Maxwell 架构的 GPU",
    "5": "330欧姆电阻",
    "6": "3个Conv2D和2个MaxPooling2D层",
    "7": "40 针 GPIO 扩展接口",
    "8": "40个 GPIO 引脚，其中26个引脚可以用作数字输入或输出，另外14个引脚用于其他功能",
    "9": "40个GPIO引脚，包括电源接口、I2C接口、SPI接口、UART串口接口、PWM接口等",
    "10": "40个引脚，其中26个可用作数字输入或输出，14个用于其他功能",
    "11": "4GB 的内存并不能完全使用，其中有一部分（1GB 左右）是和显存共享的",
    "12": "5V 电源输入",
    "13": "64位四核ARM Cortex-A57 CPU、128核NVIDIA Maxwell架构GPU、4GB内存",
    "14": "64位四核的 ARM Cortex-A57",
    "15": "800万像素、感光芯片为索尼IMX219",
    "16": "AC8265",
    "17": "ARM Cortex-A72",
    "18": "AUTOTUNE",
    "19": "Adam",
    "20": "Android",
    "21": "Android、iOS和Linux等移动/嵌入式平台",
    "22": "B02版本有两路",
    "23": "BCM编号",
    "24": "BCM编号方式",
    "25": "BCM编号模式",
    "26": "CSI 摄像头",
    "27": "CSI 相机接口",
    "28": "CSI端口",
    "29": "CUDA",
    "30": "Conv2D",
    "31": "Conv2D, MaxPooling2D, Flatten, Dense层",
    "32": "Conv2D层、MaxPooling2D层、Flatten层和Dense层",
    "33": "Dense",
    "34": "Display Port 接口",
    "35": "Etcher",
    "36": "Face Recognition",
    "37": "GND",
    "38": "GPIO",
    "39": "GPIO.cleanup()方法",
    "40": "GPIO.setup()方法",
    "41": "GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP)",
    "42": "GPIO21",
    "43": "GPIO口",
    "44": "GPIO库",
    "45": "GPIO库、I2C库、SPI库、UART库和软件PWM库等",
    "46": "GPIO引脚",
    "47": "GPIO引脚编号模式的一种",
    "48": "GPIO端口",
    "49": "GStreamer",
    "50": "Google Edge TPU Coral Dev Board",
    "51": "HDMI 接口",
    "52": "HIGH电平",
    "53": "Haar特征的cascade分类器",
    "54": "Hello AI World",
    "55": "I2C库",
    "56": "I2C接口(SCL、SDA)",
    "57": "ImageDataGenerator",
    "58": "Intel Neural Compute Stick 2",
    "59": "JetBot",
    "60": "JetPack",
    "61": "JetPack SDK",
    "62": "Jetson",
    "63": "Jetson Nano",
    "64": "Jetson Nano CPU",
    "65": "Jetson Nano 开发板",
    "66": "Jetson 项目社区",
    "67": "Jupyter Notebook",
    "68": "Jupyter Notebook、文本编辑器、终端以及各种个性化组件",
    "69": "Jupyter Notebook的全面升级版本",
    "70": "Jupyter lab",
    "71": "JupyterLab",
    "72": "LED",
    "73": "LED灯",
    "74": "LED的控制引脚",
    "75": "LOW电平",
    "76": "Linux 开发环境",
    "77": "Linux平台",
    "78": "Linux系统",
    "79": "MIPI",
    "80": "MIPI CSI-2 摄像头接口",
    "81": "MIPI的相机串行接口（CSI）端口",
    "82": "MIPI联盟发起的为移动应用处理器制定的开放标准",
    "83": "MaxPooling2D",
    "84": "Micro USB 接口，用来传输数据或使用电源供电",
    "85": "NVIDIA Jetson Nano",
    "86": "NVIDIA Jetson Nano 开发板",
    "87": "NVIDIA Jetson 开发者专区",
    "88": "NVIDIA Jetson 论坛",
    "89": "OpenCV",
    "90": "OpenCV 安装",
    "91": "OpenCV 编译",
    "92": "PWM接口",
    "93": "Python",
    "94": "Python 2.7",
    "95": "Python 官方集成的包管理工具",
    "96": "Python 模块",
    "97": "Python 源码包",
    "98": "Python 生态系统",
    "99": "Python 的包管理工具",
    "100": "Python 相关程序模块",
    "101": "Python开发环境",
    "102": "Python程序",
    "103": "RPI.GPIO 库",
    "104": "RandomFlip",
    "105": "RandomRotation",
    "106": "Raspberry Camera V2",
    "107": "Raspberry Pi",
    "108": "Raspberry Pi 4",
    "109": "Raspbian 软件仓库镜像",
    "110": "SPI库",
    "111": "SPI接口（MISO、MOSI、CLK、CS片选信号SPICE0_N）",
    "112": "SavedModel",
    "113": "SparseCategoricalCrossentropy",
    "114": "TFLite",
    "115": "TFLite 算子库",
    "116": "TFLite模型",
    "117": "TFLite模型转换器",
    "118": "TFLite解释器",
    "119": "TensorBoard",
    "120": "TensorFlow",
    "121": "TensorFlow GPU 版本",
    "122": "TensorFlow Lite",
    "123": "TensorFlow Lite API",
    "124": "TensorFlow Lite 推理",
    "125": "TensorFlow Lite 解释器",
    "126": "TensorFlow Lite 解释器(Interpreter)、TensorFlow Lite 转换器(Converter)、算子库(Op kernels)、硬件加速代理(Hardware accelerator delegate)",
    "127": "TensorFlow Lite 转换器",
    "128": "TensorFlow Lite工作流程",
    "129": "TensorFlow Lite支持库",
    "130": "TensorFlow Lite的简称，用于在移动和嵌入式设备上运行机器学习模型",
    "131": "TensorFlow, PyTorch, Caffe / Caffe2, Keras, MXNet 等深度学习框架",
    "132": "UART串口接口（TXD、RXD）",
    "133": "UART库",
    "134": "USB",
    "135": "VNC Viewer",
    "136": "VNC 服务器",
    "137": "Wiring Pi",
    "138": "Wiring Pi编号",
    "139": "Wiring Pi编号模式",
    "140": "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']",
    "141": "add_event_detect()函数",
    "142": "allocate_tensors",
    "143": "batch_size",
    "144": "class_names",
    "145": "compare_faces",
    "146": "converter",
    "147": "daisy, dandelion, roses, sunflowers, tulips",
    "148": "dlib 这一 C++ 图形库",
    "149": "face_cascade.detectMultiScale",
    "150": "face_distance",
    "151": "face_encodings",
    "152": "face_locations",
    "153": "face_recognition",
    "154": "filters参数、kernel_size参数、padding参数和activation参数",
    "155": "flow_from_directory",
    "156": "get_input_details",
    "157": "get_output_details",
    "158": "get_tensor()",
    "159": "gpio readall命令",
    "160": "iOS",
    "161": "input_details",
    "162": "interpreter",
    "163": "interpreter.get_tensor()",
    "164": "invoke",
    "165": "jtop 命令",
    "166": "jupyter",
    "167": "jupyter_notebook_config.py",
    "168": "lambda x, y: (normalization_layer(x), y)",
    "169": "layers.Flatten()",
    "170": "load_image_file",
    "171": "make install",
    "172": "make 命令",
    "173": "microSD 卡",
    "174": "microSD 卡作为启动设备和主存储器",
    "175": "microSD 卡插槽，可以进行系统镜像烧写",
    "176": "minNeighbors",
    "177": "model",
    "178": "model.compile",
    "179": "model.fit",
    "180": "model.tflite",
    "181": "nano",
    "182": "normalization_layer",
    "183": "number_of_times_to_upsample",
    "184": "output_data",
    "185": "output_details",
    "186": "pip",
    "187": "pip install",
    "188": "pip3",
    "189": "pip3 是 pip 的 Python 3 版本",
    "190": "print(\"button pressed!\")",
    "191": "python",
    "192": "saved_model_dir",
    "193": "set_tensor",
    "194": "target_size",
    "195": "tensor()",
    "196": "tensorboard_callback",
    "197": "tf.keras.losses.SparseCategoricalCrossentropy",
    "198": "tf.keras.optimizers.Adam()",
    "199": "tf.lite.TFLiteConverter.from_saved_model",
    "200": "tf.nn.softmax",
    "201": "tf.nn.softmax()",
    "202": "tf.saved_model.save",
    "203": "tflite_model",
    "204": "time.sleep()方法",
    "205": "train_ds",
    "206": "units参数和activation参数",
    "207": "val_ds",
    "208": "val_ds.map",
    "209": "vi",
    "210": "wait_for_edge()函数",
    "211": "x—images, y—labels",
    "212": "一个使用数据流图进行数值计算的开源软件库",
    "213": "一个函数",
    "214": "一个功能强大的交互式Python开发环境",
    "215": "一个多媒体框架，用于后端处理任务",
    "216": "一个强大、简单、易上手的人脸识别开源项目",
    "217": "一个用于构建卷积神经网络的层，输出三维张量",
    "218": "一个用于构建卷积神经网络的池化层，输出三维张量",
    "219": "一个软链接",
    "220": "一款功能强大的边缘计算设备",
    "221": "一款设计用于教育的廉价开发板，目前已进化到第4代",
    "222": "一种功能强大的编程语言",
    "223": "一种应对快速变化需求的软件开发模式",
    "224": "一种有效的物品检测方法",
    "225": "一种有效的物品检测方法，通过许多正负样例中训练得到cascade方程",
    "226": "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型",
    "227": "一组工具，帮助开发者在移动设备、嵌入式设备和IoT设备上运行TensorFlow模型",
    "228": "一组数字引脚，可用于将树莓派连接到其他电子设备",
    "229": "上拉电阻",
    "230": "下载 OpenCV",
    "231": "下载、安装并启动 Etcher",
    "232": "下载时选择特定版本",
    "233": "下载解压",
    "234": "不支持 CUDA",
    "235": "不支持 CUDA 且版本是固定搭配的",
    "236": "不需要原始模型构建代码就可以运行",
    "237": "与NVIDIA Jetson Nano相比，树莓派更廉价且周边设备多",
    "238": "与树莓派结合可以将项目与现实世界轻松的联系起来",
    "239": "两种模式：5W（低功耗模式；可以使用 USB 口供电）和10W（必须使用 Power Jack 外接5V 电源供电）",
    "240": "为LED提供电源",
    "241": "人脸检测",
    "242": "人脸检测、检测面部特征点、给脸部编码、从编码中找出人的名字",
    "243": "人脸识别",
    "244": "人脸识别与商品识别",
    "245": "从 Python 官网下载",
    "246": "以 ldconfig 结束",
    "247": "以依赖项的安装开始",
    "248": "优化数据加载性能",
    "249": "优化模型参数",
    "250": "体积小，采用核心板可拆的设计，核心板的大小只有70 x 45 mm，可以很方便的集成在各种嵌入式应用中",
    "251": "作为LED灯的限流电阻",
    "252": "作为优化器用于模型训练",
    "253": "作为损失函数用于多分类任务",
    "254": "使用 Etcher 将镜像写入 microSD 卡",
    "255": "使用3×3的卷积核，并在输出上使用Relu激活函数",
    "256": "使用C++和Python提供的TensorFlow Lite API运行推断",
    "257": "使用C、C++开发并且可以被其他语言包使用",
    "258": "使用GIT工具下载代码，然后编译安装",
    "259": "使用GPIO.setmod()方法指定引脚编号系统",
    "260": "使用GPIO.setup()方法设置引脚为输入或输出",
    "261": "使用Java或C++ API执行TensorFlow Lite推理",
    "262": "使用Swift和Objective-C编写的原生iOS库执行TensorFlow Lite推理",
    "263": "使用系统设置应用程序来启用自动登录",
    "264": "使输出宽度和高度收缩",
    "265": "保存完整的TensorFlow程序，包括权重值和计算",
    "266": "保存训练好的模型",
    "267": "修改软件源的配置文件/etc/apt/sources.list",
    "268": "修改运行服务监听的 IP 地址，端口，用于 notebooks 内核的目录，是否打开浏览器",
    "269": "全连接层",
    "270": "全连接层，等同于Full Connected层",
    "271": "关闭LED灯",
    "272": "准备好所有编译指令后开始编译",
    "273": "创建 GStreamer 管道，将管道绑定 opencv 的视频流，逐帧提取和显示",
    "274": "创建解释器、分配张量等功能",
    "275": "利用计算机对图像进行处理、分析和理解，以识别各种不同模式的目标和对象的技术",
    "276": "功耗要求苛刻",
    "277": "功耗非常低",
    "278": "功能强大，交互式、富文本，还有丰富的插件、主题修改、多语言支持",
    "279": "加载和运行TFLite模型",
    "280": "加载面孔照片",
    "281": "千兆以太网端口",
    "282": "单击“Flash!”（闪存！）",
    "283": "单击“Select drive”（选择驱动器），并选择正确设备",
    "284": "单击“Select image”（选择镜像），然后选择先前下载的压缩镜像文件",
    "285": "卷积层",
    "286": "卷积层与全连接层",
    "287": "卷积层输入",
    "288": "卷积神经网络模型",
    "289": "受限于GPU内存的大小",
    "290": "只有 Ethernet 有线网络，不包括无线网卡",
    "291": "只有在本地登录到 Jetson 之后才可用",
    "292": "可以从同一网络上的另一台计算机控制 Jetson Nano 开发板",
    "293": "可以使用树莓派摄像头，IMX219模组800万像素",
    "294": "可以创建了一个安装脚本",
    "295": "可以利用手机上的加速器，比如 GPU 或者 DSP 等",
    "296": "可以配置为输入或输出",
    "297": "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型",
    "298": "商品流通过程中，特别是无人货架、智能零售柜等无人零售领域",
    "299": "商品识别",
    "300": "四引脚按键",
    "301": "图像识别",
    "302": "图像识别、对象检测和定位、姿势估计、语义分割、视频增强和智能分析等",
    "303": "图像识别技术",
    "304": "图片形状是(224,224,3)",
    "305": "在 Jetson Nano 开发板上手动编译与安装",
    "306": "在18号引脚处设置上拉电阻",
    "307": "在C语言中使用",
    "308": "在Python程序中控制硬件",
    "309": "在图像中检测面部",
    "310": "在图像分类、物体检测、分割和语音处理等应用程序中并行运行多个神经网络",
    "311": "在官网下载安装包后安装",
    "312": "在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型",
    "313": "在树莓派浏览器中输入 http://",
    "314": "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化",
    "315": "在设备端运行TFLite模型，调用不同的硬件加速器",
    "316": "在靠近物或数据源头的一侧，采用网络、计算、存储、应用核心能力为一体的开放平台，就近提供最近端服务",
    "317": "基于现有模型构建Interpreter",
    "318": "增加一个事件的检测函数",
    "319": "处理媒体应用程序，如格式修改、显示驱动程序协调和数据处理",
    "320": "多种编程语言",
    "321": "大量易于学习的教程",
    "322": "大量的由活跃开发者社区打造的开源项目",
    "323": "如果提示 Python 模块无法编译，需要按照错误提示排查原因，通常是没安装相应的依赖包",
    "324": "如果通过 USB3 连接，Etcher 写入和验证镜像需要10 分钟",
    "325": "存储模型推理结果",
    "326": "安全检查、身份核验与移动支付",
    "327": "安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB",
    "328": "安装 OpenCV 项目",
    "329": "安装 vino，可以用 dpkg -l |grep vino 查看是否已经安装",
    "330": "安装依赖项",
    "331": "安装依赖项，安装 TensorFlow 所需的系统包，安装和升级 pip3，安装 Python 包依赖项，确认 CUDA 已经被正常安装，安装 TensorFlow，验证安装",
    "332": "安装其它版本的 Python",
    "333": "完成分类任务",
    "334": "官方已经停止维护",
    "335": "官方推荐的无线网卡",
    "336": "定位图像中的人脸位置",
    "337": "实现 headless 远程桌面访问 Jetson Nano",
    "338": "实现刷脸登录的功能",
    "339": "对x进行归一化处理",
    "340": "对图像数据进行归一化处理",
    "341": "对训练图像随机变换以增加数据多样性",
    "342": "对训练图像随机旋转以增加数据多样性",
    "343": "将 Python 相关程序模块拷贝到/opt/python",
    "344": "将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能",
    "345": "将LED灯通过限流电阻连接到GPIO21，负极连接到GND形成回路",
    "346": "将SavedModel转换为TFLite兼容格式",
    "347": "将TensorFlow模型转换为TFLite文件格式(FlatBuffers格式)",
    "348": "将三维张量展开到一维",
    "349": "将三维张量展开到一维以便传入Dense层",
    "350": "将人脸编码列表与候选编码进行比较，以查看它们是否匹配",
    "351": "将已写入系统映像的 microSD 卡插入 Jetson Nano 模块底部的插槽中",
    "352": "将彩色图像转换为灰度图像，检测图像中是否包含人脸，在边界周围绘制矩形",
    "353": "将所有图像加载到一个模型需要的特定的大小",
    "354": "将模型加载到内存中",
    "355": "将模型转换为TFLite格式",
    "356": "将给定人脸编码列表与已知的人脸编码进行比较，并得到每个比较人脸的欧氏距离",
    "357": "将输入数据转换成模型接收的形式或排布，如resize原始图像到模型输入大小",
    "358": "将需要大约两个半小时",
    "359": "嵌入式开发平台",
    "360": "已经训练好的分类器，其中包括面部，眼睛，微笑等",
    "361": "常开触点",
    "362": "常闭触点",
    "363": "应用于树莓派的GPIO控制库函数",
    "364": "应用深度学习算法的一种实践应用",
    "365": "应用程序在边缘侧发起，产生更快的网络服务响应，满足行业在实时业务、应用智能、安全与隐私保护等方面的基本需求",
    "366": "廉价且周边设备多，互联网上有丰富的接口设备和项目案例资料",
    "367": "延迟一秒钟",
    "368": "开机前先安装CSI摄像头，系统才能识别",
    "369": "张量形状是(image_height, image_width, color_channels)",
    "370": "强调自组织的跨功能团队协作、进化开发、提前交付与持续改进",
    "371": "当压力撤销时电路恢复",
    "372": "当压力施压时电路接通",
    "373": "快速的启动并运行一组深度学习推理演示，体验 Jetson 的强大功能",
    "374": "手动下载安装需要的 Package 后用 pip 安装",
    "375": "打开终端窗口，执行python来测试是否安装了Python开发环境，并查看当前的Python版本",
    "376": "执行TensorFlow Lite模型推理",
    "377": "执行推理",
    "378": "执行推理以识别输入图像",
    "379": "执行模型推理",
    "380": "把 microSD 卡插到读卡器上之后插到电脑，使用 SD Memory Card Formatter 格式化 microSD 卡",
    "381": "控制GPIO引脚",
    "382": "控制GPIO管脚",
    "383": "控制GPIO管脚，可以在Shell脚本中使用",
    "384": "控制外部硬件设备",
    "385": "提供电路回路的地线连接",
    "386": "提问或分享项目",
    "387": "插入 microSD 卡",
    "388": "搭建电路原型",
    "389": "摄像头预捕获的图像宽度、高度，窗口显示的图像宽度、高度，捕获帧率，是否旋转图像",
    "390": "支持1080p30, 720p60以及640 × 480p90视频录像",
    "391": "支持Raspberry Pi、Arducam等常见的相机模块",
    "392": "支持设备端机器学习推断，延迟较低，并且二进制文件很小",
    "393": "支持预装驱动程序的RPi相机，可以很容易地用作即插即用外围设备",
    "394": "敏捷开发",
    "395": "数值计算",
    "396": "数据转换",
    "397": "整个安装需要两个小时才能完成",
    "398": "易于使用，易于阅读和编写",
    "399": "易于设置和使用，并且与许多流行的配件兼容",
    "400": "普通GPIO口",
    "401": "更新系统需要 root 权限",
    "402": "最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口",
    "403": "有两种方式可以与 Jetson Nano 开发板进行交互，一个是连接显示器、键盘和鼠标，二是通过 SSH 或 VNC 服务从另一台计算机远程访问",
    "404": "有两种编号模式：BCM编号模式和物理引脚Broad编号模式",
    "405": "杜邦线公对母",
    "406": "构建小型移动机器人、人脸签到打卡、口罩识别、智能门锁、智能音箱等复杂 AI 系统",
    "407": "构成检测目标的相邻矩形的最小个数",
    "408": "查看开发板系统信息",
    "409": "查看树莓派的GPIO引脚信息",
    "410": "树莓派",
    "411": "树莓派接口",
    "412": "树莓派的GPIO端口",
    "413": "树莓派系统",
    "414": "树莓派通用输入/输出接口（GPIO）",
    "415": "检测面部、眼睛、微笑等",
    "416": "模型推理",
    "417": "模型训练",
    "418": "涉及许多内容",
    "419": "添加--no-cache-dir 参数",
    "420": "清华源",
    "421": "清理GPIO引脚的设置",
    "422": "演示使用计算机视觉相关的模型，包括实时摄像机的使用，使用带有 JetPack SDK 和 NVIDIA TensorRT 的 Jetson 开发工具包上的预训练模型进行实时图像分类和对象检测",
    "423": "激活、设置为输出状态、写入1以点亮LED",
    "424": "灵活的架构可以将模型部署到桌面、服务器或移动设备中的 CPU 或 GPU 上",
    "425": "点亮LED灯",
    "426": "版本变化后API函数会改变",
    "427": "物理引脚Broad编号",
    "428": "物联网与人工智能项目开发",
    "429": "生成一个批次的图片，以生成器的形式给模型训练",
    "430": "用于在Jetson Nano开发板上识别花卉图片",
    "431": "用于控制LED灯的亮暗的按键",
    "432": "用于电路中的发光元件",
    "433": "用于训练模型",
    "434": "用于连接显示设备的接口",
    "435": "用于验证模型",
    "436": "由 jupyter 软件生成",
    "437": "由常开触点、常闭触点组合而成",
    "438": "电信号从低电平到高电平，或从高电平到低电平状态的改变",
    "439": "电源接口（5V）",
    "440": "电阻",
    "441": "目前有130个左右，它与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化",
    "442": "直接在Objective-C代码中使用C API执行TensorFlow Lite推理",
    "443": "直接更新树莓派系统",
    "444": "直流桶式插座",
    "445": "移动和嵌入式设备",
    "446": "第一个卷积层",
    "447": "第一次请连接显示器，键盘和鼠标，然后连接的 Micro-USB 电源，开发板将自动开机并启动",
    "448": "第二、三卷积层",
    "449": "简化图像预处理和模型输出处理",
    "450": "编译 OpenCV",
    "451": "编译模型、设置损失函数、设置优化器、设置评估指标",
    "452": "编辑工具",
    "453": "能够在图像分类、物体检测等应用程序中并行运行多个神经网络，运行功率仅为5瓦",
    "454": "花卉数据集",
    "455": "花卉识别模型",
    "456": "获取一些非常有意思的项目",
    "457": "获取分类结果的概率",
    "458": "获取张量的指针",
    "459": "获取张量的数据",
    "460": "获取更多的 Jetson 平台信息",
    "461": "获取模型输入张量信息",
    "462": "获取模型输出张量信息",
    "463": "观测开关去抖效果",
    "464": "解释器、转换器、算子库和硬件加速代理",
    "465": "计算分类损失",
    "466": "计算分类概率",
    "467": "计算已知人脸和未知人脸特征向量的距离",
    "468": "计算机视觉应用，如物体检测、人脸识别、图像分割等",
    "469": "计算能力不高，勉强可以使用一些小规模、并且优化过的网络进行推理，训练的话还是不够用的",
    "470": "计算预测结果的概率分布",
    "471": "训练时从数据集中的不同类中随机选出的图像数量",
    "472": "训练模型并记录训练和验证准确性/损失",
    "473": "训练模型并验证",
    "474": "记录训练日志用于可视化",
    "475": "记录训练过程数据",
    "476": "设备端机器学习推断，延迟较低，二进制文件很小",
    "477": "设置 VNC 密码 thepassword 修改为你的密码",
    "478": "设置GPIO引脚模式",
    "479": "设置上拉电阻",
    "480": "设置对图像进行多少次上采样以查找人脸",
    "481": "设置访问密码",
    "482": "设置输入张量值",
    "483": "识别图像里的空间模式，例如线条和物体局部",
    "484": "读取传感器数据，控制 LED 等外部设备",
    "485": "读取传感器数据，控制LED等外部设备",
    "486": "读取输出张量值",
    "487": "资源有限，训练网络时可能出现内存溢出错误",
    "488": "资源限制严重",
    "489": "跟换源",
    "490": "软件PWM库",
    "491": "软件源的配置文件",
    "492": "输入 IP 地址后点击 OK，双击对应的 VNC 用户输入密码，最后进入到 VNC 界面",
    "493": "输出三维张量，形状为(height, width, channels)",
    "494": "输出控制信号",
    "495": "输出模式",
    "496": "输出电压约为3.3V",
    "497": "输出的通道数量取决于声明层时的filters参数",
    "498": "输出通道数为32",
    "499": "输出通道数为64",
    "500": "边做边学的理想工具",
    "501": "边缘",
    "502": "边缘计算",
    "503": "运行功率仅为 5 瓦",
    "504": "运行各种深度学习模型",
    "505": "运行配置后需要检查输出结果",
    "506": "返回图像中每张人脸的 128 维人脸编码",
    "507": "返回张量数据的副本",
    "508": "还可以使用 C++ 编写自己的易于理解的识别程序",
    "509": "连接 DP 屏幕",
    "510": "连接摄像头",
    "511": "连接电路元件",
    "512": "选择模型、转换模型、部署到设备、优化模型",
    "513": "逐步加载单个数据集的图像",
    "514": "通用输入/输出接口，一组数字引脚，可用于将树莓派连接到其他电子设备",
    "515": "通过GPIO控制展示基础硬件控制能力",
    "516": "通过pip安装，网络环境差时可考虑更换源",
    "517": "通过下载源代码来安装",
    "518": "通过几个交互式教程展示如何利用 AI 的力量来教 JetBot 跟随物体、避免碰撞等",
    "519": "通过文件读写操作控制外设",
    "520": "通过许多正负样例中训练得到cascade方程，然后将其应用于其他图片",
    "521": "通过软件编程进行控制，例如使用 Python 或其他编程语言编写程序",
    "522": "郁金香(tulips)、玫瑰(roses)、浦公英(dandelion)、向日葵(sunflowers)、雏菊(daisy)",
    "523": "部署TensorFlow Lite模型",
    "524": "部署到嵌入式设备",
    "525": "配置 Jupyter lab",
    "526": "配置 VNC 服务",
    "527": "配置优化器、损失函数和评估指标",
    "528": "采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能",
    "529": "重启树莓派后尝试启动",
    "530": "错误的连接和编程可能会导致设备损坏或故障",
    "531": "镜像写入 microSD 卡",
    "532": "阻塞函数，会阻塞程序执行，直到检测到一个边沿",
    "533": "降低卷积层对位置的敏感",
    "534": "限制电流以保护LED和GPIO引脚",
    "535": "限流电阻",
    "536": "集Jupyter Notebook、文本编辑器、终端以及各种个性化组件于一体的全能IDE",
    "537": "需要 5V⎓2A 的高品质电源供电",
    "538": "需要使用 Gstreamer 读取视频流",
    "539": "需要小心谨慎，建议在使用之前仔细阅读相关文档，并确保采取适当的安全措施",
    "540": "需要设置 OpenCV 的内容、位置和方式",
    "541": "静态图片分辨率为3280 × 2464",
    "542": "面包板",
    "543": "面向有兴趣学习 AI 和构建有趣应用程序的创客、学生和爱好者",
    "544": "首先到英伟达官方下载官方镜像，也可以去开源社区下载配置好的镜像",
    "545": "首先需要查询 ip 地址",
    "546": "默认为3个"
  }
}