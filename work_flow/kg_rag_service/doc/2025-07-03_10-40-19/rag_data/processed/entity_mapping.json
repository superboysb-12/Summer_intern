{
  "entity_to_id": {
    "--enable_v1_converter": 0,
    "--keras_model_file": 1,
    "--no-cache-dir": 2,
    "--output_file": 3,
    "--output_file, --saved_model_dir, --keras_model_file, --enable_v1_converter": 4,
    "--saved_model_dir": 5,
    "-D WITH_QT=OFF 禁用了 Qt5 支持": 6,
    ".tflite": 7,
    "/dev目录存储所有设备文件或特殊文件": 8,
    "/etc/apt/sources.list": 9,
    "/opt/python": 10,
    "/sys/class/gpio目录下的端口文件": 11,
    "/usr/bin/python": 12,
    "0.2s的响应时间": 13,
    "1000": 14,
    "128核 NVIDIA Maxwell 架构的 GPU": 15,
    "14个引脚用于其他功能": 16,
    "155层": 17,
    "155层网络": 18,
    "2.0.0": 19,
    "2.3.0": 20,
    "2017年底": 21,
    "26个引脚可以用作数字输入或输出": 22,
    "330欧姆电阻": 23,
    "3个 Conv2D 和 2个 MaxPooling2D 层": 24,
    "40 针 GPIO 扩展接口": 25,
    "40个 GPIO 引脚": 26,
    "40个GPIO引脚": 27,
    "4GB 的内存": 28,
    "512": 29,
    "5500": 30,
    "5个节点": 31,
    "5个节点的输出层": 32,
    "6": 33,
    "64位四核的 ARM Cortex-A57 CPU": 34,
    "800万像素": 35,
    "800万像素、感光芯片为索尼IMX219": 36,
    "9": 37,
    "<!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">": 38,
    "<html> <body> <h4>TFJS example<hr/></h4> <div id=\"micro-out-div\">TensorFlow.js Test</div> <script src=\"./index.js\"> </script> </body> </html>": 39,
    "<script>标签": 40,
    "@tensorflow/tfjs": 41,
    "@tensorflow/tfjs-vis": 42,
    "AC8265": 43,
    "ARM Cortex-A57 CPU、NVIDIA Maxwell GPU": 44,
    "ARM Cortex-A72 CPU": 45,
    "AR效果": 46,
    "Adam": 47,
    "Adam优化器": 48,
    "Android": 49,
    "Android Studio": 50,
    "Android 应用": 51,
    "Android 开发人员": 52,
    "Android 开发者使用 JCenter Bintray 的 TFLite AAR": 53,
    "Android 设备": 54,
    "Android部署": 55,
    "B02版本有两路": 56,
    "BATCH_SIZE": 57,
    "BCM编号": 58,
    "BCM编号方式": 59,
    "BCM编号模式和物理引脚Broad编号模式": 60,
    "Broadcom针脚号，也即是通常称的GPIO": 61,
    "C": 62,
    "C#": 63,
    "C++": 64,
    "C++ 和 Python 提供的 TensorFlow Lite API": 65,
    "CNN": 66,
    "CSI 相机接口": 67,
    "CSI摄像头": 68,
    "CSI端口": 69,
    "ClassifierFloatMobileNet类": 70,
    "Classifier类": 71,
    "CocoaPods for Swift or Objective-C": 72,
    "Conv2D": 73,
    "Conv2D, MaxPooling2D, Flatten, Dense等层": 74,
    "Core API": 75,
    "DeepLearning.js": 76,
    "Dense": 77,
    "Display Port 接口": 78,
    "Etcher": 79,
    "Ethernet 有线网络": 80,
    "Face Recognition库": 81,
    "False": 82,
    "FlatBuffers": 83,
    "FlatBuffers 格式": 84,
    "GND": 85,
    "GPIO.cleanup()方法": 86,
    "GPIO.setmod()": 87,
    "GPIO.setup()": 88,
    "GPIO.setup()方法": 89,
    "GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP)": 90,
    "GPIO21": 91,
    "GPIO口": 92,
    "GPIO库": 93,
    "GPIO库、I2C库、SPI库、UART库和软件PWM库": 94,
    "GPIO库、I2C库、SPI库、UART库和软件PWM库等": 95,
    "GPIO引脚": 96,
    "GPU": 97,
    "GPU 委托": 98,
    "GPU代理": 99,
    "GStreamer": 100,
    "GStreamer管道": 101,
    "GlobalAveragePooling2D": 102,
    "Google": 103,
    "Google Assistant": 104,
    "Google Assistant，Google Photos，Uber，Airbnb，网易，爱奇艺和 WPS 等": 105,
    "Google Edge TPU Coral Dev Board": 106,
    "Google Photos": 107,
    "Google 内部用于计算机视觉场景的解决方案": 108,
    "Google 尝试简化 TensorFlow 并在移动设备上运行的项目": 109,
    "Gradle 同步": 110,
    "HDMI 接口": 111,
    "HIGH电平": 112,
    "HTML 文件": 113,
    "HTML文件、JS文件和配置文件": 114,
    "Haar特征的cascade分类器": 115,
    "Hello AI World": 116,
    "I2C接口(SCL、SDA)，SPI接口（MISO、MOSI、CLK、CS片选信号SPICE0_N），UART串口接口（TXD、RXD），PWM接口以及普通GPIO口": 117,
    "IMAGE_WIDTH, IMAGE_HEIGHT, testData, testxs, labels, preds": 118,
    "IMX219模组": 119,
    "ImageDataGenerator": 120,
    "ImageProcessor": 121,
    "Intel Neural Compute Stick 2": 122,
    "IoT领域": 123,
    "Java": 124,
    "Java 或 C++ API 执行 TensorFlow Lite 推理": 125,
    "JavaScript": 126,
    "JavaScript 语言版本的扩展": 127,
    "JetBot": 128,
    "JetPack SDK": 129,
    "Jetson": 130,
    "Jetson Community Projects": 131,
    "Jetson Developer Kits": 132,
    "Jetson Nano": 133,
    "Jetson Nano 开发板": 134,
    "Jupyter Notebook": 135,
    "Jupyter Notebook 的全面升级": 136,
    "Jupyter Notebook、文本编辑器、终端以及各种个性化组件": 137,
    "Jupyter lab": 138,
    "JupyterLab": 139,
    "Jupyter的配置文件": 140,
    "Keras H5": 141,
    "Keras Model 和 SavedModel": 142,
    "Keras 模型": 143,
    "Keras模型": 144,
    "Keras的模型定义方式": 145,
    "LED": 146,
    "LED灯": 147,
    "LED灯、限流电阻、GPIO21、GND": 148,
    "LOW电平": 149,
    "Layers API": 150,
    "Layers API 和 Core API": 151,
    "Layers API和Core API": 152,
    "Linux": 153,
    "Linux 平台": 154,
    "Linux 开发环境": 155,
    "Live Caption": 156,
    "MCU": 157,
    "MIPI": 158,
    "MIPI CSI-2 摄像头接口": 159,
    "MIPI的相机串行接口（CSI）端口": 160,
    "MIPI联盟发起的为移动应用处理器制定的开放标准": 161,
    "MNIST数据集": 162,
    "MaxPooling2D": 163,
    "Micro USB 接口": 164,
    "Micro-USB 接口": 165,
    "MnistData": 166,
    "MobileNet": 167,
    "MobileNet V2": 168,
    "MobileNetV2": 169,
    "MobileNets_v2": 170,
    "NVIDIA Jetson Nano": 171,
    "NVIDIA Jetson Nano 开发板": 172,
    "NVIDIA Jetson论坛": 173,
    "Node 和 Python 一样都是使用 C++编写的环境，所以在 Node 环境进行运算的速度目前与 Python 速度不相上下": 174,
    "OCR处理": 175,
    "Object C": 176,
    "OpenCV": 177,
    "OpenCV 安装": 178,
    "OpenCV 安装脚本": 179,
    "OpenCV 编译": 180,
    "OperatorCode": 181,
    "PCB板上针脚的物理位置对应的编号（1~40）": 182,
    "Parcel": 183,
    "Parcel, WebPack 或 Rollup": 184,
    "Pi 4B与Pi v3+": 185,
    "PoseNet模型": 186,
    "PoseNet示例应用程序": 187,
    "Post training quantization 和 Quantization-aware training": 188,
    "Python": 189,
    "Python 2.7": 190,
    "Python API": 191,
    "Python API 调用方式": 192,
    "Python GPIO编程": 193,
    "Python 代码片段": 194,
    "Python 包管理": 195,
    "Python 官方集成的包管理工具": 196,
    "Python 官网": 197,
    "Python 源码包": 198,
    "Python安装": 199,
    "Python开发环境": 200,
    "Python模块": 201,
    "Python相关程序模块会拷贝到/opt/python": 202,
    "Python程序": 203,
    "Quantization-aware training": 204,
    "RPI.GPIO库": 205,
    "RandomFlip": 206,
    "RandomRotation": 207,
    "Raspberry Camera V2": 208,
    "Raspberry Pi": 209,
    "Raspberry Pi 4": 210,
    "Raspberry Pi、Arducam等常见的相机模块": 211,
    "Raspbian软件仓库镜像": 212,
    "ResNet": 213,
    "SD Memory Card Formatter": 214,
    "SavedModel": 215,
    "SavedModel 和 Keras Sequential": 216,
    "SavedModel 和 Keras Sequential 两种模型导出方法和格式": 217,
    "Sequential模型": 218,
    "SparseCategoricalCrossentropy": 219,
    "Swift": 220,
    "Swift 和 Objective-C 编写的原生 iOS 库": 221,
    "SymbolicTensor": 222,
    "TEST_DATA_SIZE": 223,
    "TF Mobile": 224,
    "TF Mobile 的经验": 225,
    "TFLite": 226,
    "TFLite model": 227,
    "TFLite 文件格式": 228,
    "TFLite 模型文件格式": 229,
    "TFLite 模型文件格式，更注重考虑实时性，内存高效": 230,
    "TFLite 模型转换器": 231,
    "TFLite 模型转换过程": 232,
    "TFLite 算子库": 233,
    "TFLite 解释器": 234,
    "TFLite 解释执行器": 235,
    "TFLite 转换器": 236,
    "TFLiteConverter": 237,
    "TFLiteConverter.from_concrete_functions()": 238,
    "TFLiteConverter.from_keras_model()": 239,
    "TFLiteConverter.from_saved_model()": 240,
    "TFLite模型": 241,
    "TFLite解释器": 242,
    "TFLite解释器和GPU代理": 243,
    "TFLite转换": 244,
    "TFMini": 245,
    "TFMini 和内部其他类似项目的很多优秀工作": 246,
    "TRAIN_DATA_SIZE": 247,
    "Tensor": 248,
    "Tensor 的主要构造函数": 249,
    "TensorBoard": 250,
    "TensorFLow-vis": 251,
    "TensorFlow": 252,
    "TensorFlow 2.x 模型": 253,
    "TensorFlow GPU 版本": 254,
    "TensorFlow GPU 版本安装": 255,
    "TensorFlow Hub": 256,
    "TensorFlow Hub 上可搜索到的模型": 257,
    "TensorFlow Lite": 258,
    "TensorFlow Lite AAR": 259,
    "TensorFlow Lite API": 260,
    "TensorFlow Lite 开发工作流程": 261,
    "TensorFlow Lite 推理": 262,
    "TensorFlow Lite 支持库": 263,
    "TensorFlow Lite 模型": 264,
    "TensorFlow Lite 模型文件": 265,
    "TensorFlow Lite 的工作流程": 266,
    "TensorFlow Lite 示例": 267,
    "TensorFlow Lite 算子库": 268,
    "TensorFlow Lite 解释器": 269,
    "TensorFlow Lite 解释器(Interpreter)": 270,
    "TensorFlow Lite 解释器(Interpreter)和 TensorFlow Lite 转换器(Converter)": 271,
    "TensorFlow Lite 解释执行器": 272,
    "TensorFlow Lite 转换器": 273,
    "TensorFlow Lite 转换器(Converter)": 274,
    "TensorFlow Lite 转换器命令行工具": 275,
    "TensorFlow Lite支持库": 276,
    "TensorFlow Lite模型": 277,
    "TensorFlow Lite解释器": 278,
    "TensorFlow 官网": 279,
    "TensorFlow 模型": 280,
    "TensorFlow 模型导出": 281,
    "TensorFlow 的 JavaScript 版本": 282,
    "TensorFlow.js": 283,
    "TensorFlow.js 中的中心数据单元，是一维或多维数组": 284,
    "TensorFlow.js 模块": 285,
    "TensorFlow.js 进行浏览器可视化的一组实用工具库": 286,
    "TensorFlow团队开发的产品": 287,
    "TensorFlow模型的序列化格式": 288,
    "TensorLabel": 289,
    "Tensorflow.js": 290,
    "Tensorflow.js 的模型可以跟 Python 等其他语言模型进行互转": 291,
    "Text, Image, Video 和 Publishers 等类别": 292,
    "Total params: 2,626,821, Trainable params: 368,837, Non-trainable params: 2,257,984": 293,
    "USB": 294,
    "USB摄像头": 295,
    "VGG": 296,
    "VNC": 297,
    "VNC Viewer": 298,
    "WPS": 299,
    "Web Server for Chrome": 300,
    "Web 开发新手": 301,
    "Webpack": 302,
    "Wiring Pi": 303,
    "Wiring Pi库": 304,
    "Wiring Pi编号": 305,
    "Wiring Pi编号、BCM编号、物理引脚Broad编号": 306,
    "Wiring Pi编号模式": 307,
    "aaptOptions": 308,
    "activation: 'relu'": 309,
    "activation: 'softmax'": 310,
    "add_event_detect()函数": 311,
    "allocate_tensors()": 312,
    "android 目录": 313,
    "base_model, Conv2D, Dropout, GlobalAveragePooling2D, Dense": 314,
    "batchSize": 315,
    "batchSize设置为512": 316,
    "batch_size": 317,
    "batch_size用于设置每批图像数量": 318,
    "bool": 319,
    "build.gradle": 320,
    "buildscript": 321,
    "callback": 322,
    "callbacks设置为fitCallbacks": 323,
    "categoricalCrossentropy": 324,
    "categorical_crossentropy": 325,
    "cdn.jsdelivr.net": 326,
    "class_names": 327,
    "classpath 'com.android.tools.build:gradle:...'": 328,
    "compare_faces函数": 329,
    "conv2d, dropout, global_average_pooling2d, dense": 330,
    "convertToTensor函数": 331,
    "converter": 332,
    "converter.convert": 333,
    "createModel()": 334,
    "daisy, dandelion, roses, sunflowers, tulips": 335,
    "data.js": 336,
    "data.js文件": 337,
    "dense层": 338,
    "dependencies": 339,
    "dispose": 340,
    "dispose和tf.tidy两种内存管理方法": 341,
    "dlib库": 342,
    "dlib这一C++图形库": 343,
    "doPrediction函数": 344,
    "epochs": 345,
    "epochs设置为10": 346,
    "face_cascade.detectMultiScale": 347,
    "face_distance函数": 348,
    "face_encodings": 349,
    "face_encodings函数": 350,
    "face_landmarks": 351,
    "face_locations": 352,
    "face_recognition": 353,
    "filters: 8": 354,
    "fine_tune_at": 355,
    "flatten层": 356,
    "flow_from_directory": 357,
    "flower_classification": 358,
    "flower_classification 项目": 359,
    "from_saved_model(), from_keras_model(), from_concrete_functions()": 360,
    "functional模型": 361,
    "get_input_details()": 362,
    "get_output_details()": 363,
    "get_tensor()": 364,
    "gpio readall命令": 365,
    "hub.KerasLayer": 366,
    "iOS": 367,
    "iOS 开发人员": 368,
    "iOS 开发者通过 CocoaPods 获取": 369,
    "import * as tf from '@tensorflow/tfjs' console.log(tf.version.tfjs) const shape = [2, 3]; // 2 rows, 3 columns const a = tf.tensor": 370,
    "import语句和TensorFlow.js测试代码": 371,
    "include_top=False": 372,
    "index": 373,
    "index.html": 374,
    "index.js": 375,
    "inputShape: [28, 28, 1]": 376,
    "inputShape为[1], units为1, useBias为true": 377,
    "interpreter": 378,
    "interpreter.get_tensor()": 379,
    "invoke()": 380,
    "jtop 命令": 381,
    "jupyter": 382,
    "jupyter_notebook_config.py": 383,
    "kernelInitializer: 'varianceScaling'": 384,
    "kernelSize: 5": 385,
    "label.txt": 386,
    "lambda x, y: (normalization_layer(x), y)": 387,
    "layers.Flatten()": 388,
    "load_image_file": 389,
    "loss: 'categoricalCrossentropy'": 390,
    "make install": 391,
    "make命令": 392,
    "maven { url '[URL]' }": 393,
    "metrics: ['accuracy']": 394,
    "microSD 卡": 395,
    "microSD 卡插槽": 396,
    "microSD卡": 397,
    "minNeighbors参数": 398,
    "mnist项目": 399,
    "mobilenetv2_1.00_224": 400,
    "model inference": 401,
    "model.compile": 402,
    "model.fit": 403,
    "model.fit()": 404,
    "model.predict()": 405,
    "model.tflite": 406,
    "model.tflite和label.txt": 407,
    "model.tflite文件": 408,
    "model.trainable = False": 409,
    "modelSummary": 410,
    "model参数": 411,
    "nano或者vi": 412,
    "nextTestBatch": 413,
    "nextTrainBatch": 414,
    "nextTrainBatch和nextTestBatch方法": 415,
    "noCompress \"tflite\"": 416,
    "normalization_layer": 417,
    "np.argmax()": 418,
    "number_of_times_to_upsample参数": 419,
    "optimizer: Adam": 420,
    "org.tensorflow:tensorflow-lite:+": 421,
    "output_details": 422,
    "package.json": 423,
    "pip": 424,
    "pip install": 425,
    "pip3": 426,
    "poolSize: [2, 2]": 427,
    "post-training quantization": 428,
    "predict()": 429,
    "print(\"button pressed!\")": 430,
    "python": 431,
    "recognizeImage方法": 432,
    "repositories": 433,
    "repositories 和 dependencies": 434,
    "saved_model_dir": 435,
    "sequential模型": 436,
    "sequential模型和functional模型": 437,
    "set_tensor()": 438,
    "showAccuracy函数": 439,
    "showConfusion函数": 440,
    "shuffle": 441,
    "shuffle用于控制批处理顺序": 442,
    "shuffle设置为true": 443,
    "softmax": 444,
    "start 目录和 finish 目录": 445,
    "strides: 1": 446,
    "strides: [2, 2]": 447,
    "string": 448,
    "target_size 参数": 449,
    "target_size用于设置图像大小": 450,
    "tensor()": 451,
    "tf.cast": 452,
    "tf.expand_dims": 453,
    "tf.image.resize": 454,
    "tf.keras model": 455,
    "tf.keras.Sequential": 456,
    "tf.keras.layers.Dense(units=1)": 457,
    "tf.keras.layers.Dense(units=1, input_shape=[1])": 458,
    "tf.keras.layers.Dense(units=16, activation='relu')": 459,
    "tf.keras.models.Sequential": 460,
    "tf.linspace()": 461,
    "tf.lite.TFLiteConverter": 462,
    "tf.lite.TFLiteConverter.from_keras_model": 463,
    "tf.lite.TFLiteConverter.from_saved_model": 464,
    "tf.losses.meanSquaredError": 465,
    "tf.model()": 466,
    "tf.nn.softmax": 467,
    "tf.nn.softmax()": 468,
    "tf.saved_model.save": 469,
    "tf.sequential()": 470,
    "tf.sequential()和tf.model()两种创建模型的方式": 471,
    "tf.tensor": 472,
    "tf.tidy": 473,
    "tf.tidy()": 474,
    "tf.train.adam()": 475,
    "tf.util.shuffle": 476,
    "tfjs-examples/mnist": 477,
    "tflite_convert": 478,
    "tflite_convert --keras_model_file=/tmp/mobilenet_keras_model.h5 --output_file=/tmp/mobilenet.tflite": 479,
    "tflite_convert --saved_model_dir=/tmp/mobilenet_saved_model --output_file=/tmp/mobilenet.tflite": 480,
    "tfvis.render.scatterplot": 481,
    "time.sleep()方法": 482,
    "train_generator": 483,
    "train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=val_generator, validation_steps=len(val_generator)": 484,
    "ui.js": 485,
    "units: 10": 486,
    "units为1, useBias为true": 487,
    "val_ds": 488,
    "val_generator": 489,
    "validationData设置为[testXs, testYs]": 490,
    "wait_for_edge()函数": 491,
    "wait_for_edge()函数和add_event_detect()函数": 492,
    "yarn": 493,
    "一个使用数据流图进行数值计算的开源软件库": 494,
    "一个强大、简单、易上手的人脸识别开源项目": 495,
    "一个用于使用 JavaScript 进行机器学习开发的库，用于在浏览器和 Node.js 训练和部署机器学习模型": 496,
    "一个端到端的机器学习开源框架": 497,
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具": 498,
    "一次采样32条训练数据": 499,
    "一种数据结构，包含了在解决特定问题时训练得到的机器学习网络的逻辑和知识": 500,
    "一种有效的物品检测方法": 501,
    "一种特定的矩阵用来呈现算法性能的可视化效果": 502,
    "一系列的函数，这些函数以一个或多个张量作为输入，并输出另一个张量": 503,
    "一系列的计算节点、多个张量，以及子图本身的输入和输出": 504,
    "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型": 505,
    "一组数字引脚，可用于将树莓派连接到其他电子设备": 506,
    "三维张量输出，形状为(height, width, channels)": 507,
    "上拉电阻": 508,
    "下载 OpenCV": 509,
    "下载TensorFlow Lite示例源码": 510,
    "下载和访问mnist数据集": 511,
    "下载特定版本的Python": 512,
    "下载解压": 513,
    "不包括无线网卡": 514,
    "不支持 CUDA": 515,
    "不支持 CUDA 且版本是固定搭配的": 516,
    "不支持即插即用": 517,
    "不改变基础模型的各项参数变量": 518,
    "不更新预训练网络的权重": 519,
    "不清除内部函数的返回值": 520,
    "不需要原始模型构建代码": 521,
    "不需要原始模型构建代码就可以运行": 522,
    "不需要原有模型中最后的神经网络层": 523,
    "不需要序列化或可以创造自己的序列化方法": 524,
    "不需要改变模型，最少情况只需多加一行代码": 525,
    "与 TensorFlow 一起安装": 526,
    "与 TensorFlow 团队合并，重命名为 TensorFlow.js": 527,
    "与 TensorFlow 的核心算子库略有不同": 528,
    "与JavaScript中的常规范围类似，但针对GPU支持的张量": 529,
    "与树莓派结合可以将项目与现实世界轻松的联系起来": 530,
    "串联在LED和电源之间限制电流": 531,
    "为了高性能场景创建的序列化库": 532,
    "为图像张量添加批次维度": 533,
    "为机器学习提供低级构建模块，以及构建神经网络的高级 Keras Layers API": 534,
    "主要应用于游戏场景": 535,
    "主要应用于游戏场景，是为了高性能场景创建的序列化库": 536,
    "了解模型效率、调试超参数": 537,
    "二维卷积层": 538,
    "二进制文件很小": 539,
    "二进制文件的大小约为 1 MB（针对 32 位 ARM build）": 540,
    "人体姿势估计": 541,
    "人脸检测": 542,
    "人脸检测、检测面部特征点、给脸部编码、从编码中找出人的名字": 543,
    "人脸识别": 544,
    "人脸识别与商品识别": 545,
    "仅用于开发的程序包": 546,
    "仅适用于卷积神经网络的一个子集": 547,
    "从 GitHub 获取源码并运行；创建相关文件；定义模型结构；训练模型；使用模型进行评估与预测": 548,
    "从 MNIST 数据集中随机批量提取 MNIST 图像": 549,
    "从头编译": 550,
    "从指定目录生成训练数据批次": 551,
    "从指定目录生成验证数据批次": 552,
    "从测试集中返回一批图像及其标签": 553,
    "从训练集中返回一批随机图像及其标签": 554,
    "以 ldconfig 结束": 555,
    "以依赖项的安装开始": 556,
    "以最小精度下降来训练网络": 557,
    "优化器为Adam": 558,
    "优化器使用Adam": 559,
    "优化模型": 560,
    "优化模型大小和性能": 561,
    "优化的 FlatBuffer 格式": 562,
    "优化的 FlatBuffer 格式，以 .tflite 为文件扩展名": 563,
    "优化的算子内核": 564,
    "位于其引脚排针上": 565,
    "低功耗": 566,
    "作为LED灯的限流电阻": 567,
    "作为LED的控制引脚": 568,
    "作为functional模型第一层的输入": 569,
    "作为最终的Dense层的激活函数用于多分类": 570,
    "作为模型的优化器": 571,
    "作为模型的损失函数": 572,
    "作为迁移学习的基础模型": 573,
    "使权重和激活值的 Post training 更简单": 574,
    "使模型准确率提高几个百分点": 575,
    "使用 GPU 加速模型的运算，提高运算效率": 576,
    "使用 Python API 进行转换": 577,
    "使用 SavedModel 格式存储": 578,
    "使用 TFLite 模型转换器转换成 TFLite 文件格式(FlatBuffers 格式)": 579,
    "使用 TensorFlow Lite 解释器（提供多种语言的 API）在设备端运行模型": 580,
    "使用 TensorFlow Lite 转换器将模型转换为 TensorFlow Lite 格式": 581,
    "使用'mean_squared_error'作为损失函数": 582,
    "使用'sgd'作为优化器": 583,
    "使用3×3的卷积核，并在输出上使用 Relu 激活函数": 584,
    "使用BCM编号、物理引脚Broad编号": 585,
    "使用C、C++开发并且可以被其他语言包使用，例如python、ruby或者PHP等": 586,
    "使用GPU来加速数学运算": 587,
    "使用ImageProcessor进行resize和normalize": 588,
    "使用TFLiteConverter转换为TFLite格式": 589,
    "使用TensorFlow.js识别剪刀、石头、布手势": 590,
    "使用tf.model() API创建非闭环的计算图": 591,
    "使用tf.saved_model.save保存模型": 592,
    "使用低学习率编译模型": 593,
    "使用低学习率重新编译模型": 594,
    "使用层构建模型": 595,
    "使用已编译好的库": 596,
    "使用模型从未见过的测试数据评估分类器准确性": 597,
    "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响": 598,
    "使用测试数据集评估模型": 599,
    "使用测试集中的数据": 600,
    "使用深度可分离的卷积": 601,
    "使用滑动滤波器窗口学习空间不变的变换": 602,
    "使用网络摄像头检查自己做出的代表石头剪刀布的手势图像": 603,
    "使用计算机视觉相关模型和预训练模型进行实时图像分类和对象检测": 604,
    "使用训练集进行训练": 605,
    "使用语言就是 Javascript，前端工程师不需要学习其他后端语言，降低入门门槛": 606,
    "使用预训练量化进行模型转换": 607,
    "保存完整的TensorFlow程序，包括权重值和计算": 608,
    "保护LED和GPIO引脚": 609,
    "保持了很多通用性": 610,
    "保留原来大规模训练的优势": 611,
    "借助低级运算（例如 tf.matMul()、tf.add() 等）创建机器学习模型": 612,
    "做了移动设备相关的优化": 613,
    "允许解释器在设备的 GPU 上运行适当的运算符": 614,
    "全能 IDE": 615,
    "全连接(Full Connected)层": 616,
    "全连接网络": 617,
    "关闭LED灯": 618,
    "具有 shape 属性定义其数组形状": 619,
    "内存只有几十KB": 620,
    "内存回收问题突出": 621,
    "内存管理": 622,
    "内存高效": 623,
    "内存高效，采取静态内存分配": 624,
    "写一段简单的测试代码": 625,
    "写入镜像": 626,
    "冻结前100层，设置不可训练": 627,
    "冻结预训练模型并更新分类器权重": 628,
    "准备训练集和验证集": 629,
    "准确度": 630,
    "减少内存碎片化": 631,
    "减少服务器的运算，提高服务器资源利用，增强客户端响应运算结果的速度": 632,
    "出门问问智能音箱": 633,
    "创建0~1之间平均分配的100个值": 634,
    "创建TFLite转换器实例": 635,
    "创建、训练和导出自定义 TensorFlow Lite 模型": 636,
    "创建了一个安装脚本": 637,
    "创建任意非闭环的计算图": 638,
    "创建实例并加载模型": 639,
    "创新奇智": 640,
    "判断训练结果的参数": 641,
    "利用 ARM 的 NEON 指令集做了大量的优化": 642,
    "利用GPIO控制外部硬件设备的基础": 643,
    "利用在同一域中的较大数据集上训练的模型所学习的特征": 644,
    "利用手机上的加速器，比如 GPU 或者 DSP 等": 645,
    "利用计算机对图像进行处理、分析和理解，以识别各种不同模式的目标和对象的技术": 646,
    "前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像": 647,
    "前端工程师不需要学习其他后端语言，降低入门门槛": 648,
    "功耗非常低，有两种模式：5W（低功耗模式；可以使用 USB 口供电）和10W（必须使用 Power Jack 外接5V 电源供电）": 649,
    "功能强大的编程语言，易于使用，易于阅读和编写": 650,
    "功能强大，交互式、富文本，还有丰富的插件、主题修改、多语言支持": 651,
    "功能接线的引脚号（如TXD、PWM0等）": 652,
    "加载 @tensorflow/tfjs 和 @tensorflow/tfjs-vis 两个 TFJS 模块的代码": 653,
    "加载 @tensorflow/tfjs 和 @tensorflow/tfjs-vis 两个 TFJS 模块的脚本": 654,
    "加载 TensorFlow Hub 上的模型": 655,
    "加载和运行TFLite模型": 656,
    "加载数据并准备进行训练；定义模型结构；训练模型，并监视其性能；评估模型": 657,
    "加载数据集并显示20张图片": 658,
    "加载数据，定义模型，训练循环并指定UI元素": 659,
    "加载模型": 660,
    "加载模型，转换数据，运行模型推理，解释输出": 661,
    "加载面孔照片": 662,
    "加速模型推理过程": 663,
    "动态显示训练的过程": 664,
    "包含完整的TensorFlow程序": 665,
    "包含完整的TensorFlow程序，包括权重值和计算": 666,
    "千兆以太网端口": 667,
    "单一芯片的小型计算机": 668,
    "单个图像的维度为[28,28,1]": 669,
    "占用更少的磁盘和内存，更快更高效": 670,
    "卷积层": 671,
    "卷积层与全连接层": 672,
    "卷积层输入": 673,
    "取消冻结模型的顶层": 674,
    "取消冻结模型的顶层，设置 base_model.trainable = True": 675,
    "变量(Variable)": 676,
    "只使用在C语言中": 677,
    "只提供了基本的转化功能": 678,
    "可以使用树莓派摄像头": 679,
    "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的 TensorFlow 预训练模型中选择一个模型直接使用或重新训练": 680,
    "可以利用手机上的加速器，比如 GPU 或者 DSP": 681,
    "可以利用手机上的加速器，比如 GPU 或者 DSP 等": 682,
    "可以是内置的算子，也可以是自定制算子，有一个名字": 683,
    "可以直接使用cv2.videocapture(2)打开": 684,
    "可以直接在浏览器中运行，无需进行安装，也无需借助后端运行": 685,
    "可以设置访问密码": 686,
    "可以通过跳线线连接到其他电路板或设备": 687,
    "可以通过软件编程进行控制": 688,
    "可以配置为输入或输出": 689,
    "可以配置图像加载的细节": 690,
    "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行": 691,
    "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型": 692,
    "可能值得使用构建工具进行探索": 693,
    "可能出现哈希不匹配的错误": 694,
    "可能导致模型过拟合": 695,
    "可能导致预训练模型忘记已学内容": 696,
    "可视化模型训练的过程和结果": 697,
    "可视化模型预测结果和原始数据": 698,
    "可配置为输入或输出": 699,
    "启动图标": 700,
    "启用 TF 1.x 的转换器和标志": 701,
    "命令行 TensorFlow Lite 转换器命令行工具": 702,
    "命令行与 Python API": 703,
    "命令行工具": 704,
    "命令行工具gpio": 705,
    "命令行工具和 Python API": 706,
    "命令行调用方式": 707,
    "商品流通过程中，特别是无人货架、智能零售柜等无人零售领域": 708,
    "商品识别": 709,
    "四引脚按键": 710,
    "四脚按键开关": 711,
    "回调函数": 712,
    "因为 TensorFlow.js 使用了 GPU 来加速数学运算，因此当 tensorflow 处理张量和变量时就有必要来管理 GPU 内存": 713,
    "国内源": 714,
    "图像、文本和语音处理": 715,
    "图像分类任务": 716,
    "图像和视频处理": 717,
    "图像处理": 718,
    "图像识别": 719,
    "图像识别技术": 720,
    "图像预处理": 721,
    "在 Android 与 iOS 平台上使用": 722,
    "在 HTML 中直接引用 TensorFlow.js 发布的 NPM 包中已经打包安装好的 JavaScript 代码": 723,
    "在 MCU 上甚至可以小于 100KB": 724,
    "在 Node.js 环境中，需要有 CUDA 环境支持": 725,
    "在 Tensorflow.js 有两种创建模型的方式：可以用高层 API：Layers API 来建立模型，也用 Core API 来搭建相同的模型": 726,
    "在18号引脚处设置": 727,
    "在Jetson Nano开发板上进行花卉图片识别": 728,
    "在不同设备上使用硬件加速": 729,
    "在图像中检测面部": 730,
    "在图像分类、物体检测、分割和语音处理等应用程序中并行运行多个神经网络": 731,
    "在大规模数据处理上不如Python高效": 732,
    "在官网下载安装包后安装": 733,
    "在小型数据集上训练模型": 734,
    "在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战": 735,
    "在有 GPU 加速的手机上运行 MobileNet 图像分类，模型运行速度可以提高": 736,
    "在每一个训练周期显示训练情况": 737,
    "在浏览器上开发模型": 738,
    "在浏览器中加载": 739,
    "在浏览器中训练模型": 740,
    "在浏览器和 Node.js 环境中进行机器学习模型的开发、训练和部署": 741,
    "在浏览器环境中实现深度学习的功能": 742,
    "在浏览器环境中，需要有 WebGL 环境支持": 743,
    "在生产环境中不需要": 744,
    "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化": 745,
    "在移动端、嵌入式和物联网设备上运行 TensorFlow 模型": 746,
    "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型": 747,
    "在移动设备、嵌入式设备和IoT设备上运行TensorFlow模型": 748,
    "在移动设备上实现性能大幅度提升": 749,
    "在给定设备上实现性能、模型大小和准确性的理想平衡": 750,
    "在训练过程中不能用于训练": 751,
    "在设备端运行 TFLite 模型": 752,
    "在资源有限的硬件上运行": 753,
    "在边缘设备上运行 TensorFlow 模型推理的官方框架": 754,
    "在靠近物或数据源头的一侧，采用网络、计算、存储、应用核心能力为一体的开放平台，就近提供最近端服务": 755,
    "基于 WebGL 加速的开放源代码 JavaScript 机器学习库": 756,
    "基于一个流线型的架构，使用深度可分离的卷积": 757,
    "基于流线型架构的轻量级深层神经网络": 758,
    "基于浏览器运行已训练的模型": 759,
    "基于现有模型构建 Interpreter": 760,
    "基于现有的模型进行继续训练": 761,
    "基于适应性低阶矩估计": 762,
    "基础模型的各项参数变量不会被新的训练修改数据": 763,
    "基础硬件控制能力展示": 764,
    "增加一个事件的检测函数": 765,
    "处理媒体应用程序": 766,
    "处理简单的数据": 767,
    "多媒体框架，用于后端处理任务": 768,
    "多种编程语言": 769,
    "多种编程语言包括Python, C++, Java, Swift和Javascript": 770,
    "大电流可能损坏LED和供电设备": 771,
    "大而复杂的模型": 772,
    "头信息": 773,
    "委托（Delegates）": 774,
    "子图": 775,
    "子图、算子库和共享的内存缓冲区": 776,
    "存储图像和标签的数据集": 777,
    "存储已安装软件包的名称和版本": 778,
    "存储模型权重，或者计算节点的输入和输出": 779,
    "存放Python相关程序模块": 780,
    "存放训练好的模型供开发人员复用": 781,
    "学习AI和构建应用程序": 782,
    "安全检查、身份核验与移动支付": 783,
    "安卓应用只需 1 兆左右的运行环境": 784,
    "安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB": 785,
    "安装 OpenCV 项目": 786,
    "安装 Python 包依赖项": 787,
    "安装 TensorFlow": 788,
    "安装 TensorFlow 所需的系统包": 789,
    "安装Android Studio": 790,
    "安装Python": 791,
    "安装Python包": 792,
    "安装依赖": 793,
    "安装依赖项": 794,
    "安装包是不同的": 795,
    "安装和升级 pip3": 796,
    "安装的 TensorFlow 版本必须与正在使用的 JetPack 版本一致": 797,
    "安装相应的依赖包": 798,
    "完全基于 JavaScript 从头开发、训练和部署模型": 799,
    "完成分类任务": 800,
    "官方已经停止维护": 801,
    "官方推荐": 802,
    "定义的神经元网络层与层之间的关系较为随意": 803,
    "定义需要监视的指标": 804,
    "定位图像中的人脸位置": 805,
    "实例化tf.sequential对象、添加输入层、添加输出层": 806,
    "实时识别照相机所拍摄的花卉": 807,
    "实现人体姿势估计": 808,
    "实现花卉识别 app": 809,
    "实现识别花卉模型": 810,
    "室内避开障碍物": 811,
    "对 SIMD 指令功能特别有益": 812,
    "对val_ds中的每个图像x应用normalization_layer，同时保留对应的标签y": 813,
    "对图像数据进行归一化处理": 814,
    "对手写数字的图像进行分类": 815,
    "对数据降维": 816,
    "对模型的权重产生更一致且变化较小的渐变更新": 817,
    "对现有 CPU 平台的支持": 818,
    "对训练图像进行旋转以增加数据多样性": 819,
    "对训练图像进行水平翻转以增加数据多样性": 820,
    "对输入图像进行预处理": 821,
    "对随机目标函数执行一阶梯度优化的算法": 822,
    "导入 TensorFlow Lite 库": 823,
    "导致每个时期的梯度更新数量较少": 824,
    "将 NPM 模块转换为在线可以引用的免费服务": 825,
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API": 826,
    "将 TensorFlow 模型转换为 TFLite 文件格式": 827,
    "将 TensorFlow 模型转换为 TFLite 格式": 828,
    "将 TensorFlow 模型转换为 TensorFlow Lite 格式": 829,
    "将 TensorFlow 模型转换为方便解释器使用的格式": 830,
    "将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能": 831,
    "将GPIO21设置为输出模式": 832,
    "将Keras模型保存为SavedModel格式": 833,
    "将Keras模型转换为TFLite模型": 834,
    "将SavedModel转换为TFLite兼容格式": 835,
    "将SavedModel转换为TFLite模型": 836,
    "将SavedModel转换为TensorFlow Lite兼容格式": 837,
    "将TensorFlow模型转换为轻量级格式": 838,
    "将三维张量展开到1维以便传入Dense层": 839,
    "将人脸编码列表与候选编码进行比较，查看是否匹配": 840,
    "将前一层的输出平铺到一个向量中": 841,
    "将原始图像调整到模型输入大小": 842,
    "将原始数据转变为TensorFlow可读的张量格式": 843,
    "将图片分类到1000类": 844,
    "将外设操作视为文件读写": 845,
    "将大规模内存操作放置在其回调中执行": 846,
    "将彩色图像转换为灰度图像，检测人脸并在边界周围绘制矩形": 847,
    "将所有图像加载到一个模型需要的特定的大小": 848,
    "将模型加载到内存中": 849,
    "将模型嵌入到二进制文件中，这样就可以在设备上运行和部署模型": 850,
    "将模型文件拷贝到 assets 目录下": 851,
    "将模型显示在浏览器中": 852,
    "将模型输出概率与类别标签关联": 853,
    "将模型输出转换为概率分布": 854,
    "将特征转换为每个图像对应一个1280元素向量": 855,
    "将网络的每一层简单的叠在一起": 856,
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型": 857,
    "将镜像写入microSD卡": 858,
    "将需要的层按顺序写在一个列表里，然后将列表作为sequential()函数的输入": 859,
    "小一点的模型": 860,
    "已经训练好的分类器（面部，眼睛，微笑等）": 861,
    "常开触点": 862,
    "常开触点和常闭触点": 863,
    "常见的移动/嵌入式平台": 864,
    "常闭触点": 865,
    "应对快速变化需求的软件开发模式": 866,
    "应用于树莓派的GPIO控制库函数，由Gordon Henderson所编写维护": 867,
    "应用深度学习算法的一种实践应用": 868,
    "应用程序在边缘侧发起，产生更快的网络服务响应，满足行业在实时业务、应用智能、安全与隐私保护等方面的基本需求": 869,
    "底层 Core API 和最高级的 Layers API": 870,
    "度量模型的最后一层产生的概率分布与标签给出的概率分布之间的误差": 871,
    "廉价且周边设备多": 872,
    "延迟一秒钟": 873,
    "延迟较低": 874,
    "建议使用脚本代码": 875,
    "建议在使用之前仔细阅读相关文档，并确保采取适当的安全措施": 876,
    "建议最小采用 64 GB UHS-1 卡": 877,
    "开关去抖": 878,
    "开关抖动": 879,
    "开发 Android 应用": 880,
    "开发依赖": 881,
    "开箱即用的开发库，开发者无需花精力去编写基础复杂的数学问题": 882,
    "引入优化以减小二进制文件的大小和提高性能": 883,
    "引用 Model 的内存缓冲区的一片区域，提高内存效率": 884,
    "张量": 885,
    "张量(Tensor)": 886,
    "张量形状是 (image_height, image_width, color_channels)": 887,
    "归一化操作": 888,
    "当压力撤销时电路恢复": 889,
    "当压力施压时电路接通": 890,
    "形状为[null, 10]的张量": 891,
    "形状为[null, 28, 28, 1]的张量": 892,
    "形状是 (224,224, 3)": 893,
    "微调": 894,
    "微调过程": 895,
    "微调预训练模型的顶层权重": 896,
    "必须在开机前先装上去，系统才能识别": 897,
    "快速启动": 898,
    "快速启动深度学习推理演示": 899,
    "快速启动，能够将模型直接映射到内存中，同时有一个静态执行计划": 900,
    "忽略时理论上每按下一次开关会输出一次": 901,
    "忽略由于开关抖动引起的小于": 902,
    "恢复训练": 903,
    "手写数字识别": 904,
    "手势识别项目": 905,
    "打乱数据集": 906,
    "打乱数据集中数据顺序": 907,
    "打乱数据顺序，创建特征向量和标签向量，转换为张量格式，进行归一化操作": 908,
    "打开现有 Android Studio 项目": 909,
    "打开项目图标": 910,
    "执行TensorFlow Lite模型的推理": 911,
    "执行一个函数并清除所有创建的中间张量": 912,
    "执行推理": 913,
    "执行最终的分类": 914,
    "执行模型推理": 915,
    "执行模型推理过程": 916,
    "执行模型文件在输入数据上定义的运算符，输出推理结果": 917,
    "执行模型转换过程": 918,
    "批次大小": 919,
    "拷贝模型和标签文件到assets目录": 920,
    "指定 Keras H5 模型文件的绝对路径": 921,
    "指定从哪个层开始进行微调的参数": 922,
    "指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录": 923,
    "指定含有 TensorFlow 1.x 或者 2.0 使用 tf.keras model 生成 HDF5 文件的绝对路径目录": 924,
    "指定含有 TensorFlow 1.x 或者 2.x SavedModel 的目录": 925,
    "指定引脚编号系统": 926,
    "指定输出文件的绝对路径": 927,
    "损失函数": 928,
    "损失函数为categorical_crossentropy": 929,
    "损失函数使用SparseCategoricalCrossentropy": 930,
    "接受 TFLite 模型": 931,
    "控制GPIO引脚": 932,
    "控制LED灯": 933,
    "控制LED灯的亮暗": 934,
    "控制外部硬件设备": 935,
    "控制树莓派的GPIO": 936,
    "控制迁移学习中微调的起始层": 937,
    "推理过程": 938,
    "推理速度提高了30%": 939,
    "描述构建和运行示例所需的依赖项": 940,
    "提供 5V⎓2A 的高品质电源为开发者套件供电": 941,
    "提供了各种库和工具，使编程更加方便": 942,
    "提供了大量方便的工具，例如权重初始化，模型序列化，训练监测，可迁移性和安全检查": 943,
    "提供低级的机器学习构建模块和高级的类似 Keras 的 API 来构建神经网络": 944,
    "提供多种语言的 API": 945,
    "提供简单的 API 用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型": 946,
    "提供经过充分认证的模型": 947,
    "提供训练好的模型，开发人员可以复用这些已经训练好且经过充分认证的模型": 948,
    "提供转换工具压缩模型，进行算子融合并生成代码": 949,
    "提供预训练模型用于图像分类、对象检测、姿势估计、文本恶意检测等": 950,
    "提问或分享项目": 951,
    "提高了用户的体验": 952,
    "提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练": 953,
    "搭建电路原型": 954,
    "摄像头预捕获的图像宽度、高度、窗口显示的图像宽度、高度、捕获帧率、是否旋转图像": 955,
    "操作(Ops)": 956,
    "支持 Android 神经网络 API（Android NN API)": 957,
    "支持 GPU 硬件加速": 958,
    "支持 GPU 硬件加速，可以运行在 Node.js 或浏览器环境中": 959,
    "支持1080p30, 720p60以及640 × 480p90视频录像": 960,
    "支持Linux SoC": 961,
    "支持像素缩放和数据增强": 962,
    "支持图像大小调整和批量处理": 963,
    "支持大规模的模型训练和各种环境的部署": 964,
    "支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析": 965,
    "支持将文件映射到内存中，直接进行读取和解释，不需要额外解析": 966,
    "支持微控制器(MCU)": 967,
    "支持微控制器(MCU)，应用于 IoT 领域": 968,
    "支持算子优化和常见的编译优化": 969,
    "支持算子优化和常见的编译优化，比如算子融合、常数折叠或无用代码删除等": 970,
    "支持自定义输入形状和是否包含顶层分类器": 971,
    "支持设备端机器学习推断": 972,
    "支持设备端机器学习推断，延迟较低，并且二进制文件很小": 973,
    "支持量化原生支持": 974,
    "支持量化的原生支持": 975,
    "支持预装驱动程序的RPi相机": 976,
    "改造模型": 977,
    "敏捷开发": 978,
    "教育": 979,
    "数据图像的采集、模型的训练、参数的调整、模型文件生成、网页端部署": 980,
    "数据规范化和转换为张量类型": 981,
    "数据转换": 982,
    "数据预处理": 983,
    "整个安装需要两个小时才能完成": 984,
    "文字处理": 985,
    "文本处理": 986,
    "易于设置和使用，兼容许多配件": 987,
    "是一个线性堆叠layers的模型": 988,
    "显示每个类别的准确度": 989,
    "显示混淆矩阵": 990,
    "智能读码机": 991,
    "智能质检一体机": 992,
    "更新可视化元素": 993,
    "更新数据慢可以考虑更换源": 994,
    "更谨慎地控制内存何时回收": 995,
    "更轻量，二进制文件的大小约为 1 MB（针对 32 位 ARM build）": 996,
    "更适合于边缘设备部署": 997,
    "最后的神经网络层": 998,
    "最大池化层": 999,
    "最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口": 1000,
    "有助于避免因错误的样本而改向错误的方向": 1001,
    "有经验的开发者": 1002,
    "服务器和移动端的部署": 1003,
    "未满足的对等依赖 seedrandom@~": 1004,
    "机器学习和计算机视觉应用": 1005,
    "杜邦线公对母": 1006,
    "构建CNN模型": 1007,
    "构建Tensorflow.js模型来识别手写数字": 1008,
    "构建和运行mnist代码": 1009,
    "构建和运行机器学习模型": 1010,
    "构建小型移动机器人、人脸签到打卡、口罩识别、智能门锁、智能音箱等复杂 AI 系统": 1011,
    "构建工具": 1012,
    "构建工具用于编写更大的程序": 1013,
    "构成检测目标的相邻矩形的最小个数": 1014,
    "查看开发板系统信息": 1015,
    "查看树莓派的GPIO引脚信息": 1016,
    "标准算子": 1017,
    "树莓派": 1018,
    "树莓派4B的18号引脚": 1019,
    "树莓派GPIO": 1020,
    "树莓派接口": 1021,
    "树莓派的21号引脚": 1022,
    "树莓派系统": 1023,
    "树莓派系统升级": 1024,
    "树莓派通用输入/输出接口（GPIO）": 1025,
    "核心板可拆的设计，核心板的大小只有70 x 45 mm": 1026,
    "核心运行时": 1027,
    "格式修改、显示驱动程序协调和数据处理": 1028,
    "格式化microSD卡": 1029,
    "梯度下降": 1030,
    "检测人脸": 1031,
    "检测关键身体部位的位置": 1032,
    "检测面部特征点": 1033,
    "模型": 1034,
    "模型优化": 1035,
    "模型优化工具": 1036,
    "模型优化工具包": 1037,
    "模型优化算法": 1038,
    "模型可以跟 Python 等其他语言模型进行互转": 1039,
    "模型和层": 1040,
    "模型大小只有20KB左右": 1041,
    "模型对象和保存路径": 1042,
    "模型执行流图": 1043,
    "模型文件和标签文件": 1044,
    "模型文件的一种": 1045,
    "模型编译": 1046,
    "模型训练": 1047,
    "模型评估": 1048,
    "模型预测": 1049,
    "每一列代表预测值，每一行代表实际的类别": 1050,
    "比 CPU 执行更快的浮点矩阵运算": 1051,
    "池化层": 1052,
    "汽车油耗（MPG）": 1053,
    "汽车的功率（Horsepower）": 1054,
    "没有操作系统": 1055,
    "注重实时性，内存高效": 1056,
    "测试Python开发环境并查看当前的Python版本": 1057,
    "测试的软件包、webpack或Babel": 1058,
    "浏览器可以很好可视化机器训练过程，同时浏览器可调用设备的摄像头、麦克风等增加机器学习的应用场景": 1059,
    "浏览器可以很好可视化机器训练过程，同时浏览器可调用设备的摄像头、麦克风等增加机器学习的应用场景，让机器学习跟接近用户": 1060,
    "混淆矩阵": 1061,
    "添加tensorflow-lite依赖": 1062,
    "清华源": 1063,
    "清理GPIO引脚的设置": 1064,
    "清除张量或变量并释放其GPU内存": 1065,
    "清除所有创建的中间张量并释放它们的GPU内存": 1066,
    "激活、设置为输出状态、写入1使其输出高电压": 1067,
    "灵活的架构可以将模型部署到桌面、服务器或移动设备中的 CPU 或 GPU 上": 1068,
    "点亮LED灯": 1069,
    "热词唤醒": 1070,
    "爱奇艺": 1071,
    "版本变化后 API 函数会改变": 1072,
    "版本变化后API函数会改变": 1073,
    "物体检测、人脸识别、图像分割等视觉任务": 1074,
    "物理引脚Broad编号": 1075,
    "特别为各种端侧设备优化的算子库": 1076,
    "瓶颈层": 1077,
    "生成 HDF5 文件的绝对路径目录": 1078,
    "生成SavedModel": 1079,
    "生成一个批次一个批次的图片，以生成器的形式给模型训练": 1080,
    "生成一个批次的图片，以生成器的形式给模型训练": 1081,
    "生成批次的图片数据用于模型训练": 1082,
    "用于 5V 电源输入": 1083,
    "用于 flower_classification 项目": 1084,
    "用于处理或存储数据": 1085,
    "用于实现网页的交互功能": 1086,
    "用于工具的配置中心": 1087,
    "用于操作张量数据的线性代数和机器学习运算": 1088,
    "用于构建网页的用户界面": 1089,
    "用于监督学习，展示多个类别是否有混淆": 1090,
    "用于训练模型": 1091,
    "用作启动设备和主存储器": 1092,
    "用到的算子索引，以及输入输出用到的 Tensor 索引": 1093,
    "用张量的值进行初始化，但其值是可变的": 1094,
    "用户在自己的工作台中使用 TensorFlow API 构造 TensorFlow 模型": 1095,
    "用来设置GPIO管脚，可以用来读写GPIO管脚，甚至可以在Shell脚本中使用来达到控制GPIO管脚的目的": 1096,
    "用来连接 DP 屏幕": 1097,
    "由 schema.fbs 文件使用 FlatBuffers 定义": 1098,
    "由jupyter软件自动生成": 1099,
    "由于可运行于浏览器，减少服务器的运算，提高服务器资源利用，增强客户端响应运算结果的速度": 1100,
    "由于浏览器的 WebGL 可调用 GPU，所以 Tensorflow.js 会使用 GPU 加速模型的运算，提高运算效率": 1101,
    "电信号从低电平到高电平，或从高电平到低电平状态的改变": 1102,
    "电路": 1103,
    "电阻": 1104,
    "登录 Jetson Nano": 1105,
    "目前有130个左右": 1106,
    "目前有130个左右，它与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化": 1107,
    "直接串联3.3V电源会产生大电流": 1108,
    "直接在 Objective-C 代码中使用 C API": 1109,
    "直接更新树莓派系统": 1110,
    "直接部署或用于迁移学习": 1111,
    "直流桶式插座": 1112,
    "相比 Protocol Buffer 有更高的性能和更小的大小": 1113,
    "硬件加速代理(Hardware accelerator delegate)": 1114,
    "确认 CUDA 已经被正常安装": 1115,
    "离线语音识别": 1116,
    "科沃斯扫地机器人": 1117,
    "移动端语音识别": 1118,
    "端侧机器学习": 1119,
    "第一个卷积层": 1120,
    "第二、三卷积层": 1121,
    "简化图像预处理和模型输出处理": 1122,
    "简化图像预处理和输出处理": 1123,
    "简单的姿态检测模型": 1124,
    "简单的线性回归的实验": 1125,
    "算子实现": 1126,
    "算子库(Op kernels)": 1127,
    "算子库(Op kernels)和硬件加速代理(Hardware accelerator delegate)": 1128,
    "精度达到98%": 1129,
    "给脸部编码": 1130,
    "编译 OpenCV": 1131,
    "编译Python模块": 1132,
    "缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响": 1133,
    "缩减版的 TensorFlow，简化了算子集，也缩小了运行库": 1134,
    "缩短开发周期": 1135,
    "网易": 1136,
    "网络环境较差时可以考虑更换源": 1137,
    "能够利用各种硬件加速": 1138,
    "能够执行完整全面的反向传播": 1139,
    "脚本标签": 1140,
    "自动将视频和对话中的语言转化为文字": 1141,
    "自动连接到具有一个隐藏单元的dense层": 1142,
    "花卉数据集中的图片": 1143,
    "花卉识别 app": 1144,
    "花卉识别模型": 1145,
    "英伟达官方或开源社区": 1146,
    "获取Jetson平台信息": 1147,
    "获取score中的最大值索引": 1148,
    "获取分类结果的概率": 1149,
    "获取图像数据、处理图像、调用姿势估计函数、绘制关键点": 1150,
    "获取张量数据": 1151,
    "获取指向张量的指针": 1152,
    "获取有趣项目": 1153,
    "衡量所有预测中正确预测的百分比": 1154,
    "观测开关去抖效果": 1155,
    "视频中的AR效果": 1156,
    "解决JavaScript内存回收问题": 1157,
    "解决pip安装时的哈希不匹配问题": 1158,
    "解决特定问题的机器学习网络": 1159,
    "解决跨域问题": 1160,
    "解释器、转换器、算子库、硬件加速代理": 1161,
    "解释输出": 1162,
    "计算已知人脸和未知人脸特征向量的距离": 1163,
    "计算机视觉应用": 1164,
    "计算能力不高，勉强可以使用一些小规模、并且优化过的网络进行推理，训练的话还是不够用": 1165,
    "计算节点": 1166,
    "计算预测结果的softmax概率": 1167,
    "让输入输出映射到0-1之间，保证后期更有效地训练": 1168,
    "训练 MNIST 分类器": 1169,
    "训练分类器查看数千个图像及其标签": 1170,
    "训练后量化": 1171,
    "训练好的模型": 1172,
    "训练数据和测试数据": 1173,
    "训练时从数据集中的不同类中随机选出一定数量的图像": 1174,
    "训练期间将不更新预训练网络的权重，只在 MobileNet V2基础模型上训练了几层": 1175,
    "训练期间需要更多的内存": 1176,
    "训练模型": 1177,
    "训练模型并记录训练和验证准确性/损失": 1178,
    "训练集": 1179,
    "记录训练日志和可视化训练过程": 1180,
    "记录训练过程中的指标和计算图": 1181,
    "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，对量化特别有益": 1182,
    "设置 OpenCV 的内容、位置和方式": 1183,
    "设置 model.trainable = False": 1184,
    "设置GPIO引脚编号模式": 1185,
    "设置aaptOptions防止模型压缩": 1186,
    "设置model.trainable = False": 1187,
    "设置上拉电阻": 1188,
    "设置为100表示从第100层开始微调": 1189,
    "设置人脸检测模型，'hog'在CPU上运行更快，'cnn'更准确但需要GPU加速": 1190,
    "设置前100层为不可训练": 1191,
    "设置在训练中，基础模型的各项参数变量不会被新的训练修改数据": 1192,
    "设置对图像进行多少次上采样以查找人脸": 1193,
    "设置引脚为输入或输出模式": 1194,
    "设置输入张量值": 1195,
    "设置过大会导致Jetson Nano开发板内存溢出": 1196,
    "评估指标为accuracy": 1197,
    "评估指标为准确率(acc)": 1198,
    "评估模型": 1199,
    "评估训练有素的模型的性能": 1200,
    "识别图像里的空间模式，例如线条和物体局部": 1201,
    "识别花卉图片": 1202,
    "识别若干关键词的语音识别模型": 1203,
    "语音功能部署": 1204,
    "语音识别": 1205,
    "读取传感器数据，控制 LED 等外部设备": 1206,
    "读取输出张量值": 1207,
    "调整大小、裁剪、旋转和归一化图像": 1208,
    "调整数据集形状": 1209,
    "调整输入图像大小以匹配模型输入要求": 1210,
    "调用 Python API 或命令行进行转换": 1211,
    "调用 TensorFlow Lite 解释器的方式：try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) { interpreter.run(input, output); }": 1212,
    "调用CSI摄像头和USB摄像头": 1213,
    "调用model.fit方法进行训练": 1214,
    "调用不同的硬件加速器比如 GPU 进行执行": 1215,
    "跨平台运行，包括 Android、iOS 以及基于 Linux 的 IoT 设备和微控制器": 1216,
    "转换 SavedModel 格式模型": 1217,
    "转换 concrete functions": 1218,
    "转换 tf.keras 模型": 1219,
    "转换为 TensorFlow Lite 模型": 1220,
    "转换和运行 TensorFlow 模型的工具": 1221,
    "转换图像数据类型为tf.float32": 1222,
    "转换数据": 1223,
    "转换模型": 1224,
    "软件源配置文件": 1225,
    "软链接": 1226,
    "轻量化和针对移动端及IoT设备端": 1227,
    "轻量级": 1228,
    "轻量级，在32 b 安卓平台下，编译核心运行时得到的库大小只有100 KB 左右": 1229,
    "输入层": 1230,
    "输出层": 1231,
    "输出数量等于类别数并使用softmax激活函数": 1232,
    "输出是一个三维的张量，形状描述了(height, width, channels)": 1233,
    "输出的通道数量取决于声明层时的filters参数": 1234,
    "输出通道数为32": 1235,
    "输出通道数为64": 1236,
    "输出通道数量由filters参数决定": 1237,
    "边做边学的理想工具": 1238,
    "边缘": 1239,
    "边缘操作": 1240,
    "边缘计算": 1241,
    "边缘计算设备": 1242,
    "迁移学习": 1243,
    "运行TFLite推理并获取输出概率": 1244,
    "运行功率仅为 5 瓦": 1245,
    "运行各种深度学习模型": 1246,
    "运行在 Node.js 或浏览器环境中": 1247,
    "运行已有的 Python 版 TensorFlow 模型": 1248,
    "运行服务监听的IP地址、端口、notebooks内核目录、浏览器开关设置": 1249,
    "运行模型推理": 1250,
    "返回图像中每张人脸的128维人脸编码": 1251,
    "返回张量数据的副本": 1252,
    "返回的是数据的副本而非引用": 1253,
    "进行VNC连接": 1254,
    "进行内存清理工作，防止内存泄露": 1255,
    "远程桌面访问Jetson Nano": 1256,
    "连接LED灯的正极": 1257,
    "连接LED灯的负极形成回路": 1258,
    "连接其他电子设备": 1259,
    "连接按键的一个引脚": 1260,
    "连接显示器、键盘和鼠标或通过SSH/VNC远程访问": 1261,
    "连接树莓派和面包板上的元件": 1262,
    "适用于多个平台": 1263,
    "适用于多个平台，提供了一个简单的 API": 1264,
    "适用于移动和嵌入式设备的轻量级推理框架": 1265,
    "选择模型": 1266,
    "选择模型、转换模型、部署到设备、优化模型": 1267,
    "选择模型，转换模型，部署到设备，优化模型": 1268,
    "逐步加载单个数据集的图像": 1269,
    "通过 pip 安装": 1270,
    "通过GPIO控制展示基础硬件控制能力": 1271,
    "通过script标签引入index.js": 1272,
    "通过下载源代码来安装，使用GIT工具下载代码，然后编译安装": 1273,
    "通过利用 WebGL 在 GPU 上执行计算大幅提高了速度": 1274,
    "通过脚本标签（script tags）或从 yarn（或者 NPM）安装并使用 Parcel，WebPack 或 Rollup 等工具构建工程": 1275,
    "通过计算每个滑动窗口的最大值来缩减卷积结果的大小": 1276,
    "通过许多正负样例中训练得到cascade方程，然后将其应用于其他图片": 1277,
    "遍历所有样本50次": 1278,
    "郁金香(tulips)、玫瑰(roses)、浦公英(dandelion)、向日葵(sunflowers)、雏菊(daisy)": 1279,
    "部署TensorFlow Lite模型": 1280,
    "部署到设备": 1281,
    "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上": 1282,
    "配置build.gradle文件": 1283,
    "配置文件": 1284,
    "配置模型的优化器和损失函数": 1285,
    "配置项目依赖": 1286,
    "采用更小的模型格式，并提供了方便的模型转换器": 1287,
    "采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式": 1288,
    "采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型": 1289,
    "释放张量的GPU内存": 1290,
    "量化": 1291,
    "针对移动设备构建": 1292,
    "错误的连接和编程可能会导致设备损坏或故障": 1293,
    "镜像": 1294,
    "防止 Android 在生成应用程序二进制文件时压缩 TensorFlow Lite 模型文件": 1295,
    "防止应用程序中的内存泄漏": 1296,
    "阻塞函数，会阻塞程序执行直到检测到一个边沿": 1297,
    "阿里、清华等": 1298,
    "降低卷积层对位置的敏感": 1299,
    "降低存储器访问成本": 1300,
    "降低权重的精确表示，并且可选的降低存储和计算的激活值": 1301,
    "降低权重的精确表示，降低存储和计算的激活值": 1302,
    "降低用于读取和存储中间激活值的存储器访问成本": 1303,
    "降低移动端及IoT设备端的深度学习技术门槛": 1304,
    "限流电阻": 1305,
    "随机打乱数据集": 1306,
    "随着层越来越高，这些功能越来越多地针对训练模型的数据集": 1307,
    "需要root权限": 1308,
    "需要使用GStreamer读取视频流": 1309,
    "需要大约两个半小时": 1310,
    "需要小心谨慎使用": 1311,
    "需要成功配置好 CUDA": 1312,
    "需要更多灵活性和控制时使用": 1313,
    "需要注意版本变化": 1314,
    "需要设置VNC密码和启用自动登录": 1315,
    "需要配置 proxy 或使用国内镜像以获取 SDK 和 gradle 编译环境": 1316,
    "需要重启树莓派": 1317,
    "需要高准确率": 1318,
    "静态图片分辨率为3280 × 2464": 1319,
    "面包板": 1320,
    "页面的基本结构，包含div标签、UI元素和JavaScript代码插入": 1321,
    "项目的清单文件": 1322,
    "预加载了ImageNet训练权重的深度学习模型": 1323,
    "预处理模型输入和后处理模型输出": 1324,
    "预测汽车油耗效率": 1325,
    "预测汽车油耗（MPG）": 1326,
    "预测汽车的油耗效率 MPG": 1327,
    "预测结果": 1328,
    "预训练模型和全连接的分类器": 1329,
    "预训练模型将忘记它学到的东西": 1330,
    "首次打开项目时": 1331,
    "验证损失高于训练损失，可能存在过拟合": 1332,
    "验证集": 1333,
    "高性能": 1334,
    "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）": 1335,
    "默认安装 JetPack 安装了对应的 OpenCV": 1336
  },
  "id_to_entity": {
    "0": "--enable_v1_converter",
    "1": "--keras_model_file",
    "2": "--no-cache-dir",
    "3": "--output_file",
    "4": "--output_file, --saved_model_dir, --keras_model_file, --enable_v1_converter",
    "5": "--saved_model_dir",
    "6": "-D WITH_QT=OFF 禁用了 Qt5 支持",
    "7": ".tflite",
    "8": "/dev目录存储所有设备文件或特殊文件",
    "9": "/etc/apt/sources.list",
    "10": "/opt/python",
    "11": "/sys/class/gpio目录下的端口文件",
    "12": "/usr/bin/python",
    "13": "0.2s的响应时间",
    "14": "1000",
    "15": "128核 NVIDIA Maxwell 架构的 GPU",
    "16": "14个引脚用于其他功能",
    "17": "155层",
    "18": "155层网络",
    "19": "2.0.0",
    "20": "2.3.0",
    "21": "2017年底",
    "22": "26个引脚可以用作数字输入或输出",
    "23": "330欧姆电阻",
    "24": "3个 Conv2D 和 2个 MaxPooling2D 层",
    "25": "40 针 GPIO 扩展接口",
    "26": "40个 GPIO 引脚",
    "27": "40个GPIO引脚",
    "28": "4GB 的内存",
    "29": "512",
    "30": "5500",
    "31": "5个节点",
    "32": "5个节点的输出层",
    "33": "6",
    "34": "64位四核的 ARM Cortex-A57 CPU",
    "35": "800万像素",
    "36": "800万像素、感光芯片为索尼IMX219",
    "37": "9",
    "38": "<!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">",
    "39": "<html> <body> <h4>TFJS example<hr/></h4> <div id=\"micro-out-div\">TensorFlow.js Test</div> <script src=\"./index.js\"> </script> </body> </html>",
    "40": "<script>标签",
    "41": "@tensorflow/tfjs",
    "42": "@tensorflow/tfjs-vis",
    "43": "AC8265",
    "44": "ARM Cortex-A57 CPU、NVIDIA Maxwell GPU",
    "45": "ARM Cortex-A72 CPU",
    "46": "AR效果",
    "47": "Adam",
    "48": "Adam优化器",
    "49": "Android",
    "50": "Android Studio",
    "51": "Android 应用",
    "52": "Android 开发人员",
    "53": "Android 开发者使用 JCenter Bintray 的 TFLite AAR",
    "54": "Android 设备",
    "55": "Android部署",
    "56": "B02版本有两路",
    "57": "BATCH_SIZE",
    "58": "BCM编号",
    "59": "BCM编号方式",
    "60": "BCM编号模式和物理引脚Broad编号模式",
    "61": "Broadcom针脚号，也即是通常称的GPIO",
    "62": "C",
    "63": "C#",
    "64": "C++",
    "65": "C++ 和 Python 提供的 TensorFlow Lite API",
    "66": "CNN",
    "67": "CSI 相机接口",
    "68": "CSI摄像头",
    "69": "CSI端口",
    "70": "ClassifierFloatMobileNet类",
    "71": "Classifier类",
    "72": "CocoaPods for Swift or Objective-C",
    "73": "Conv2D",
    "74": "Conv2D, MaxPooling2D, Flatten, Dense等层",
    "75": "Core API",
    "76": "DeepLearning.js",
    "77": "Dense",
    "78": "Display Port 接口",
    "79": "Etcher",
    "80": "Ethernet 有线网络",
    "81": "Face Recognition库",
    "82": "False",
    "83": "FlatBuffers",
    "84": "FlatBuffers 格式",
    "85": "GND",
    "86": "GPIO.cleanup()方法",
    "87": "GPIO.setmod()",
    "88": "GPIO.setup()",
    "89": "GPIO.setup()方法",
    "90": "GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP)",
    "91": "GPIO21",
    "92": "GPIO口",
    "93": "GPIO库",
    "94": "GPIO库、I2C库、SPI库、UART库和软件PWM库",
    "95": "GPIO库、I2C库、SPI库、UART库和软件PWM库等",
    "96": "GPIO引脚",
    "97": "GPU",
    "98": "GPU 委托",
    "99": "GPU代理",
    "100": "GStreamer",
    "101": "GStreamer管道",
    "102": "GlobalAveragePooling2D",
    "103": "Google",
    "104": "Google Assistant",
    "105": "Google Assistant，Google Photos，Uber，Airbnb，网易，爱奇艺和 WPS 等",
    "106": "Google Edge TPU Coral Dev Board",
    "107": "Google Photos",
    "108": "Google 内部用于计算机视觉场景的解决方案",
    "109": "Google 尝试简化 TensorFlow 并在移动设备上运行的项目",
    "110": "Gradle 同步",
    "111": "HDMI 接口",
    "112": "HIGH电平",
    "113": "HTML 文件",
    "114": "HTML文件、JS文件和配置文件",
    "115": "Haar特征的cascade分类器",
    "116": "Hello AI World",
    "117": "I2C接口(SCL、SDA)，SPI接口（MISO、MOSI、CLK、CS片选信号SPICE0_N），UART串口接口（TXD、RXD），PWM接口以及普通GPIO口",
    "118": "IMAGE_WIDTH, IMAGE_HEIGHT, testData, testxs, labels, preds",
    "119": "IMX219模组",
    "120": "ImageDataGenerator",
    "121": "ImageProcessor",
    "122": "Intel Neural Compute Stick 2",
    "123": "IoT领域",
    "124": "Java",
    "125": "Java 或 C++ API 执行 TensorFlow Lite 推理",
    "126": "JavaScript",
    "127": "JavaScript 语言版本的扩展",
    "128": "JetBot",
    "129": "JetPack SDK",
    "130": "Jetson",
    "131": "Jetson Community Projects",
    "132": "Jetson Developer Kits",
    "133": "Jetson Nano",
    "134": "Jetson Nano 开发板",
    "135": "Jupyter Notebook",
    "136": "Jupyter Notebook 的全面升级",
    "137": "Jupyter Notebook、文本编辑器、终端以及各种个性化组件",
    "138": "Jupyter lab",
    "139": "JupyterLab",
    "140": "Jupyter的配置文件",
    "141": "Keras H5",
    "142": "Keras Model 和 SavedModel",
    "143": "Keras 模型",
    "144": "Keras模型",
    "145": "Keras的模型定义方式",
    "146": "LED",
    "147": "LED灯",
    "148": "LED灯、限流电阻、GPIO21、GND",
    "149": "LOW电平",
    "150": "Layers API",
    "151": "Layers API 和 Core API",
    "152": "Layers API和Core API",
    "153": "Linux",
    "154": "Linux 平台",
    "155": "Linux 开发环境",
    "156": "Live Caption",
    "157": "MCU",
    "158": "MIPI",
    "159": "MIPI CSI-2 摄像头接口",
    "160": "MIPI的相机串行接口（CSI）端口",
    "161": "MIPI联盟发起的为移动应用处理器制定的开放标准",
    "162": "MNIST数据集",
    "163": "MaxPooling2D",
    "164": "Micro USB 接口",
    "165": "Micro-USB 接口",
    "166": "MnistData",
    "167": "MobileNet",
    "168": "MobileNet V2",
    "169": "MobileNetV2",
    "170": "MobileNets_v2",
    "171": "NVIDIA Jetson Nano",
    "172": "NVIDIA Jetson Nano 开发板",
    "173": "NVIDIA Jetson论坛",
    "174": "Node 和 Python 一样都是使用 C++编写的环境，所以在 Node 环境进行运算的速度目前与 Python 速度不相上下",
    "175": "OCR处理",
    "176": "Object C",
    "177": "OpenCV",
    "178": "OpenCV 安装",
    "179": "OpenCV 安装脚本",
    "180": "OpenCV 编译",
    "181": "OperatorCode",
    "182": "PCB板上针脚的物理位置对应的编号（1~40）",
    "183": "Parcel",
    "184": "Parcel, WebPack 或 Rollup",
    "185": "Pi 4B与Pi v3+",
    "186": "PoseNet模型",
    "187": "PoseNet示例应用程序",
    "188": "Post training quantization 和 Quantization-aware training",
    "189": "Python",
    "190": "Python 2.7",
    "191": "Python API",
    "192": "Python API 调用方式",
    "193": "Python GPIO编程",
    "194": "Python 代码片段",
    "195": "Python 包管理",
    "196": "Python 官方集成的包管理工具",
    "197": "Python 官网",
    "198": "Python 源码包",
    "199": "Python安装",
    "200": "Python开发环境",
    "201": "Python模块",
    "202": "Python相关程序模块会拷贝到/opt/python",
    "203": "Python程序",
    "204": "Quantization-aware training",
    "205": "RPI.GPIO库",
    "206": "RandomFlip",
    "207": "RandomRotation",
    "208": "Raspberry Camera V2",
    "209": "Raspberry Pi",
    "210": "Raspberry Pi 4",
    "211": "Raspberry Pi、Arducam等常见的相机模块",
    "212": "Raspbian软件仓库镜像",
    "213": "ResNet",
    "214": "SD Memory Card Formatter",
    "215": "SavedModel",
    "216": "SavedModel 和 Keras Sequential",
    "217": "SavedModel 和 Keras Sequential 两种模型导出方法和格式",
    "218": "Sequential模型",
    "219": "SparseCategoricalCrossentropy",
    "220": "Swift",
    "221": "Swift 和 Objective-C 编写的原生 iOS 库",
    "222": "SymbolicTensor",
    "223": "TEST_DATA_SIZE",
    "224": "TF Mobile",
    "225": "TF Mobile 的经验",
    "226": "TFLite",
    "227": "TFLite model",
    "228": "TFLite 文件格式",
    "229": "TFLite 模型文件格式",
    "230": "TFLite 模型文件格式，更注重考虑实时性，内存高效",
    "231": "TFLite 模型转换器",
    "232": "TFLite 模型转换过程",
    "233": "TFLite 算子库",
    "234": "TFLite 解释器",
    "235": "TFLite 解释执行器",
    "236": "TFLite 转换器",
    "237": "TFLiteConverter",
    "238": "TFLiteConverter.from_concrete_functions()",
    "239": "TFLiteConverter.from_keras_model()",
    "240": "TFLiteConverter.from_saved_model()",
    "241": "TFLite模型",
    "242": "TFLite解释器",
    "243": "TFLite解释器和GPU代理",
    "244": "TFLite转换",
    "245": "TFMini",
    "246": "TFMini 和内部其他类似项目的很多优秀工作",
    "247": "TRAIN_DATA_SIZE",
    "248": "Tensor",
    "249": "Tensor 的主要构造函数",
    "250": "TensorBoard",
    "251": "TensorFLow-vis",
    "252": "TensorFlow",
    "253": "TensorFlow 2.x 模型",
    "254": "TensorFlow GPU 版本",
    "255": "TensorFlow GPU 版本安装",
    "256": "TensorFlow Hub",
    "257": "TensorFlow Hub 上可搜索到的模型",
    "258": "TensorFlow Lite",
    "259": "TensorFlow Lite AAR",
    "260": "TensorFlow Lite API",
    "261": "TensorFlow Lite 开发工作流程",
    "262": "TensorFlow Lite 推理",
    "263": "TensorFlow Lite 支持库",
    "264": "TensorFlow Lite 模型",
    "265": "TensorFlow Lite 模型文件",
    "266": "TensorFlow Lite 的工作流程",
    "267": "TensorFlow Lite 示例",
    "268": "TensorFlow Lite 算子库",
    "269": "TensorFlow Lite 解释器",
    "270": "TensorFlow Lite 解释器(Interpreter)",
    "271": "TensorFlow Lite 解释器(Interpreter)和 TensorFlow Lite 转换器(Converter)",
    "272": "TensorFlow Lite 解释执行器",
    "273": "TensorFlow Lite 转换器",
    "274": "TensorFlow Lite 转换器(Converter)",
    "275": "TensorFlow Lite 转换器命令行工具",
    "276": "TensorFlow Lite支持库",
    "277": "TensorFlow Lite模型",
    "278": "TensorFlow Lite解释器",
    "279": "TensorFlow 官网",
    "280": "TensorFlow 模型",
    "281": "TensorFlow 模型导出",
    "282": "TensorFlow 的 JavaScript 版本",
    "283": "TensorFlow.js",
    "284": "TensorFlow.js 中的中心数据单元，是一维或多维数组",
    "285": "TensorFlow.js 模块",
    "286": "TensorFlow.js 进行浏览器可视化的一组实用工具库",
    "287": "TensorFlow团队开发的产品",
    "288": "TensorFlow模型的序列化格式",
    "289": "TensorLabel",
    "290": "Tensorflow.js",
    "291": "Tensorflow.js 的模型可以跟 Python 等其他语言模型进行互转",
    "292": "Text, Image, Video 和 Publishers 等类别",
    "293": "Total params: 2,626,821, Trainable params: 368,837, Non-trainable params: 2,257,984",
    "294": "USB",
    "295": "USB摄像头",
    "296": "VGG",
    "297": "VNC",
    "298": "VNC Viewer",
    "299": "WPS",
    "300": "Web Server for Chrome",
    "301": "Web 开发新手",
    "302": "Webpack",
    "303": "Wiring Pi",
    "304": "Wiring Pi库",
    "305": "Wiring Pi编号",
    "306": "Wiring Pi编号、BCM编号、物理引脚Broad编号",
    "307": "Wiring Pi编号模式",
    "308": "aaptOptions",
    "309": "activation: 'relu'",
    "310": "activation: 'softmax'",
    "311": "add_event_detect()函数",
    "312": "allocate_tensors()",
    "313": "android 目录",
    "314": "base_model, Conv2D, Dropout, GlobalAveragePooling2D, Dense",
    "315": "batchSize",
    "316": "batchSize设置为512",
    "317": "batch_size",
    "318": "batch_size用于设置每批图像数量",
    "319": "bool",
    "320": "build.gradle",
    "321": "buildscript",
    "322": "callback",
    "323": "callbacks设置为fitCallbacks",
    "324": "categoricalCrossentropy",
    "325": "categorical_crossentropy",
    "326": "cdn.jsdelivr.net",
    "327": "class_names",
    "328": "classpath 'com.android.tools.build:gradle:...'",
    "329": "compare_faces函数",
    "330": "conv2d, dropout, global_average_pooling2d, dense",
    "331": "convertToTensor函数",
    "332": "converter",
    "333": "converter.convert",
    "334": "createModel()",
    "335": "daisy, dandelion, roses, sunflowers, tulips",
    "336": "data.js",
    "337": "data.js文件",
    "338": "dense层",
    "339": "dependencies",
    "340": "dispose",
    "341": "dispose和tf.tidy两种内存管理方法",
    "342": "dlib库",
    "343": "dlib这一C++图形库",
    "344": "doPrediction函数",
    "345": "epochs",
    "346": "epochs设置为10",
    "347": "face_cascade.detectMultiScale",
    "348": "face_distance函数",
    "349": "face_encodings",
    "350": "face_encodings函数",
    "351": "face_landmarks",
    "352": "face_locations",
    "353": "face_recognition",
    "354": "filters: 8",
    "355": "fine_tune_at",
    "356": "flatten层",
    "357": "flow_from_directory",
    "358": "flower_classification",
    "359": "flower_classification 项目",
    "360": "from_saved_model(), from_keras_model(), from_concrete_functions()",
    "361": "functional模型",
    "362": "get_input_details()",
    "363": "get_output_details()",
    "364": "get_tensor()",
    "365": "gpio readall命令",
    "366": "hub.KerasLayer",
    "367": "iOS",
    "368": "iOS 开发人员",
    "369": "iOS 开发者通过 CocoaPods 获取",
    "370": "import * as tf from '@tensorflow/tfjs' console.log(tf.version.tfjs) const shape = [2, 3]; // 2 rows, 3 columns const a = tf.tensor",
    "371": "import语句和TensorFlow.js测试代码",
    "372": "include_top=False",
    "373": "index",
    "374": "index.html",
    "375": "index.js",
    "376": "inputShape: [28, 28, 1]",
    "377": "inputShape为[1], units为1, useBias为true",
    "378": "interpreter",
    "379": "interpreter.get_tensor()",
    "380": "invoke()",
    "381": "jtop 命令",
    "382": "jupyter",
    "383": "jupyter_notebook_config.py",
    "384": "kernelInitializer: 'varianceScaling'",
    "385": "kernelSize: 5",
    "386": "label.txt",
    "387": "lambda x, y: (normalization_layer(x), y)",
    "388": "layers.Flatten()",
    "389": "load_image_file",
    "390": "loss: 'categoricalCrossentropy'",
    "391": "make install",
    "392": "make命令",
    "393": "maven { url '[URL]' }",
    "394": "metrics: ['accuracy']",
    "395": "microSD 卡",
    "396": "microSD 卡插槽",
    "397": "microSD卡",
    "398": "minNeighbors参数",
    "399": "mnist项目",
    "400": "mobilenetv2_1.00_224",
    "401": "model inference",
    "402": "model.compile",
    "403": "model.fit",
    "404": "model.fit()",
    "405": "model.predict()",
    "406": "model.tflite",
    "407": "model.tflite和label.txt",
    "408": "model.tflite文件",
    "409": "model.trainable = False",
    "410": "modelSummary",
    "411": "model参数",
    "412": "nano或者vi",
    "413": "nextTestBatch",
    "414": "nextTrainBatch",
    "415": "nextTrainBatch和nextTestBatch方法",
    "416": "noCompress \"tflite\"",
    "417": "normalization_layer",
    "418": "np.argmax()",
    "419": "number_of_times_to_upsample参数",
    "420": "optimizer: Adam",
    "421": "org.tensorflow:tensorflow-lite:+",
    "422": "output_details",
    "423": "package.json",
    "424": "pip",
    "425": "pip install",
    "426": "pip3",
    "427": "poolSize: [2, 2]",
    "428": "post-training quantization",
    "429": "predict()",
    "430": "print(\"button pressed!\")",
    "431": "python",
    "432": "recognizeImage方法",
    "433": "repositories",
    "434": "repositories 和 dependencies",
    "435": "saved_model_dir",
    "436": "sequential模型",
    "437": "sequential模型和functional模型",
    "438": "set_tensor()",
    "439": "showAccuracy函数",
    "440": "showConfusion函数",
    "441": "shuffle",
    "442": "shuffle用于控制批处理顺序",
    "443": "shuffle设置为true",
    "444": "softmax",
    "445": "start 目录和 finish 目录",
    "446": "strides: 1",
    "447": "strides: [2, 2]",
    "448": "string",
    "449": "target_size 参数",
    "450": "target_size用于设置图像大小",
    "451": "tensor()",
    "452": "tf.cast",
    "453": "tf.expand_dims",
    "454": "tf.image.resize",
    "455": "tf.keras model",
    "456": "tf.keras.Sequential",
    "457": "tf.keras.layers.Dense(units=1)",
    "458": "tf.keras.layers.Dense(units=1, input_shape=[1])",
    "459": "tf.keras.layers.Dense(units=16, activation='relu')",
    "460": "tf.keras.models.Sequential",
    "461": "tf.linspace()",
    "462": "tf.lite.TFLiteConverter",
    "463": "tf.lite.TFLiteConverter.from_keras_model",
    "464": "tf.lite.TFLiteConverter.from_saved_model",
    "465": "tf.losses.meanSquaredError",
    "466": "tf.model()",
    "467": "tf.nn.softmax",
    "468": "tf.nn.softmax()",
    "469": "tf.saved_model.save",
    "470": "tf.sequential()",
    "471": "tf.sequential()和tf.model()两种创建模型的方式",
    "472": "tf.tensor",
    "473": "tf.tidy",
    "474": "tf.tidy()",
    "475": "tf.train.adam()",
    "476": "tf.util.shuffle",
    "477": "tfjs-examples/mnist",
    "478": "tflite_convert",
    "479": "tflite_convert --keras_model_file=/tmp/mobilenet_keras_model.h5 --output_file=/tmp/mobilenet.tflite",
    "480": "tflite_convert --saved_model_dir=/tmp/mobilenet_saved_model --output_file=/tmp/mobilenet.tflite",
    "481": "tfvis.render.scatterplot",
    "482": "time.sleep()方法",
    "483": "train_generator",
    "484": "train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=val_generator, validation_steps=len(val_generator)",
    "485": "ui.js",
    "486": "units: 10",
    "487": "units为1, useBias为true",
    "488": "val_ds",
    "489": "val_generator",
    "490": "validationData设置为[testXs, testYs]",
    "491": "wait_for_edge()函数",
    "492": "wait_for_edge()函数和add_event_detect()函数",
    "493": "yarn",
    "494": "一个使用数据流图进行数值计算的开源软件库",
    "495": "一个强大、简单、易上手的人脸识别开源项目",
    "496": "一个用于使用 JavaScript 进行机器学习开发的库，用于在浏览器和 Node.js 训练和部署机器学习模型",
    "497": "一个端到端的机器学习开源框架",
    "498": "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具",
    "499": "一次采样32条训练数据",
    "500": "一种数据结构，包含了在解决特定问题时训练得到的机器学习网络的逻辑和知识",
    "501": "一种有效的物品检测方法",
    "502": "一种特定的矩阵用来呈现算法性能的可视化效果",
    "503": "一系列的函数，这些函数以一个或多个张量作为输入，并输出另一个张量",
    "504": "一系列的计算节点、多个张量，以及子图本身的输入和输出",
    "505": "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型",
    "506": "一组数字引脚，可用于将树莓派连接到其他电子设备",
    "507": "三维张量输出，形状为(height, width, channels)",
    "508": "上拉电阻",
    "509": "下载 OpenCV",
    "510": "下载TensorFlow Lite示例源码",
    "511": "下载和访问mnist数据集",
    "512": "下载特定版本的Python",
    "513": "下载解压",
    "514": "不包括无线网卡",
    "515": "不支持 CUDA",
    "516": "不支持 CUDA 且版本是固定搭配的",
    "517": "不支持即插即用",
    "518": "不改变基础模型的各项参数变量",
    "519": "不更新预训练网络的权重",
    "520": "不清除内部函数的返回值",
    "521": "不需要原始模型构建代码",
    "522": "不需要原始模型构建代码就可以运行",
    "523": "不需要原有模型中最后的神经网络层",
    "524": "不需要序列化或可以创造自己的序列化方法",
    "525": "不需要改变模型，最少情况只需多加一行代码",
    "526": "与 TensorFlow 一起安装",
    "527": "与 TensorFlow 团队合并，重命名为 TensorFlow.js",
    "528": "与 TensorFlow 的核心算子库略有不同",
    "529": "与JavaScript中的常规范围类似，但针对GPU支持的张量",
    "530": "与树莓派结合可以将项目与现实世界轻松的联系起来",
    "531": "串联在LED和电源之间限制电流",
    "532": "为了高性能场景创建的序列化库",
    "533": "为图像张量添加批次维度",
    "534": "为机器学习提供低级构建模块，以及构建神经网络的高级 Keras Layers API",
    "535": "主要应用于游戏场景",
    "536": "主要应用于游戏场景，是为了高性能场景创建的序列化库",
    "537": "了解模型效率、调试超参数",
    "538": "二维卷积层",
    "539": "二进制文件很小",
    "540": "二进制文件的大小约为 1 MB（针对 32 位 ARM build）",
    "541": "人体姿势估计",
    "542": "人脸检测",
    "543": "人脸检测、检测面部特征点、给脸部编码、从编码中找出人的名字",
    "544": "人脸识别",
    "545": "人脸识别与商品识别",
    "546": "仅用于开发的程序包",
    "547": "仅适用于卷积神经网络的一个子集",
    "548": "从 GitHub 获取源码并运行；创建相关文件；定义模型结构；训练模型；使用模型进行评估与预测",
    "549": "从 MNIST 数据集中随机批量提取 MNIST 图像",
    "550": "从头编译",
    "551": "从指定目录生成训练数据批次",
    "552": "从指定目录生成验证数据批次",
    "553": "从测试集中返回一批图像及其标签",
    "554": "从训练集中返回一批随机图像及其标签",
    "555": "以 ldconfig 结束",
    "556": "以依赖项的安装开始",
    "557": "以最小精度下降来训练网络",
    "558": "优化器为Adam",
    "559": "优化器使用Adam",
    "560": "优化模型",
    "561": "优化模型大小和性能",
    "562": "优化的 FlatBuffer 格式",
    "563": "优化的 FlatBuffer 格式，以 .tflite 为文件扩展名",
    "564": "优化的算子内核",
    "565": "位于其引脚排针上",
    "566": "低功耗",
    "567": "作为LED灯的限流电阻",
    "568": "作为LED的控制引脚",
    "569": "作为functional模型第一层的输入",
    "570": "作为最终的Dense层的激活函数用于多分类",
    "571": "作为模型的优化器",
    "572": "作为模型的损失函数",
    "573": "作为迁移学习的基础模型",
    "574": "使权重和激活值的 Post training 更简单",
    "575": "使模型准确率提高几个百分点",
    "576": "使用 GPU 加速模型的运算，提高运算效率",
    "577": "使用 Python API 进行转换",
    "578": "使用 SavedModel 格式存储",
    "579": "使用 TFLite 模型转换器转换成 TFLite 文件格式(FlatBuffers 格式)",
    "580": "使用 TensorFlow Lite 解释器（提供多种语言的 API）在设备端运行模型",
    "581": "使用 TensorFlow Lite 转换器将模型转换为 TensorFlow Lite 格式",
    "582": "使用'mean_squared_error'作为损失函数",
    "583": "使用'sgd'作为优化器",
    "584": "使用3×3的卷积核，并在输出上使用 Relu 激活函数",
    "585": "使用BCM编号、物理引脚Broad编号",
    "586": "使用C、C++开发并且可以被其他语言包使用，例如python、ruby或者PHP等",
    "587": "使用GPU来加速数学运算",
    "588": "使用ImageProcessor进行resize和normalize",
    "589": "使用TFLiteConverter转换为TFLite格式",
    "590": "使用TensorFlow.js识别剪刀、石头、布手势",
    "591": "使用tf.model() API创建非闭环的计算图",
    "592": "使用tf.saved_model.save保存模型",
    "593": "使用低学习率编译模型",
    "594": "使用低学习率重新编译模型",
    "595": "使用层构建模型",
    "596": "使用已编译好的库",
    "597": "使用模型从未见过的测试数据评估分类器准确性",
    "598": "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响",
    "599": "使用测试数据集评估模型",
    "600": "使用测试集中的数据",
    "601": "使用深度可分离的卷积",
    "602": "使用滑动滤波器窗口学习空间不变的变换",
    "603": "使用网络摄像头检查自己做出的代表石头剪刀布的手势图像",
    "604": "使用计算机视觉相关模型和预训练模型进行实时图像分类和对象检测",
    "605": "使用训练集进行训练",
    "606": "使用语言就是 Javascript，前端工程师不需要学习其他后端语言，降低入门门槛",
    "607": "使用预训练量化进行模型转换",
    "608": "保存完整的TensorFlow程序，包括权重值和计算",
    "609": "保护LED和GPIO引脚",
    "610": "保持了很多通用性",
    "611": "保留原来大规模训练的优势",
    "612": "借助低级运算（例如 tf.matMul()、tf.add() 等）创建机器学习模型",
    "613": "做了移动设备相关的优化",
    "614": "允许解释器在设备的 GPU 上运行适当的运算符",
    "615": "全能 IDE",
    "616": "全连接(Full Connected)层",
    "617": "全连接网络",
    "618": "关闭LED灯",
    "619": "具有 shape 属性定义其数组形状",
    "620": "内存只有几十KB",
    "621": "内存回收问题突出",
    "622": "内存管理",
    "623": "内存高效",
    "624": "内存高效，采取静态内存分配",
    "625": "写一段简单的测试代码",
    "626": "写入镜像",
    "627": "冻结前100层，设置不可训练",
    "628": "冻结预训练模型并更新分类器权重",
    "629": "准备训练集和验证集",
    "630": "准确度",
    "631": "减少内存碎片化",
    "632": "减少服务器的运算，提高服务器资源利用，增强客户端响应运算结果的速度",
    "633": "出门问问智能音箱",
    "634": "创建0~1之间平均分配的100个值",
    "635": "创建TFLite转换器实例",
    "636": "创建、训练和导出自定义 TensorFlow Lite 模型",
    "637": "创建了一个安装脚本",
    "638": "创建任意非闭环的计算图",
    "639": "创建实例并加载模型",
    "640": "创新奇智",
    "641": "判断训练结果的参数",
    "642": "利用 ARM 的 NEON 指令集做了大量的优化",
    "643": "利用GPIO控制外部硬件设备的基础",
    "644": "利用在同一域中的较大数据集上训练的模型所学习的特征",
    "645": "利用手机上的加速器，比如 GPU 或者 DSP 等",
    "646": "利用计算机对图像进行处理、分析和理解，以识别各种不同模式的目标和对象的技术",
    "647": "前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像",
    "648": "前端工程师不需要学习其他后端语言，降低入门门槛",
    "649": "功耗非常低，有两种模式：5W（低功耗模式；可以使用 USB 口供电）和10W（必须使用 Power Jack 外接5V 电源供电）",
    "650": "功能强大的编程语言，易于使用，易于阅读和编写",
    "651": "功能强大，交互式、富文本，还有丰富的插件、主题修改、多语言支持",
    "652": "功能接线的引脚号（如TXD、PWM0等）",
    "653": "加载 @tensorflow/tfjs 和 @tensorflow/tfjs-vis 两个 TFJS 模块的代码",
    "654": "加载 @tensorflow/tfjs 和 @tensorflow/tfjs-vis 两个 TFJS 模块的脚本",
    "655": "加载 TensorFlow Hub 上的模型",
    "656": "加载和运行TFLite模型",
    "657": "加载数据并准备进行训练；定义模型结构；训练模型，并监视其性能；评估模型",
    "658": "加载数据集并显示20张图片",
    "659": "加载数据，定义模型，训练循环并指定UI元素",
    "660": "加载模型",
    "661": "加载模型，转换数据，运行模型推理，解释输出",
    "662": "加载面孔照片",
    "663": "加速模型推理过程",
    "664": "动态显示训练的过程",
    "665": "包含完整的TensorFlow程序",
    "666": "包含完整的TensorFlow程序，包括权重值和计算",
    "667": "千兆以太网端口",
    "668": "单一芯片的小型计算机",
    "669": "单个图像的维度为[28,28,1]",
    "670": "占用更少的磁盘和内存，更快更高效",
    "671": "卷积层",
    "672": "卷积层与全连接层",
    "673": "卷积层输入",
    "674": "取消冻结模型的顶层",
    "675": "取消冻结模型的顶层，设置 base_model.trainable = True",
    "676": "变量(Variable)",
    "677": "只使用在C语言中",
    "678": "只提供了基本的转化功能",
    "679": "可以使用树莓派摄像头",
    "680": "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的 TensorFlow 预训练模型中选择一个模型直接使用或重新训练",
    "681": "可以利用手机上的加速器，比如 GPU 或者 DSP",
    "682": "可以利用手机上的加速器，比如 GPU 或者 DSP 等",
    "683": "可以是内置的算子，也可以是自定制算子，有一个名字",
    "684": "可以直接使用cv2.videocapture(2)打开",
    "685": "可以直接在浏览器中运行，无需进行安装，也无需借助后端运行",
    "686": "可以设置访问密码",
    "687": "可以通过跳线线连接到其他电路板或设备",
    "688": "可以通过软件编程进行控制",
    "689": "可以配置为输入或输出",
    "690": "可以配置图像加载的细节",
    "691": "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行",
    "692": "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型",
    "693": "可能值得使用构建工具进行探索",
    "694": "可能出现哈希不匹配的错误",
    "695": "可能导致模型过拟合",
    "696": "可能导致预训练模型忘记已学内容",
    "697": "可视化模型训练的过程和结果",
    "698": "可视化模型预测结果和原始数据",
    "699": "可配置为输入或输出",
    "700": "启动图标",
    "701": "启用 TF 1.x 的转换器和标志",
    "702": "命令行 TensorFlow Lite 转换器命令行工具",
    "703": "命令行与 Python API",
    "704": "命令行工具",
    "705": "命令行工具gpio",
    "706": "命令行工具和 Python API",
    "707": "命令行调用方式",
    "708": "商品流通过程中，特别是无人货架、智能零售柜等无人零售领域",
    "709": "商品识别",
    "710": "四引脚按键",
    "711": "四脚按键开关",
    "712": "回调函数",
    "713": "因为 TensorFlow.js 使用了 GPU 来加速数学运算，因此当 tensorflow 处理张量和变量时就有必要来管理 GPU 内存",
    "714": "国内源",
    "715": "图像、文本和语音处理",
    "716": "图像分类任务",
    "717": "图像和视频处理",
    "718": "图像处理",
    "719": "图像识别",
    "720": "图像识别技术",
    "721": "图像预处理",
    "722": "在 Android 与 iOS 平台上使用",
    "723": "在 HTML 中直接引用 TensorFlow.js 发布的 NPM 包中已经打包安装好的 JavaScript 代码",
    "724": "在 MCU 上甚至可以小于 100KB",
    "725": "在 Node.js 环境中，需要有 CUDA 环境支持",
    "726": "在 Tensorflow.js 有两种创建模型的方式：可以用高层 API：Layers API 来建立模型，也用 Core API 来搭建相同的模型",
    "727": "在18号引脚处设置",
    "728": "在Jetson Nano开发板上进行花卉图片识别",
    "729": "在不同设备上使用硬件加速",
    "730": "在图像中检测面部",
    "731": "在图像分类、物体检测、分割和语音处理等应用程序中并行运行多个神经网络",
    "732": "在大规模数据处理上不如Python高效",
    "733": "在官网下载安装包后安装",
    "734": "在小型数据集上训练模型",
    "735": "在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战",
    "736": "在有 GPU 加速的手机上运行 MobileNet 图像分类，模型运行速度可以提高",
    "737": "在每一个训练周期显示训练情况",
    "738": "在浏览器上开发模型",
    "739": "在浏览器中加载",
    "740": "在浏览器中训练模型",
    "741": "在浏览器和 Node.js 环境中进行机器学习模型的开发、训练和部署",
    "742": "在浏览器环境中实现深度学习的功能",
    "743": "在浏览器环境中，需要有 WebGL 环境支持",
    "744": "在生产环境中不需要",
    "745": "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化",
    "746": "在移动端、嵌入式和物联网设备上运行 TensorFlow 模型",
    "747": "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型",
    "748": "在移动设备、嵌入式设备和IoT设备上运行TensorFlow模型",
    "749": "在移动设备上实现性能大幅度提升",
    "750": "在给定设备上实现性能、模型大小和准确性的理想平衡",
    "751": "在训练过程中不能用于训练",
    "752": "在设备端运行 TFLite 模型",
    "753": "在资源有限的硬件上运行",
    "754": "在边缘设备上运行 TensorFlow 模型推理的官方框架",
    "755": "在靠近物或数据源头的一侧，采用网络、计算、存储、应用核心能力为一体的开放平台，就近提供最近端服务",
    "756": "基于 WebGL 加速的开放源代码 JavaScript 机器学习库",
    "757": "基于一个流线型的架构，使用深度可分离的卷积",
    "758": "基于流线型架构的轻量级深层神经网络",
    "759": "基于浏览器运行已训练的模型",
    "760": "基于现有模型构建 Interpreter",
    "761": "基于现有的模型进行继续训练",
    "762": "基于适应性低阶矩估计",
    "763": "基础模型的各项参数变量不会被新的训练修改数据",
    "764": "基础硬件控制能力展示",
    "765": "增加一个事件的检测函数",
    "766": "处理媒体应用程序",
    "767": "处理简单的数据",
    "768": "多媒体框架，用于后端处理任务",
    "769": "多种编程语言",
    "770": "多种编程语言包括Python, C++, Java, Swift和Javascript",
    "771": "大电流可能损坏LED和供电设备",
    "772": "大而复杂的模型",
    "773": "头信息",
    "774": "委托（Delegates）",
    "775": "子图",
    "776": "子图、算子库和共享的内存缓冲区",
    "777": "存储图像和标签的数据集",
    "778": "存储已安装软件包的名称和版本",
    "779": "存储模型权重，或者计算节点的输入和输出",
    "780": "存放Python相关程序模块",
    "781": "存放训练好的模型供开发人员复用",
    "782": "学习AI和构建应用程序",
    "783": "安全检查、身份核验与移动支付",
    "784": "安卓应用只需 1 兆左右的运行环境",
    "785": "安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB",
    "786": "安装 OpenCV 项目",
    "787": "安装 Python 包依赖项",
    "788": "安装 TensorFlow",
    "789": "安装 TensorFlow 所需的系统包",
    "790": "安装Android Studio",
    "791": "安装Python",
    "792": "安装Python包",
    "793": "安装依赖",
    "794": "安装依赖项",
    "795": "安装包是不同的",
    "796": "安装和升级 pip3",
    "797": "安装的 TensorFlow 版本必须与正在使用的 JetPack 版本一致",
    "798": "安装相应的依赖包",
    "799": "完全基于 JavaScript 从头开发、训练和部署模型",
    "800": "完成分类任务",
    "801": "官方已经停止维护",
    "802": "官方推荐",
    "803": "定义的神经元网络层与层之间的关系较为随意",
    "804": "定义需要监视的指标",
    "805": "定位图像中的人脸位置",
    "806": "实例化tf.sequential对象、添加输入层、添加输出层",
    "807": "实时识别照相机所拍摄的花卉",
    "808": "实现人体姿势估计",
    "809": "实现花卉识别 app",
    "810": "实现识别花卉模型",
    "811": "室内避开障碍物",
    "812": "对 SIMD 指令功能特别有益",
    "813": "对val_ds中的每个图像x应用normalization_layer，同时保留对应的标签y",
    "814": "对图像数据进行归一化处理",
    "815": "对手写数字的图像进行分类",
    "816": "对数据降维",
    "817": "对模型的权重产生更一致且变化较小的渐变更新",
    "818": "对现有 CPU 平台的支持",
    "819": "对训练图像进行旋转以增加数据多样性",
    "820": "对训练图像进行水平翻转以增加数据多样性",
    "821": "对输入图像进行预处理",
    "822": "对随机目标函数执行一阶梯度优化的算法",
    "823": "导入 TensorFlow Lite 库",
    "824": "导致每个时期的梯度更新数量较少",
    "825": "将 NPM 模块转换为在线可以引用的免费服务",
    "826": "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API",
    "827": "将 TensorFlow 模型转换为 TFLite 文件格式",
    "828": "将 TensorFlow 模型转换为 TFLite 格式",
    "829": "将 TensorFlow 模型转换为 TensorFlow Lite 格式",
    "830": "将 TensorFlow 模型转换为方便解释器使用的格式",
    "831": "将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能",
    "832": "将GPIO21设置为输出模式",
    "833": "将Keras模型保存为SavedModel格式",
    "834": "将Keras模型转换为TFLite模型",
    "835": "将SavedModel转换为TFLite兼容格式",
    "836": "将SavedModel转换为TFLite模型",
    "837": "将SavedModel转换为TensorFlow Lite兼容格式",
    "838": "将TensorFlow模型转换为轻量级格式",
    "839": "将三维张量展开到1维以便传入Dense层",
    "840": "将人脸编码列表与候选编码进行比较，查看是否匹配",
    "841": "将前一层的输出平铺到一个向量中",
    "842": "将原始图像调整到模型输入大小",
    "843": "将原始数据转变为TensorFlow可读的张量格式",
    "844": "将图片分类到1000类",
    "845": "将外设操作视为文件读写",
    "846": "将大规模内存操作放置在其回调中执行",
    "847": "将彩色图像转换为灰度图像，检测人脸并在边界周围绘制矩形",
    "848": "将所有图像加载到一个模型需要的特定的大小",
    "849": "将模型加载到内存中",
    "850": "将模型嵌入到二进制文件中，这样就可以在设备上运行和部署模型",
    "851": "将模型文件拷贝到 assets 目录下",
    "852": "将模型显示在浏览器中",
    "853": "将模型输出概率与类别标签关联",
    "854": "将模型输出转换为概率分布",
    "855": "将特征转换为每个图像对应一个1280元素向量",
    "856": "将网络的每一层简单的叠在一起",
    "857": "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型",
    "858": "将镜像写入microSD卡",
    "859": "将需要的层按顺序写在一个列表里，然后将列表作为sequential()函数的输入",
    "860": "小一点的模型",
    "861": "已经训练好的分类器（面部，眼睛，微笑等）",
    "862": "常开触点",
    "863": "常开触点和常闭触点",
    "864": "常见的移动/嵌入式平台",
    "865": "常闭触点",
    "866": "应对快速变化需求的软件开发模式",
    "867": "应用于树莓派的GPIO控制库函数，由Gordon Henderson所编写维护",
    "868": "应用深度学习算法的一种实践应用",
    "869": "应用程序在边缘侧发起，产生更快的网络服务响应，满足行业在实时业务、应用智能、安全与隐私保护等方面的基本需求",
    "870": "底层 Core API 和最高级的 Layers API",
    "871": "度量模型的最后一层产生的概率分布与标签给出的概率分布之间的误差",
    "872": "廉价且周边设备多",
    "873": "延迟一秒钟",
    "874": "延迟较低",
    "875": "建议使用脚本代码",
    "876": "建议在使用之前仔细阅读相关文档，并确保采取适当的安全措施",
    "877": "建议最小采用 64 GB UHS-1 卡",
    "878": "开关去抖",
    "879": "开关抖动",
    "880": "开发 Android 应用",
    "881": "开发依赖",
    "882": "开箱即用的开发库，开发者无需花精力去编写基础复杂的数学问题",
    "883": "引入优化以减小二进制文件的大小和提高性能",
    "884": "引用 Model 的内存缓冲区的一片区域，提高内存效率",
    "885": "张量",
    "886": "张量(Tensor)",
    "887": "张量形状是 (image_height, image_width, color_channels)",
    "888": "归一化操作",
    "889": "当压力撤销时电路恢复",
    "890": "当压力施压时电路接通",
    "891": "形状为[null, 10]的张量",
    "892": "形状为[null, 28, 28, 1]的张量",
    "893": "形状是 (224,224, 3)",
    "894": "微调",
    "895": "微调过程",
    "896": "微调预训练模型的顶层权重",
    "897": "必须在开机前先装上去，系统才能识别",
    "898": "快速启动",
    "899": "快速启动深度学习推理演示",
    "900": "快速启动，能够将模型直接映射到内存中，同时有一个静态执行计划",
    "901": "忽略时理论上每按下一次开关会输出一次",
    "902": "忽略由于开关抖动引起的小于",
    "903": "恢复训练",
    "904": "手写数字识别",
    "905": "手势识别项目",
    "906": "打乱数据集",
    "907": "打乱数据集中数据顺序",
    "908": "打乱数据顺序，创建特征向量和标签向量，转换为张量格式，进行归一化操作",
    "909": "打开现有 Android Studio 项目",
    "910": "打开项目图标",
    "911": "执行TensorFlow Lite模型的推理",
    "912": "执行一个函数并清除所有创建的中间张量",
    "913": "执行推理",
    "914": "执行最终的分类",
    "915": "执行模型推理",
    "916": "执行模型推理过程",
    "917": "执行模型文件在输入数据上定义的运算符，输出推理结果",
    "918": "执行模型转换过程",
    "919": "批次大小",
    "920": "拷贝模型和标签文件到assets目录",
    "921": "指定 Keras H5 模型文件的绝对路径",
    "922": "指定从哪个层开始进行微调的参数",
    "923": "指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录",
    "924": "指定含有 TensorFlow 1.x 或者 2.0 使用 tf.keras model 生成 HDF5 文件的绝对路径目录",
    "925": "指定含有 TensorFlow 1.x 或者 2.x SavedModel 的目录",
    "926": "指定引脚编号系统",
    "927": "指定输出文件的绝对路径",
    "928": "损失函数",
    "929": "损失函数为categorical_crossentropy",
    "930": "损失函数使用SparseCategoricalCrossentropy",
    "931": "接受 TFLite 模型",
    "932": "控制GPIO引脚",
    "933": "控制LED灯",
    "934": "控制LED灯的亮暗",
    "935": "控制外部硬件设备",
    "936": "控制树莓派的GPIO",
    "937": "控制迁移学习中微调的起始层",
    "938": "推理过程",
    "939": "推理速度提高了30%",
    "940": "描述构建和运行示例所需的依赖项",
    "941": "提供 5V⎓2A 的高品质电源为开发者套件供电",
    "942": "提供了各种库和工具，使编程更加方便",
    "943": "提供了大量方便的工具，例如权重初始化，模型序列化，训练监测，可迁移性和安全检查",
    "944": "提供低级的机器学习构建模块和高级的类似 Keras 的 API 来构建神经网络",
    "945": "提供多种语言的 API",
    "946": "提供简单的 API 用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型",
    "947": "提供经过充分认证的模型",
    "948": "提供训练好的模型，开发人员可以复用这些已经训练好且经过充分认证的模型",
    "949": "提供转换工具压缩模型，进行算子融合并生成代码",
    "950": "提供预训练模型用于图像分类、对象检测、姿势估计、文本恶意检测等",
    "951": "提问或分享项目",
    "952": "提高了用户的体验",
    "953": "提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练",
    "954": "搭建电路原型",
    "955": "摄像头预捕获的图像宽度、高度、窗口显示的图像宽度、高度、捕获帧率、是否旋转图像",
    "956": "操作(Ops)",
    "957": "支持 Android 神经网络 API（Android NN API)",
    "958": "支持 GPU 硬件加速",
    "959": "支持 GPU 硬件加速，可以运行在 Node.js 或浏览器环境中",
    "960": "支持1080p30, 720p60以及640 × 480p90视频录像",
    "961": "支持Linux SoC",
    "962": "支持像素缩放和数据增强",
    "963": "支持图像大小调整和批量处理",
    "964": "支持大规模的模型训练和各种环境的部署",
    "965": "支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析",
    "966": "支持将文件映射到内存中，直接进行读取和解释，不需要额外解析",
    "967": "支持微控制器(MCU)",
    "968": "支持微控制器(MCU)，应用于 IoT 领域",
    "969": "支持算子优化和常见的编译优化",
    "970": "支持算子优化和常见的编译优化，比如算子融合、常数折叠或无用代码删除等",
    "971": "支持自定义输入形状和是否包含顶层分类器",
    "972": "支持设备端机器学习推断",
    "973": "支持设备端机器学习推断，延迟较低，并且二进制文件很小",
    "974": "支持量化原生支持",
    "975": "支持量化的原生支持",
    "976": "支持预装驱动程序的RPi相机",
    "977": "改造模型",
    "978": "敏捷开发",
    "979": "教育",
    "980": "数据图像的采集、模型的训练、参数的调整、模型文件生成、网页端部署",
    "981": "数据规范化和转换为张量类型",
    "982": "数据转换",
    "983": "数据预处理",
    "984": "整个安装需要两个小时才能完成",
    "985": "文字处理",
    "986": "文本处理",
    "987": "易于设置和使用，兼容许多配件",
    "988": "是一个线性堆叠layers的模型",
    "989": "显示每个类别的准确度",
    "990": "显示混淆矩阵",
    "991": "智能读码机",
    "992": "智能质检一体机",
    "993": "更新可视化元素",
    "994": "更新数据慢可以考虑更换源",
    "995": "更谨慎地控制内存何时回收",
    "996": "更轻量，二进制文件的大小约为 1 MB（针对 32 位 ARM build）",
    "997": "更适合于边缘设备部署",
    "998": "最后的神经网络层",
    "999": "最大池化层",
    "1000": "最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口",
    "1001": "有助于避免因错误的样本而改向错误的方向",
    "1002": "有经验的开发者",
    "1003": "服务器和移动端的部署",
    "1004": "未满足的对等依赖 seedrandom@~",
    "1005": "机器学习和计算机视觉应用",
    "1006": "杜邦线公对母",
    "1007": "构建CNN模型",
    "1008": "构建Tensorflow.js模型来识别手写数字",
    "1009": "构建和运行mnist代码",
    "1010": "构建和运行机器学习模型",
    "1011": "构建小型移动机器人、人脸签到打卡、口罩识别、智能门锁、智能音箱等复杂 AI 系统",
    "1012": "构建工具",
    "1013": "构建工具用于编写更大的程序",
    "1014": "构成检测目标的相邻矩形的最小个数",
    "1015": "查看开发板系统信息",
    "1016": "查看树莓派的GPIO引脚信息",
    "1017": "标准算子",
    "1018": "树莓派",
    "1019": "树莓派4B的18号引脚",
    "1020": "树莓派GPIO",
    "1021": "树莓派接口",
    "1022": "树莓派的21号引脚",
    "1023": "树莓派系统",
    "1024": "树莓派系统升级",
    "1025": "树莓派通用输入/输出接口（GPIO）",
    "1026": "核心板可拆的设计，核心板的大小只有70 x 45 mm",
    "1027": "核心运行时",
    "1028": "格式修改、显示驱动程序协调和数据处理",
    "1029": "格式化microSD卡",
    "1030": "梯度下降",
    "1031": "检测人脸",
    "1032": "检测关键身体部位的位置",
    "1033": "检测面部特征点",
    "1034": "模型",
    "1035": "模型优化",
    "1036": "模型优化工具",
    "1037": "模型优化工具包",
    "1038": "模型优化算法",
    "1039": "模型可以跟 Python 等其他语言模型进行互转",
    "1040": "模型和层",
    "1041": "模型大小只有20KB左右",
    "1042": "模型对象和保存路径",
    "1043": "模型执行流图",
    "1044": "模型文件和标签文件",
    "1045": "模型文件的一种",
    "1046": "模型编译",
    "1047": "模型训练",
    "1048": "模型评估",
    "1049": "模型预测",
    "1050": "每一列代表预测值，每一行代表实际的类别",
    "1051": "比 CPU 执行更快的浮点矩阵运算",
    "1052": "池化层",
    "1053": "汽车油耗（MPG）",
    "1054": "汽车的功率（Horsepower）",
    "1055": "没有操作系统",
    "1056": "注重实时性，内存高效",
    "1057": "测试Python开发环境并查看当前的Python版本",
    "1058": "测试的软件包、webpack或Babel",
    "1059": "浏览器可以很好可视化机器训练过程，同时浏览器可调用设备的摄像头、麦克风等增加机器学习的应用场景",
    "1060": "浏览器可以很好可视化机器训练过程，同时浏览器可调用设备的摄像头、麦克风等增加机器学习的应用场景，让机器学习跟接近用户",
    "1061": "混淆矩阵",
    "1062": "添加tensorflow-lite依赖",
    "1063": "清华源",
    "1064": "清理GPIO引脚的设置",
    "1065": "清除张量或变量并释放其GPU内存",
    "1066": "清除所有创建的中间张量并释放它们的GPU内存",
    "1067": "激活、设置为输出状态、写入1使其输出高电压",
    "1068": "灵活的架构可以将模型部署到桌面、服务器或移动设备中的 CPU 或 GPU 上",
    "1069": "点亮LED灯",
    "1070": "热词唤醒",
    "1071": "爱奇艺",
    "1072": "版本变化后 API 函数会改变",
    "1073": "版本变化后API函数会改变",
    "1074": "物体检测、人脸识别、图像分割等视觉任务",
    "1075": "物理引脚Broad编号",
    "1076": "特别为各种端侧设备优化的算子库",
    "1077": "瓶颈层",
    "1078": "生成 HDF5 文件的绝对路径目录",
    "1079": "生成SavedModel",
    "1080": "生成一个批次一个批次的图片，以生成器的形式给模型训练",
    "1081": "生成一个批次的图片，以生成器的形式给模型训练",
    "1082": "生成批次的图片数据用于模型训练",
    "1083": "用于 5V 电源输入",
    "1084": "用于 flower_classification 项目",
    "1085": "用于处理或存储数据",
    "1086": "用于实现网页的交互功能",
    "1087": "用于工具的配置中心",
    "1088": "用于操作张量数据的线性代数和机器学习运算",
    "1089": "用于构建网页的用户界面",
    "1090": "用于监督学习，展示多个类别是否有混淆",
    "1091": "用于训练模型",
    "1092": "用作启动设备和主存储器",
    "1093": "用到的算子索引，以及输入输出用到的 Tensor 索引",
    "1094": "用张量的值进行初始化，但其值是可变的",
    "1095": "用户在自己的工作台中使用 TensorFlow API 构造 TensorFlow 模型",
    "1096": "用来设置GPIO管脚，可以用来读写GPIO管脚，甚至可以在Shell脚本中使用来达到控制GPIO管脚的目的",
    "1097": "用来连接 DP 屏幕",
    "1098": "由 schema.fbs 文件使用 FlatBuffers 定义",
    "1099": "由jupyter软件自动生成",
    "1100": "由于可运行于浏览器，减少服务器的运算，提高服务器资源利用，增强客户端响应运算结果的速度",
    "1101": "由于浏览器的 WebGL 可调用 GPU，所以 Tensorflow.js 会使用 GPU 加速模型的运算，提高运算效率",
    "1102": "电信号从低电平到高电平，或从高电平到低电平状态的改变",
    "1103": "电路",
    "1104": "电阻",
    "1105": "登录 Jetson Nano",
    "1106": "目前有130个左右",
    "1107": "目前有130个左右，它与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化",
    "1108": "直接串联3.3V电源会产生大电流",
    "1109": "直接在 Objective-C 代码中使用 C API",
    "1110": "直接更新树莓派系统",
    "1111": "直接部署或用于迁移学习",
    "1112": "直流桶式插座",
    "1113": "相比 Protocol Buffer 有更高的性能和更小的大小",
    "1114": "硬件加速代理(Hardware accelerator delegate)",
    "1115": "确认 CUDA 已经被正常安装",
    "1116": "离线语音识别",
    "1117": "科沃斯扫地机器人",
    "1118": "移动端语音识别",
    "1119": "端侧机器学习",
    "1120": "第一个卷积层",
    "1121": "第二、三卷积层",
    "1122": "简化图像预处理和模型输出处理",
    "1123": "简化图像预处理和输出处理",
    "1124": "简单的姿态检测模型",
    "1125": "简单的线性回归的实验",
    "1126": "算子实现",
    "1127": "算子库(Op kernels)",
    "1128": "算子库(Op kernels)和硬件加速代理(Hardware accelerator delegate)",
    "1129": "精度达到98%",
    "1130": "给脸部编码",
    "1131": "编译 OpenCV",
    "1132": "编译Python模块",
    "1133": "缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响",
    "1134": "缩减版的 TensorFlow，简化了算子集，也缩小了运行库",
    "1135": "缩短开发周期",
    "1136": "网易",
    "1137": "网络环境较差时可以考虑更换源",
    "1138": "能够利用各种硬件加速",
    "1139": "能够执行完整全面的反向传播",
    "1140": "脚本标签",
    "1141": "自动将视频和对话中的语言转化为文字",
    "1142": "自动连接到具有一个隐藏单元的dense层",
    "1143": "花卉数据集中的图片",
    "1144": "花卉识别 app",
    "1145": "花卉识别模型",
    "1146": "英伟达官方或开源社区",
    "1147": "获取Jetson平台信息",
    "1148": "获取score中的最大值索引",
    "1149": "获取分类结果的概率",
    "1150": "获取图像数据、处理图像、调用姿势估计函数、绘制关键点",
    "1151": "获取张量数据",
    "1152": "获取指向张量的指针",
    "1153": "获取有趣项目",
    "1154": "衡量所有预测中正确预测的百分比",
    "1155": "观测开关去抖效果",
    "1156": "视频中的AR效果",
    "1157": "解决JavaScript内存回收问题",
    "1158": "解决pip安装时的哈希不匹配问题",
    "1159": "解决特定问题的机器学习网络",
    "1160": "解决跨域问题",
    "1161": "解释器、转换器、算子库、硬件加速代理",
    "1162": "解释输出",
    "1163": "计算已知人脸和未知人脸特征向量的距离",
    "1164": "计算机视觉应用",
    "1165": "计算能力不高，勉强可以使用一些小规模、并且优化过的网络进行推理，训练的话还是不够用",
    "1166": "计算节点",
    "1167": "计算预测结果的softmax概率",
    "1168": "让输入输出映射到0-1之间，保证后期更有效地训练",
    "1169": "训练 MNIST 分类器",
    "1170": "训练分类器查看数千个图像及其标签",
    "1171": "训练后量化",
    "1172": "训练好的模型",
    "1173": "训练数据和测试数据",
    "1174": "训练时从数据集中的不同类中随机选出一定数量的图像",
    "1175": "训练期间将不更新预训练网络的权重，只在 MobileNet V2基础模型上训练了几层",
    "1176": "训练期间需要更多的内存",
    "1177": "训练模型",
    "1178": "训练模型并记录训练和验证准确性/损失",
    "1179": "训练集",
    "1180": "记录训练日志和可视化训练过程",
    "1181": "记录训练过程中的指标和计算图",
    "1182": "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，对量化特别有益",
    "1183": "设置 OpenCV 的内容、位置和方式",
    "1184": "设置 model.trainable = False",
    "1185": "设置GPIO引脚编号模式",
    "1186": "设置aaptOptions防止模型压缩",
    "1187": "设置model.trainable = False",
    "1188": "设置上拉电阻",
    "1189": "设置为100表示从第100层开始微调",
    "1190": "设置人脸检测模型，'hog'在CPU上运行更快，'cnn'更准确但需要GPU加速",
    "1191": "设置前100层为不可训练",
    "1192": "设置在训练中，基础模型的各项参数变量不会被新的训练修改数据",
    "1193": "设置对图像进行多少次上采样以查找人脸",
    "1194": "设置引脚为输入或输出模式",
    "1195": "设置输入张量值",
    "1196": "设置过大会导致Jetson Nano开发板内存溢出",
    "1197": "评估指标为accuracy",
    "1198": "评估指标为准确率(acc)",
    "1199": "评估模型",
    "1200": "评估训练有素的模型的性能",
    "1201": "识别图像里的空间模式，例如线条和物体局部",
    "1202": "识别花卉图片",
    "1203": "识别若干关键词的语音识别模型",
    "1204": "语音功能部署",
    "1205": "语音识别",
    "1206": "读取传感器数据，控制 LED 等外部设备",
    "1207": "读取输出张量值",
    "1208": "调整大小、裁剪、旋转和归一化图像",
    "1209": "调整数据集形状",
    "1210": "调整输入图像大小以匹配模型输入要求",
    "1211": "调用 Python API 或命令行进行转换",
    "1212": "调用 TensorFlow Lite 解释器的方式：try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) { interpreter.run(input, output); }",
    "1213": "调用CSI摄像头和USB摄像头",
    "1214": "调用model.fit方法进行训练",
    "1215": "调用不同的硬件加速器比如 GPU 进行执行",
    "1216": "跨平台运行，包括 Android、iOS 以及基于 Linux 的 IoT 设备和微控制器",
    "1217": "转换 SavedModel 格式模型",
    "1218": "转换 concrete functions",
    "1219": "转换 tf.keras 模型",
    "1220": "转换为 TensorFlow Lite 模型",
    "1221": "转换和运行 TensorFlow 模型的工具",
    "1222": "转换图像数据类型为tf.float32",
    "1223": "转换数据",
    "1224": "转换模型",
    "1225": "软件源配置文件",
    "1226": "软链接",
    "1227": "轻量化和针对移动端及IoT设备端",
    "1228": "轻量级",
    "1229": "轻量级，在32 b 安卓平台下，编译核心运行时得到的库大小只有100 KB 左右",
    "1230": "输入层",
    "1231": "输出层",
    "1232": "输出数量等于类别数并使用softmax激活函数",
    "1233": "输出是一个三维的张量，形状描述了(height, width, channels)",
    "1234": "输出的通道数量取决于声明层时的filters参数",
    "1235": "输出通道数为32",
    "1236": "输出通道数为64",
    "1237": "输出通道数量由filters参数决定",
    "1238": "边做边学的理想工具",
    "1239": "边缘",
    "1240": "边缘操作",
    "1241": "边缘计算",
    "1242": "边缘计算设备",
    "1243": "迁移学习",
    "1244": "运行TFLite推理并获取输出概率",
    "1245": "运行功率仅为 5 瓦",
    "1246": "运行各种深度学习模型",
    "1247": "运行在 Node.js 或浏览器环境中",
    "1248": "运行已有的 Python 版 TensorFlow 模型",
    "1249": "运行服务监听的IP地址、端口、notebooks内核目录、浏览器开关设置",
    "1250": "运行模型推理",
    "1251": "返回图像中每张人脸的128维人脸编码",
    "1252": "返回张量数据的副本",
    "1253": "返回的是数据的副本而非引用",
    "1254": "进行VNC连接",
    "1255": "进行内存清理工作，防止内存泄露",
    "1256": "远程桌面访问Jetson Nano",
    "1257": "连接LED灯的正极",
    "1258": "连接LED灯的负极形成回路",
    "1259": "连接其他电子设备",
    "1260": "连接按键的一个引脚",
    "1261": "连接显示器、键盘和鼠标或通过SSH/VNC远程访问",
    "1262": "连接树莓派和面包板上的元件",
    "1263": "适用于多个平台",
    "1264": "适用于多个平台，提供了一个简单的 API",
    "1265": "适用于移动和嵌入式设备的轻量级推理框架",
    "1266": "选择模型",
    "1267": "选择模型、转换模型、部署到设备、优化模型",
    "1268": "选择模型，转换模型，部署到设备，优化模型",
    "1269": "逐步加载单个数据集的图像",
    "1270": "通过 pip 安装",
    "1271": "通过GPIO控制展示基础硬件控制能力",
    "1272": "通过script标签引入index.js",
    "1273": "通过下载源代码来安装，使用GIT工具下载代码，然后编译安装",
    "1274": "通过利用 WebGL 在 GPU 上执行计算大幅提高了速度",
    "1275": "通过脚本标签（script tags）或从 yarn（或者 NPM）安装并使用 Parcel，WebPack 或 Rollup 等工具构建工程",
    "1276": "通过计算每个滑动窗口的最大值来缩减卷积结果的大小",
    "1277": "通过许多正负样例中训练得到cascade方程，然后将其应用于其他图片",
    "1278": "遍历所有样本50次",
    "1279": "郁金香(tulips)、玫瑰(roses)、浦公英(dandelion)、向日葵(sunflowers)、雏菊(daisy)",
    "1280": "部署TensorFlow Lite模型",
    "1281": "部署到设备",
    "1282": "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上",
    "1283": "配置build.gradle文件",
    "1284": "配置文件",
    "1285": "配置模型的优化器和损失函数",
    "1286": "配置项目依赖",
    "1287": "采用更小的模型格式，并提供了方便的模型转换器",
    "1288": "采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式",
    "1289": "采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型",
    "1290": "释放张量的GPU内存",
    "1291": "量化",
    "1292": "针对移动设备构建",
    "1293": "错误的连接和编程可能会导致设备损坏或故障",
    "1294": "镜像",
    "1295": "防止 Android 在生成应用程序二进制文件时压缩 TensorFlow Lite 模型文件",
    "1296": "防止应用程序中的内存泄漏",
    "1297": "阻塞函数，会阻塞程序执行直到检测到一个边沿",
    "1298": "阿里、清华等",
    "1299": "降低卷积层对位置的敏感",
    "1300": "降低存储器访问成本",
    "1301": "降低权重的精确表示，并且可选的降低存储和计算的激活值",
    "1302": "降低权重的精确表示，降低存储和计算的激活值",
    "1303": "降低用于读取和存储中间激活值的存储器访问成本",
    "1304": "降低移动端及IoT设备端的深度学习技术门槛",
    "1305": "限流电阻",
    "1306": "随机打乱数据集",
    "1307": "随着层越来越高，这些功能越来越多地针对训练模型的数据集",
    "1308": "需要root权限",
    "1309": "需要使用GStreamer读取视频流",
    "1310": "需要大约两个半小时",
    "1311": "需要小心谨慎使用",
    "1312": "需要成功配置好 CUDA",
    "1313": "需要更多灵活性和控制时使用",
    "1314": "需要注意版本变化",
    "1315": "需要设置VNC密码和启用自动登录",
    "1316": "需要配置 proxy 或使用国内镜像以获取 SDK 和 gradle 编译环境",
    "1317": "需要重启树莓派",
    "1318": "需要高准确率",
    "1319": "静态图片分辨率为3280 × 2464",
    "1320": "面包板",
    "1321": "页面的基本结构，包含div标签、UI元素和JavaScript代码插入",
    "1322": "项目的清单文件",
    "1323": "预加载了ImageNet训练权重的深度学习模型",
    "1324": "预处理模型输入和后处理模型输出",
    "1325": "预测汽车油耗效率",
    "1326": "预测汽车油耗（MPG）",
    "1327": "预测汽车的油耗效率 MPG",
    "1328": "预测结果",
    "1329": "预训练模型和全连接的分类器",
    "1330": "预训练模型将忘记它学到的东西",
    "1331": "首次打开项目时",
    "1332": "验证损失高于训练损失，可能存在过拟合",
    "1333": "验证集",
    "1334": "高性能",
    "1335": "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）",
    "1336": "默认安装 JetPack 安装了对应的 OpenCV"
  }
}