[
  [
    "train_generator",
    "用途",
    "从指定目录生成训练数据批次"
  ],
  [
    "train_generator",
    "特点",
    "支持图像大小调整和批量处理"
  ],
  [
    "val_generator",
    "用途",
    "从指定目录生成验证数据批次"
  ],
  [
    "val_generator",
    "特点",
    "支持图像大小调整和批量处理"
  ],
  [
    "MobileNetV2",
    "是什么",
    "预加载了ImageNet训练权重的深度学习模型"
  ],
  [
    "MobileNetV2",
    "用途",
    "作为迁移学习的基础模型"
  ],
  [
    "MobileNetV2",
    "特点",
    "支持自定义输入形状和是否包含顶层分类器"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "支持设备端机器学习推断"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "延迟较低"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件很小"
  ],
  [
    "MobileNet V2",
    "用途",
    "将图片分类到1000类"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "瓶颈层"
  ],
  [
    "MobileNet V2",
    "特点",
    "保留原来大规模训练的优势"
  ],
  [
    "include_top=False",
    "用途",
    "不需要原有模型中最后的神经网络层"
  ],
  [
    "迁移学习",
    "用途",
    "改造模型"
  ],
  [
    "model.trainable = False",
    "用途",
    "基础模型的各项参数变量不会被新的训练修改数据"
  ],
  [
    "瓶颈层",
    "特点",
    "保持了很多通用性"
  ],
  [
    "GlobalAveragePooling2D",
    "用途",
    "将特征转换为每个图像对应一个1280元素向量"
  ],
  [
    "tf.keras.Sequential",
    "组成部分",
    "base_model, Conv2D, Dropout, GlobalAveragePooling2D, Dense"
  ],
  [
    "Dense",
    "特点",
    "5个节点的输出层"
  ],
  [
    "categorical_crossentropy",
    "用途",
    "损失函数"
  ],
  [
    "mobilenetv2_1.00_224",
    "组成部分",
    "conv2d, dropout, global_average_pooling2d, dense"
  ],
  [
    "mobilenetv2_1.00_224",
    "特点",
    "Total params: 2,626,821, Trainable params: 368,837, Non-trainable params: 2,257,984"
  ],
  [
    "model.fit",
    "执行步骤",
    "train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=val_generator, validation_steps=len(val_generator)"
  ],
  [
    "微调",
    "条件",
    "设置 model.trainable = False"
  ],
  [
    "微调",
    "用途",
    "提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练"
  ],
  [
    "微调",
    "特点",
    "训练期间将不更新预训练网络的权重，只在 MobileNet V2基础模型上训练了几层"
  ],
  [
    "微调",
    "结果",
    "预训练模型将忘记它学到的东西"
  ],
  [
    "微调",
    "步骤",
    "取消冻结模型的顶层，设置 base_model.trainable = True"
  ],
  [
    "MobileNet V2",
    "特点",
    "前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像"
  ],
  [
    "MobileNet V2",
    "特点",
    "随着层越来越高，这些功能越来越多地针对训练模型的数据集"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "算子库(Op kernels)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为方便解释器使用的格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "引入优化以减小二进制文件的大小和提高性能"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "安卓应用只需 1 兆左右的运行环境"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "在 MCU 上甚至可以小于 100KB"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "目前有130个左右"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "与 TensorFlow 的核心算子库略有不同"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "做了移动设备相关的优化"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "利用 ARM 的 NEON 指令集做了大量的优化"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "可以利用手机上的加速器，比如 GPU 或者 DSP"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "支持 Android 神经网络 API（Android NN API)"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "155层网络"
  ],
  [
    "微调",
    "步骤",
    "取消冻结模型的顶层"
  ],
  [
    "微调",
    "步骤",
    "设置前100层为不可训练"
  ],
  [
    "微调",
    "步骤",
    "使用低学习率重新编译模型"
  ],
  [
    "微调",
    "优点",
    "使模型准确率提高几个百分点"
  ],
  [
    "微调",
    "缺点",
    "可能导致模型过拟合"
  ],
  [
    "TFLite",
    "用途",
    "将TensorFlow模型转换为轻量级格式"
  ],
  [
    "SavedModel",
    "特点",
    "包含完整的TensorFlow程序"
  ],
  [
    "SavedModel",
    "特点",
    "不需要原始模型构建代码就可以运行"
  ],
  [
    "模型训练",
    "条件",
    "设置model.trainable = False"
  ],
  [
    "模型训练",
    "结果",
    "不更新预训练网络的权重"
  ],
  [
    "梯度下降",
    "缺点",
    "可能导致预训练模型忘记已学内容"
  ],
  [
    "fine_tune_at",
    "是什么",
    "指定从哪个层开始进行微调的参数"
  ],
  [
    "fine_tune_at",
    "用途",
    "控制迁移学习中微调的起始层"
  ],
  [
    "fine_tune_at",
    "示例",
    "设置为100表示从第100层开始微调"
  ],
  [
    "MobileNet V2",
    "用途",
    "创建、训练和导出自定义 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "模型文件和标签文件"
  ],
  [
    "Android 应用",
    "用途",
    "识别花卉图片"
  ],
  [
    "TensorFlow Lite 示例",
    "来源",
    "TensorFlow 官网"
  ],
  [
    "flower_classification",
    "组成部分",
    "android 目录"
  ],
  [
    "flower_classification 项目",
    "包含",
    "start 目录和 finish 目录"
  ],
  [
    "Android Studio",
    "用途",
    "开发 Android 应用"
  ],
  [
    "Android Studio",
    "用途",
    "打开现有 Android Studio 项目"
  ],
  [
    "Android Studio",
    "组成部分",
    "启动图标"
  ],
  [
    "Android Studio",
    "组成部分",
    "打开项目图标"
  ],
  [
    "TensorFlow Lite 模型文件",
    "用途",
    "用于 flower_classification 项目"
  ],
  [
    "label.txt",
    "用途",
    "用于 flower_classification 项目"
  ],
  [
    "build.gradle",
    "用途",
    "配置项目依赖"
  ],
  [
    "build.gradle",
    "组成部分",
    "dependencies"
  ],
  [
    "org.tensorflow:tensorflow-lite:+",
    "用途",
    "导入 TensorFlow Lite 库"
  ],
  [
    "Gradle 同步",
    "条件",
    "首次打开项目时"
  ],
  [
    "Gradle 同步",
    "步骤",
    "将模型文件拷贝到 assets 目录下"
  ],
  [
    "TensorFlow Lite 转换器",
    "可以接受",
    "Keras Model 和 SavedModel"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为 TFLite 格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "执行步骤",
    "调用 Python API 或命令行进行转换"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "支持算子优化和常见的编译优化"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "支持量化原生支持"
  ],
  [
    "TensorFlow Lite 转换器",
    "组成部分",
    "优化的算子内核"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "在移动设备上实现性能大幅度提升"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "是",
    "Python API 调用方式"
  ],
  [
    "TFLiteConverter.from_keras_model()",
    "是",
    "Python API 调用方式"
  ],
  [
    "tflite_convert",
    "是",
    "命令行调用方式"
  ],
  [
    "训练后量化",
    "特点",
    "不需要改变模型，最少情况只需多加一行代码"
  ],
  [
    "MobileNet V2",
    "包含",
    "155层"
  ],
  [
    "微调过程",
    "步骤",
    "冻结前100层，设置不可训练"
  ],
  [
    "微调过程",
    "步骤",
    "使用低学习率编译模型"
  ],
  [
    "微调过程",
    "步骤",
    "恢复训练"
  ],
  [
    "模型编译",
    "组成部分",
    "损失函数为categorical_crossentropy"
  ],
  [
    "模型编译",
    "组成部分",
    "优化器为Adam"
  ],
  [
    "模型编译",
    "组成部分",
    "评估指标为accuracy"
  ],
  [
    "模型训练",
    "结果",
    "精度达到98%"
  ],
  [
    "模型训练",
    "缺点",
    "验证损失高于训练损失，可能存在过拟合"
  ],
  [
    "TFLite转换",
    "步骤",
    "使用tf.saved_model.save保存模型"
  ],
  [
    "TFLite转换",
    "步骤",
    "使用TFLiteConverter转换为TFLite格式"
  ],
  [
    "TFLite模型",
    "特点",
    "包含完整的TensorFlow程序"
  ],
  [
    "TFLite模型",
    "特点",
    "不需要原始模型构建代码"
  ],
  [
    "Android部署",
    "步骤",
    "下载TensorFlow Lite示例源码"
  ],
  [
    "Android部署",
    "步骤",
    "安装Android Studio"
  ],
  [
    "Android部署",
    "步骤",
    "拷贝模型和标签文件到assets目录"
  ],
  [
    "Android部署",
    "步骤",
    "配置build.gradle文件"
  ],
  [
    "build.gradle",
    "组成部分",
    "添加tensorflow-lite依赖"
  ],
  [
    "build.gradle",
    "组成部分",
    "设置aaptOptions防止模型压缩"
  ],
  [
    "TensorFlow Lite解释器",
    "用途",
    "执行模型推理"
  ],
  [
    "TensorFlow Lite解释器",
    "组成部分",
    "GPU代理"
  ],
  [
    "TensorFlow Lite解释器",
    "组成部分",
    "模型执行流图"
  ],
  [
    "推理过程",
    "步骤",
    "数据转换"
  ],
  [
    "推理过程",
    "步骤",
    "执行推理"
  ],
  [
    "推理过程",
    "步骤",
    "解释输出"
  ],
  [
    "图像预处理",
    "步骤",
    "使用ImageProcessor进行resize和normalize"
  ],
  [
    "PoseNet模型",
    "用途",
    "人体姿势估计"
  ],
  [
    "PoseNet模型",
    "特点",
    "检测关键身体部位的位置"
  ],
  [
    "aaptOptions",
    "用途",
    "防止 Android 在生成应用程序二进制文件时压缩 TensorFlow Lite 模型文件"
  ],
  [
    "aaptOptions",
    "组成部分",
    "noCompress \"tflite\""
  ],
  [
    "Android Studio",
    "条件",
    "需要配置 proxy 或使用国内镜像以获取 SDK 和 gradle 编译环境"
  ],
  [
    "build.gradle",
    "组成部分",
    "buildscript"
  ],
  [
    "buildscript",
    "组成部分",
    "repositories 和 dependencies"
  ],
  [
    "repositories",
    "示例",
    "maven { url '[URL]' }"
  ],
  [
    "dependencies",
    "示例",
    "classpath 'com.android.tools.build:gradle:...'"
  ],
  [
    "TensorFlow Lite解释器",
    "用途",
    "执行模型推理过程"
  ],
  [
    "TensorFlow Lite解释器",
    "组成部分",
    "模型执行流图"
  ],
  [
    "ClassifierFloatMobileNet类",
    "包含",
    "model.tflite和label.txt"
  ],
  [
    "Classifier类",
    "包含",
    "TFLite解释器和GPU代理"
  ],
  [
    "GPU代理",
    "用途",
    "加速模型推理过程"
  ],
  [
    "TFLite解释器",
    "执行步骤",
    "创建实例并加载模型"
  ],
  [
    "TensorFlow Lite支持库",
    "用途",
    "简化图像预处理和输出处理"
  ],
  [
    "ImageProcessor",
    "用途",
    "对输入图像进行预处理"
  ],
  [
    "ImageProcessor",
    "执行步骤",
    "调整大小、裁剪、旋转和归一化图像"
  ],
  [
    "recognizeImage方法",
    "执行步骤",
    "运行TFLite推理并获取输出概率"
  ],
  [
    "TensorLabel",
    "用途",
    "将模型输出概率与类别标签关联"
  ],
  [
    "PoseNet模型",
    "用途",
    "实现人体姿势估计"
  ],
  [
    "PoseNet模型",
    "执行步骤",
    "检测关键身体部位的位置"
  ],
  [
    "PoseNet示例应用程序",
    "执行步骤",
    "获取图像数据、处理图像、调用姿势估计函数、绘制关键点"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "Python API"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是什么",
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "用途",
    "转换 SavedModel 格式模型"
  ],
  [
    "TFLiteConverter.from_keras_model()",
    "用途",
    "转换 tf.keras 模型"
  ],
  [
    "TFLiteConverter.from_concrete_functions()",
    "用途",
    "转换 concrete functions"
  ],
  [
    "TensorFlow 2.x 模型",
    "特点",
    "使用 SavedModel 格式存储"
  ],
  [
    "TensorFlow 2.x 模型",
    "生成方式",
    "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）"
  ],
  [
    "SavedModel",
    "用途",
    "转换为 TensorFlow Lite 模型"
  ],
  [
    "Keras 模型",
    "用途",
    "转换为 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "端侧机器学习"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "图像处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "文本处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "语音识别"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "OCR处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "AR效果"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "文字处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "离线语音识别"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "IoT领域"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "智能质检一体机"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "智能读码机"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "高性能"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "模型优化工具"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "支持微控制器(MCU)"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "支持Linux SoC"
  ],
  [
    "网易",
    "用途",
    "OCR处理"
  ],
  [
    "爱奇艺",
    "用途",
    "视频中的AR效果"
  ],
  [
    "WPS",
    "用途",
    "文字处理"
  ],
  [
    "Google Photos",
    "用途",
    "图像和视频处理"
  ],
  [
    "Google Assistant",
    "用途",
    "移动端语音识别"
  ],
  [
    "Google Assistant",
    "用途",
    "语音功能部署"
  ],
  [
    "Live Caption",
    "用途",
    "自动将视频和对话中的语言转化为文字"
  ],
  [
    "出门问问智能音箱",
    "用途",
    "热词唤醒"
  ],
  [
    "科沃斯扫地机器人",
    "用途",
    "室内避开障碍物"
  ],
  [
    "创新奇智",
    "用途",
    "智能质检一体机"
  ],
  [
    "创新奇智",
    "用途",
    "智能读码机"
  ],
  [
    "MCU",
    "是什么",
    "单一芯片的小型计算机"
  ],
  [
    "MCU",
    "特点",
    "没有操作系统"
  ],
  [
    "MCU",
    "特点",
    "内存只有几十KB"
  ],
  [
    "TFLite模型",
    "特点",
    "模型大小只有20KB左右"
  ],
  [
    "TFLite模型",
    "示例",
    "识别若干关键词的语音识别模型"
  ],
  [
    "TFLite模型",
    "示例",
    "简单的姿态检测模型"
  ],
  [
    "科沃斯扫地机器人",
    "结果",
    "推理速度提高了30%"
  ],
  [
    "科沃斯扫地机器人",
    "结果",
    "提高了用户的体验"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "执行步骤",
    "选择模型、转换模型、部署到设备、优化模型"
  ],
  [
    "选择模型",
    "用途",
    "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的 TensorFlow 预训练模型中选择一个模型直接使用或重新训练"
  ],
  [
    "转换模型",
    "用途",
    "使用 TensorFlow Lite 转换器将模型转换为 TensorFlow Lite 格式"
  ],
  [
    "部署到设备",
    "用途",
    "使用 TensorFlow Lite 解释器（提供多种语言的 API）在设备端运行模型"
  ],
  [
    "优化模型",
    "用途",
    "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "提供多种语言的 API"
  ],
  [
    "模型优化工具包",
    "用途",
    "缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "实现花卉识别 app"
  ],
  [
    "花卉识别 app",
    "运行平台",
    "Android 设备"
  ],
  [
    "花卉识别 app",
    "使用模型",
    "MobileNets_v2"
  ],
  [
    "花卉识别 app",
    "功能",
    "实时识别照相机所拍摄的花卉"
  ],
  [
    "花卉识别模型",
    "实现方法",
    "迁移学习"
  ],
  [
    "花卉识别模型",
    "转换工具",
    "TFLite 转换器"
  ],
  [
    "Android 应用",
    "使用组件",
    "TFLite 解释器"
  ],
  [
    "TensorFlow Lite 支持库",
    "用途",
    "预处理模型输入和后处理模型输出"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在不同设备上使用硬件加速"
  ],
  [
    "TensorFlow Lite 解释器",
    "包含",
    "委托（Delegates）"
  ],
  [
    "GPU 委托",
    "用途",
    "允许解释器在设备的 GPU 上运行适当的运算符"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在 Android 与 iOS 平台上使用"
  ],
  [
    "Android 开发人员",
    "用途",
    "TensorFlow Lite AAR"
  ],
  [
    "iOS 开发人员",
    "用途",
    "CocoaPods for Swift or Objective-C"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "执行模型文件在输入数据上定义的运算符，输出推理结果"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "适用于多个平台"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "提供简单的 API 用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型"
  ],
  [
    "Java",
    "示例",
    "调用 TensorFlow Lite 解释器的方式：try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) { interpreter.run(input, output); }"
  ],
  [
    "GPU",
    "优点",
    "比 CPU 执行更快的浮点矩阵运算"
  ],
  [
    "GPU",
    "示例",
    "在有 GPU 加速的手机上运行 MobileNet 图像分类，模型运行速度可以提高"
  ],
  [
    "TFLite 模型文件格式",
    "是",
    "FlatBuffers 格式"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "注重实时性，内存高效"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "支持将文件映射到内存中，直接进行读取和解释，不需要额外解析"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "减少内存碎片化"
  ],
  [
    "TFLite 模型文件格式",
    "组成部分",
    "子图、算子库和共享的内存缓冲区"
  ],
  [
    "TFLite 模型文件格式",
    "定义",
    "由 schema.fbs 文件使用 FlatBuffers 定义"
  ],
  [
    "张量",
    "用途",
    "存储模型权重，或者计算节点的输入和输出"
  ],
  [
    "张量",
    "特点",
    "引用 Model 的内存缓冲区的一片区域，提高内存效率"
  ],
  [
    "算子实现",
    "组成部分",
    "OperatorCode"
  ],
  [
    "OperatorCode",
    "特点",
    "可以是内置的算子，也可以是自定制算子，有一个名字"
  ],
  [
    "计算节点",
    "组成部分",
    "用到的算子索引，以及输入输出用到的 Tensor 索引"
  ],
  [
    "子图",
    "组成部分",
    "一系列的计算节点、多个张量，以及子图本身的输入和输出"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件的大小约为 1 MB（针对 32 位 ARM build）"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "TensorFlow Lite 解释器(Interpreter)和 TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "算子库(Op kernels)和硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow Lite",
    "应用",
    "Google Assistant，Google Photos，Uber，Airbnb，网易，爱奇艺和 WPS 等"
  ],
  [
    "TensorFlow Lite",
    "应用",
    "图像、文本和语音处理"
  ],
  [
    "TensorFlow Lite",
    "应用",
    "支持微控制器(MCU)，应用于 IoT 领域"
  ],
  [
    "TensorFlow Lite",
    "工作原理",
    "采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式"
  ],
  [
    "TensorFlow Lite",
    "工作原理",
    "采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型"
  ],
  [
    "TensorFlow Lite",
    "工作原理",
    "利用手机上的加速器，比如 GPU 或者 DSP 等"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为 TensorFlow Lite 格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "支持算子优化和常见的编译优化，比如算子融合、常数折叠或无用代码删除等"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "支持量化的原生支持"
  ],
  [
    "FlatBuffers 格式",
    "用途",
    "TFLite 模型文件格式，更注重考虑实时性，内存高效"
  ],
  [
    "FlatBuffers 格式",
    "特点",
    "支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析"
  ],
  [
    "TensorFlow Lite 解释执行器",
    "特点",
    "轻量级，在32 b 安卓平台下，编译核心运行时得到的库大小只有100 KB 左右"
  ],
  [
    "TensorFlow Lite 解释执行器",
    "特点",
    "快速启动，能够将模型直接映射到内存中，同时有一个静态执行计划"
  ],
  [
    "TensorFlow Lite 解释执行器",
    "特点",
    "内存高效，采取静态内存分配"
  ],
  [
    "TensorFlow Lite 解释执行器",
    "执行步骤",
    "加载模型，转换数据，运行模型推理，解释输出"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "执行步骤",
    "选择模型，转换模型，部署到设备，优化模型"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "提供训练好的模型，开发人员可以复用这些已经训练好且经过充分认证的模型"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite 模型",
    "特点",
    "优化的 FlatBuffer 格式，以 .tflite 为文件扩展名"
  ],
  [
    "TensorFlow Lite 转换器",
    "组成部分",
    "命令行工具和 Python API"
  ],
  [
    "FlatBuffers",
    "用途",
    "主要应用于游戏场景，是为了高性能场景创建的序列化库"
  ],
  [
    "FlatBuffers",
    "优点",
    "相比 Protocol Buffer 有更高的性能和更小的大小"
  ],
  [
    "FlatBuffers",
    "用途",
    "更适合于边缘设备部署"
  ],
  [
    "tflite_convert",
    "是",
    "TensorFlow Lite 转换器命令行工具"
  ],
  [
    "tflite_convert",
    "包含",
    "--output_file, --saved_model_dir, --keras_model_file, --enable_v1_converter"
  ],
  [
    "--output_file",
    "用途",
    "指定输出文件的绝对路径"
  ],
  [
    "--saved_model_dir",
    "用途",
    "指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录"
  ],
  [
    "--keras_model_file",
    "用途",
    "指定含有 TensorFlow 1.x 或者 2.0 使用 tf.keras model 生成 HDF5 文件的绝对路径目录"
  ],
  [
    "TensorFlow 模型导出",
    "包含",
    "SavedModel 和 Keras Sequential"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是",
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API"
  ],
  [
    "tf.lite.TFLiteConverter",
    "包含",
    "from_saved_model(), from_keras_model(), from_concrete_functions()"
  ],
  [
    "TensorFlow 2.x 模型",
    "特点",
    "使用 SavedModel 格式存储"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "用途",
    "将SavedModel转换为TFLite模型"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "输入参数",
    "saved_model_dir"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "输出结果",
    "converter"
  ],
  [
    "TFLite 模型转换过程",
    "步骤",
    "用户在自己的工作台中使用 TensorFlow API 构造 TensorFlow 模型"
  ],
  [
    "TFLite 模型转换过程",
    "步骤",
    "使用 TFLite 模型转换器转换成 TFLite 文件格式(FlatBuffers 格式)"
  ],
  [
    "TFLite 解释器",
    "用途",
    "接受 TFLite 模型"
  ],
  [
    "TFLite 解释器",
    "用途",
    "调用不同的硬件加速器比如 GPU 进行执行"
  ],
  [
    "TFLite 文件格式",
    "是",
    "FlatBuffers 格式"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "轻量级"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "快速启动"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "内存高效"
  ],
  [
    "TFLite 解释执行器",
    "组成部分",
    "核心运行时"
  ],
  [
    "TFLite 解释执行器",
    "组成部分",
    "标准算子"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "加载模型"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "转换数据"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "运行模型推理"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "解释输出"
  ],
  [
    "TFLite 解释执行器",
    "用途",
    "针对移动设备构建"
  ],
  [
    "TFLite",
    "支持语言",
    "Java"
  ],
  [
    "TFLite",
    "支持语言",
    "C++"
  ],
  [
    "TFLite",
    "支持语言",
    "Python"
  ],
  [
    "TFLite",
    "支持语言",
    "C"
  ],
  [
    "TFLite",
    "支持语言",
    "Object C"
  ],
  [
    "TFLite",
    "支持语言",
    "C#"
  ],
  [
    "TFLite",
    "支持语言",
    "Swift"
  ],
  [
    "TFLite",
    "部署方式",
    "从头编译"
  ],
  [
    "TFLite",
    "部署方式",
    "使用已编译好的库"
  ],
  [
    "TFLite",
    "部署方式",
    "Android 开发者使用 JCenter Bintray 的 TFLite AAR"
  ],
  [
    "TFLite",
    "部署方式",
    "iOS 开发者通过 CocoaPods 获取"
  ],
  [
    "Keras模型",
    "转换为",
    "TensorFlow Lite模型"
  ],
  [
    "TensorFlow Lite模型",
    "保存为",
    "model.tflite文件"
  ],
  [
    "TensorFlow",
    "包含",
    "TensorFlow Lite"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在移动端、嵌入式和物联网设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow 模型",
    "是什么",
    "一种数据结构，包含了在解决特定问题时训练得到的机器学习网络的逻辑和知识"
  ],
  [
    "TensorFlow 模型",
    "用途",
    "解决特定问题的机器学习网络"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "转换和运行 TensorFlow 模型的工具"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "存放训练好的模型供开发人员复用"
  ],
  [
    "TensorFlow Hub",
    "特点",
    "提供经过充分认证的模型"
  ],
  [
    "训练好的模型",
    "用途",
    "直接部署或用于迁移学习"
  ],
  [
    "TensorFlow Hub",
    "组成部分",
    "Text, Image, Video 和 Publishers 等类别"
  ],
  [
    "MobileNet",
    "示例",
    "TensorFlow Hub 上可搜索到的模型"
  ],
  [
    "hub.KerasLayer",
    "用途",
    "加载 TensorFlow Hub 上的模型"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=1, input_shape=[1])"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=16, activation='relu')"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=1)"
  ],
  [
    "model.compile",
    "用途",
    "配置模型的优化器和损失函数"
  ],
  [
    "model.compile",
    "特点",
    "使用'sgd'作为优化器"
  ],
  [
    "model.compile",
    "特点",
    "使用'mean_squared_error'作为损失函数"
  ],
  [
    "TensorFlow",
    "是什么",
    "一个端到端的机器学习开源框架"
  ],
  [
    "TensorFlow",
    "特点",
    "支持大规模的模型训练和各种环境的部署"
  ],
  [
    "TensorFlow",
    "用途",
    "服务器和移动端的部署"
  ],
  [
    "TensorFlow",
    "支持",
    "多种编程语言包括Python, C++, Java, Swift和Javascript"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "轻量化和针对移动端及IoT设备端"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "降低移动端及IoT设备端的深度学习技术门槛"
  ],
  [
    "TensorFlow Lite",
    "属于",
    "TensorFlow团队开发的产品"
  ],
  [
    "TensorFlow Lite",
    "发布时间",
    "2017年底"
  ],
  [
    "tf.saved_model.save",
    "用途",
    "生成SavedModel"
  ],
  [
    "SavedModel",
    "是",
    "TensorFlow模型的序列化格式"
  ],
  [
    "tf.saved_model.save",
    "参数",
    "模型对象和保存路径"
  ],
  [
    "tf.saved_model.save",
    "执行步骤",
    "将Keras模型保存为SavedModel格式"
  ],
  [
    "MobileNet V2",
    "用途",
    "将图片分类到1000类"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "最后的神经网络层"
  ],
  [
    "include_top=False",
    "用途",
    "不需要原有模型中最后的神经网络层"
  ],
  [
    "迁移学习",
    "特点",
    "不改变基础模型的各项参数变量"
  ],
  [
    "迁移学习",
    "优点",
    "保留原来大规模训练的优势"
  ],
  [
    "model.trainable = False",
    "用途",
    "设置在训练中，基础模型的各项参数变量不会被新的训练修改数据"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "瓶颈层"
  ],
  [
    "瓶颈层",
    "特点",
    "保持了很多通用性"
  ],
  [
    "池化层",
    "用途",
    "对数据降维"
  ],
  [
    "输出层",
    "特点",
    "5个节点"
  ],
  [
    "GlobalAveragePooling2D",
    "用途",
    "将特征转换为每个图像对应一个1280元素向量"
  ],
  [
    "tf.keras model",
    "用途",
    "生成 HDF5 文件的绝对路径目录"
  ],
  [
    "TensorFlow 模型导出",
    "支持",
    "SavedModel 和 Keras Sequential 两种模型导出方法和格式"
  ],
  [
    "SavedModel",
    "示例",
    "tflite_convert --saved_model_dir=/tmp/mobilenet_saved_model --output_file=/tmp/mobilenet.tflite"
  ],
  [
    "Keras H5",
    "示例",
    "tflite_convert --keras_model_file=/tmp/mobilenet_keras_model.h5 --output_file=/tmp/mobilenet.tflite"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite 模型",
    "特点",
    "优化的 FlatBuffer 格式"
  ],
  [
    "TensorFlow Lite 模型",
    "文件扩展名",
    ".tflite"
  ],
  [
    "TensorFlow Lite 转换器",
    "使用方式",
    "命令行与 Python API"
  ],
  [
    "Google",
    "推荐",
    "使用 Python API 进行转换"
  ],
  [
    "命令行工具",
    "特点",
    "只提供了基本的转化功能"
  ],
  [
    "FlatBuffers",
    "用途",
    "主要应用于游戏场景"
  ],
  [
    "FlatBuffers",
    "特点",
    "为了高性能场景创建的序列化库"
  ],
  [
    "FlatBuffers",
    "优点",
    "相比 Protocol Buffer 有更高的性能和更小的大小"
  ],
  [
    "FlatBuffers",
    "用途",
    "更适合于边缘设备部署"
  ],
  [
    "tflite_convert",
    "属于",
    "命令行 TensorFlow Lite 转换器命令行工具"
  ],
  [
    "tflite_convert",
    "安装方式",
    "与 TensorFlow 一起安装"
  ],
  [
    "--output_file",
    "类型",
    "string"
  ],
  [
    "--output_file",
    "用途",
    "指定输出文件的绝对路径"
  ],
  [
    "--saved_model_dir",
    "类型",
    "string"
  ],
  [
    "--saved_model_dir",
    "用途",
    "指定含有 TensorFlow 1.x 或者 2.x SavedModel 的目录"
  ],
  [
    "--keras_model_file",
    "类型",
    "string"
  ],
  [
    "--keras_model_file",
    "用途",
    "指定 Keras H5 模型文件的绝对路径"
  ],
  [
    "--enable_v1_converter",
    "类型",
    "bool"
  ],
  [
    "--enable_v1_converter",
    "默认值",
    "False"
  ],
  [
    "--enable_v1_converter",
    "用途",
    "启用 TF 1.x 的转换器和标志"
  ],
  [
    "tf.lite.TFLiteConverter",
    "用途",
    "将Keras模型转换为TFLite模型"
  ],
  [
    "tf.lite.TFLiteConverter.from_keras_model",
    "步骤",
    "创建TFLite转换器实例"
  ],
  [
    "converter.convert",
    "步骤",
    "执行模型转换过程"
  ],
  [
    "MobileNet V2",
    "是",
    "基于流线型架构的轻量级深层神经网络"
  ],
  [
    "MobileNet V2",
    "用途",
    "图像分类任务"
  ],
  [
    "MobileNet V2",
    "特点",
    "使用深度可分离的卷积"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "预训练模型和全连接的分类器"
  ],
  [
    "迁移学习",
    "用途",
    "在小型数据集上训练模型"
  ],
  [
    "迁移学习",
    "步骤",
    "冻结预训练模型并更新分类器权重"
  ],
  [
    "迁移学习",
    "步骤",
    "微调预训练模型的顶层权重"
  ],
  [
    "ImageDataGenerator",
    "用途",
    "生成批次的图片数据用于模型训练"
  ],
  [
    "ImageDataGenerator",
    "特点",
    "支持像素缩放和数据增强"
  ],
  [
    "flow_from_directory",
    "用途",
    "逐步加载单个数据集的图像"
  ],
  [
    "flow_from_directory",
    "特点",
    "可以配置图像加载的细节"
  ],
  [
    "flow_from_directory",
    "参数",
    "target_size用于设置图像大小"
  ],
  [
    "flow_from_directory",
    "参数",
    "batch_size用于设置每批图像数量"
  ],
  [
    "flow_from_directory",
    "参数",
    "shuffle用于控制批处理顺序"
  ],
  [
    "TensorFlow Lite",
    "是",
    "在边缘设备上运行 TensorFlow 模型推理的官方框架"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "跨平台运行，包括 Android、iOS 以及基于 Linux 的 IoT 设备和微控制器"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "更轻量，二进制文件的大小约为 1 MB（针对 32 位 ARM build）"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "能够利用各种硬件加速"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "特别为各种端侧设备优化的算子库"
  ],
  [
    "TF Mobile",
    "是",
    "Google 尝试简化 TensorFlow 并在移动设备上运行的项目"
  ],
  [
    "TF Mobile",
    "特点",
    "缩减版的 TensorFlow，简化了算子集，也缩小了运行库"
  ],
  [
    "TFMini",
    "是",
    "Google 内部用于计算机视觉场景的解决方案"
  ],
  [
    "TFMini",
    "用途",
    "提供转换工具压缩模型，进行算子融合并生成代码"
  ],
  [
    "TFMini",
    "特点",
    "将模型嵌入到二进制文件中，这样就可以在设备上运行和部署模型"
  ],
  [
    "TFMini",
    "缺点",
    "在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战"
  ],
  [
    "TensorFlow Lite",
    "继承",
    "TF Mobile 的经验"
  ],
  [
    "TensorFlow Lite",
    "继承",
    "TFMini 和内部其他类似项目的很多优秀工作"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "优化模型大小和性能"
  ],
  [
    "模型优化",
    "目标",
    "在给定设备上实现性能、模型大小和准确性的理想平衡"
  ],
  [
    "大而复杂的模型",
    "特点",
    "需要高准确率"
  ],
  [
    "小一点的模型",
    "特点",
    "占用更少的磁盘和内存，更快更高效"
  ],
  [
    "量化",
    "用途",
    "降低权重的精确表示，降低存储和计算的激活值"
  ],
  [
    "量化",
    "优点",
    "对现有 CPU 平台的支持"
  ],
  [
    "量化",
    "优点",
    "降低用于读取和存储中间激活值的存储器访问成本"
  ],
  [
    "量化",
    "优点",
    "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，对量化特别有益"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "post-training quantization"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "Quantization-aware training"
  ],
  [
    "post-training quantization",
    "用途",
    "使权重和激活值的 Post training 更简单"
  ],
  [
    "Quantization-aware training",
    "用途",
    "以最小精度下降来训练网络"
  ],
  [
    "Quantization-aware training",
    "条件",
    "仅适用于卷积神经网络的一个子集"
  ],
  [
    "Python 代码片段",
    "示例",
    "使用预训练量化进行模型转换"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "执行模型文件在输入数据上定义的运算符，输出推理结果"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "适用于多个平台，提供了一个简单的 API"
  ],
  [
    "TensorFlow Lite 解释器",
    "组成部分",
    "GPU 委托"
  ],
  [
    "GPU",
    "优点",
    "比 CPU 执行更快的浮点矩阵运算"
  ],
  [
    "GPU 委托",
    "用途",
    "允许解释器在设备的 GPU 上运行适当的运算符"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "优化模型大小和性能"
  ],
  [
    "量化",
    "用途",
    "降低权重的精确表示，并且可选的降低存储和计算的激活值"
  ],
  [
    "量化",
    "优点",
    "对现有 CPU 平台的支持"
  ],
  [
    "量化",
    "优点",
    "降低存储器访问成本"
  ],
  [
    "量化",
    "优点",
    "对 SIMD 指令功能特别有益"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "Post training quantization 和 Quantization-aware training"
  ],
  [
    "MobileNet V2",
    "用途",
    "实现识别花卉模型"
  ],
  [
    "MobileNet V2",
    "特点",
    "基于一个流线型的架构，使用深度可分离的卷积"
  ],
  [
    "迁移学习",
    "用途",
    "利用在同一域中的较大数据集上训练的模型所学习的特征"
  ],
  [
    "ImageDataGenerator",
    "用途",
    "生成一个批次一个批次的图片，以生成器的形式给模型训练"
  ],
  [
    "flow_from_directory",
    "用途",
    "逐步加载单个数据集的图像"
  ],
  [
    "build.gradle",
    "间接包含",
    "repositories 和 dependencies"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "算子库(Op kernels)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "模型文件和标签文件"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Python API"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)和 TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "算子库(Op kernels)和硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "转换和运行 TensorFlow 模型的工具"
  ],
  [
    "TensorFlow",
    "间接包含",
    "特别为各种端侧设备优化的算子库"
  ],
  [
    "TensorFlow",
    "间接包含",
    "post-training quantization"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Quantization-aware training"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Post training quantization 和 Quantization-aware training"
  ],
  [
    "train_generator",
    "可能与...相关",
    "val_generator"
  ],
  [
    "MobileNet V2",
    "可能与...相关",
    "MobileNet V2"
  ],
  [
    "include_top=False",
    "可能与...相关",
    "include_top=False"
  ],
  [
    "瓶颈层",
    "可能与...相关",
    "瓶颈层"
  ],
  [
    "GlobalAveragePooling2D",
    "可能与...相关",
    "GlobalAveragePooling2D"
  ],
  [
    "SavedModel",
    "可能与...相关",
    "TFLite模型"
  ],
  [
    "TensorFlow Lite 模型文件",
    "可能与...相关",
    "label.txt"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "可能与...相关",
    "TFLiteConverter.from_keras_model()"
  ],
  [
    "TensorFlow Lite解释器",
    "可能与...相关",
    "TensorFlow Lite解释器"
  ],
  [
    "TensorFlow 2.x 模型",
    "可能与...相关",
    "TensorFlow 2.x 模型"
  ],
  [
    "SavedModel",
    "可能与...相关",
    "Keras 模型"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "网易"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "WPS"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "创新奇智"
  ],
  [
    "GPU 委托",
    "可能与...相关",
    "GPU 委托"
  ],
  [
    "TensorFlow Lite 解释器",
    "可能与...相关",
    "TensorFlow Lite 解释器"
  ],
  [
    "GPU",
    "可能与...相关",
    "GPU"
  ],
  [
    "TFLite 模型文件格式",
    "可能与...相关",
    "TFLite 文件格式"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "TensorFlow Lite"
  ],
  [
    "TensorFlow Lite 转换器",
    "可能与...相关",
    "TensorFlow Lite 转换器"
  ],
  [
    "FlatBuffers",
    "可能与...相关",
    "FlatBuffers"
  ],
  [
    "--output_file",
    "可能与...相关",
    "--output_file"
  ],
  [
    "--output_file",
    "可能与...相关",
    "--saved_model_dir"
  ],
  [
    "--output_file",
    "可能与...相关",
    "--keras_model_file"
  ],
  [
    "--saved_model_dir",
    "可能与...相关",
    "--keras_model_file"
  ],
  [
    "flow_from_directory",
    "可能与...相关",
    "flow_from_directory"
  ],
  [
    "量化",
    "可能与...相关",
    "量化"
  ]
]