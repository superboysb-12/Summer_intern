{
  "entity_to_id": {
    "--enable_v1_converter": 0,
    "--keras_model_file": 1,
    "--output_file": 2,
    "--output_file, --saved_model_dir, --keras_model_file, --enable_v1_converter": 3,
    "--saved_model_dir": 4,
    "-D WITH_QT=OFF 禁用了 Qt5 支持": 5,
    ".tflite": 6,
    "/dev": 7,
    "/etc/apt/sources.list": 8,
    "/opt/python 目录": 9,
    "/sys/class/gpio": 10,
    "/usr/bin/python": 11,
    "128核 NVIDIA Maxwell 架构的 GPU": 12,
    "128核NVIDIA Maxwell架构的GPU": 13,
    "14个引脚用于其他功能": 14,
    "155层网络": 15,
    "2.0.0": 16,
    "2.3.0": 17,
    "2.3.0版本": 18,
    "26个引脚可以用作数字输入或输出": 19,
    "3670 files belonging to 5 classes": 20,
    "3个Conv2D和2个MaxPooling2D层": 21,
    "40 针 GPIO 扩展接口": 22,
    "40个 GPIO 引脚": 23,
    "40个GPIO引脚": 24,
    "4GB 的内存并不能完全使用，其中有一部分（1GB 左右）是和显存共享的": 25,
    "5个节点": 26,
    "5个节点的输出层": 27,
    "6": 28,
    "64位四核的 ARM Cortex-A57": 29,
    "7": 30,
    "734 files for validation": 31,
    "8": 32,
    "800万像素、感光芯片为索尼 IMX219，静态图片分辨率为3280 × 2464、支持1080p30, 720p60以及640 × 480p90视频录像": 33,
    "9": 34,
    "<!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">": 35,
    "<html> <body> <h4>TFJS example<hr/></h4> <div id=\"micro-out-div\">TensorFlow.js Test</div> <script src=\"./index.js\"> </script> </body> </html>": 36,
    "@tensorflow/tfjs": 37,
    "@tensorflow/tfjs-vis": 38,
    "AC8265": 39,
    "ARM Cortex-A72": 40,
    "Adam优化器": 41,
    "Android": 42,
    "Android JCenter Bintray 的 TFLite AAR": 43,
    "Android Studio": 44,
    "Android 应用": 45,
    "Android 开发人员": 46,
    "Android、iOS 和 Linux等移动/嵌入式平台": 47,
    "Android、iOS、基于 Linux 的 IoT 设备和微控制器": 48,
    "Android环境部署": 49,
    "Android部署": 50,
    "B02版本有两路": 51,
    "BATCH_SIZE": 52,
    "BATCH_SIZE设置为512": 53,
    "BCM编号": 54,
    "BCM编号方式": 55,
    "BCM编号模式和物理引脚Broad编号模式": 56,
    "Broadcom针脚号，通常称的GPIO": 57,
    "C": 58,
    "C#": 59,
    "C++": 60,
    "C++ 和 Python 提供的 TensorFlow Lite API": 61,
    "CNN": 62,
    "CSI 摄像头": 63,
    "CSI 相机接口": 64,
    "CSI 端口": 65,
    "CSI摄像头": 66,
    "ClassifierFloatMobileNet类": 67,
    "Classifier类": 68,
    "CocoaPods for Swift or Objective-C": 69,
    "Conv2D": 70,
    "Conv2D, MaxPooling2D, Flatten, Dense层": 71,
    "Core API": 72,
    "DeepLearning.js": 73,
    "Dense": 74,
    "Display Port 接口": 75,
    "Dropout": 76,
    "Enables the converter and flags used in TF 1.x instead of TF 2.x": 77,
    "Etcher": 78,
    "Ethernet 有线网络": 79,
    "Face Recognition": 80,
    "FlatBuffers": 81,
    "FlatBuffers 格式": 82,
    "Full path of the output file": 83,
    "Full path to the Keras H5 model file": 84,
    "Full path to the SavedModel directory": 85,
    "GPIO.cleanup()方法": 86,
    "GPIO.setmod()": 87,
    "GPIO.setup()": 88,
    "GPIO.setup()方法": 89,
    "GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP)": 90,
    "GPIO21": 91,
    "GPIO口": 92,
    "GPIO库": 93,
    "GPIO引脚": 94,
    "GPIO引脚编号模式": 95,
    "GPU": 96,
    "GPU 委托": 97,
    "GPU代理": 98,
    "GStreamer": 99,
    "GStreamer管道": 100,
    "GlobalAveragePooling2D": 101,
    "Google": 102,
    "Google Arts & Culture": 103,
    "Google Assistant": 104,
    "Google Assistant、Google Photos、Uber、Airbnb、网易、爱奇艺、WPS等": 105,
    "Google Edge TPU Coral Dev Board": 106,
    "Google Photos": 107,
    "Google 内部用于计算机视觉场景的解决方案": 108,
    "GpuDelegate": 109,
    "Gradle 同步": 110,
    "HDMI 接口": 111,
    "HIGH电平": 112,
    "HTML": 113,
    "HTML 文件": 114,
    "HTML文件、JS文件和配置文件": 115,
    "Haar 特征分类器": 116,
    "Haar 特征的 cascade 分类器": 117,
    "Haar特征的cascade分类器": 118,
    "Hello AI World": 119,
    "I2C库": 120,
    "I2C接口(SCL、SDA)": 121,
    "IMAGE_WIDTH, IMAGE_HEIGHT, testData, testxs, labels, preds": 122,
    "ImageDataGenerator": 123,
    "ImageProcessor": 124,
    "Intel Neural Compute Stick 2": 125,
    "Interpreter": 126,
    "IoT领域": 127,
    "Java": 128,
    "Java 或 C++ API 执行 TensorFlow Lite 推理": 129,
    "JavaScript": 130,
    "JavaScript 代码": 131,
    "JavaScript 语言版本的扩展": 132,
    "JetBot": 133,
    "JetPack SDK": 134,
    "Jetson": 135,
    "Jetson Community Projects": 136,
    "Jetson Developer Kits": 137,
    "Jetson Nano": 138,
    "Jetson Nano CPU": 139,
    "Jetson Nano 开发板": 140,
    "Jupyter Notebook": 141,
    "Jupyter Notebook 的全面升级": 142,
    "Jupyter Notebook、文本编辑器、终端以及各种个性化组件": 143,
    "Jupyter lab": 144,
    "JupyterLab": 145,
    "Keras H5": 146,
    "Keras Model 和 SavedModel": 147,
    "Keras模型": 148,
    "Keras的模型定义方式": 149,
    "LED": 150,
    "LED灯": 151,
    "LED的控制引脚": 152,
    "LOW电平": 153,
    "Layers API": 154,
    "Layers API和Core API": 155,
    "Linux": 156,
    "Linux 中所有设备文件或特殊文件的存储位置": 157,
    "Linux 开发环境": 158,
    "Linux开发环境": 159,
    "Live Caption": 160,
    "MCU": 161,
    "MIPI": 162,
    "MIPI CSI-2 摄像头接口": 163,
    "MIPI 联盟发起的为移动应用处理器制定的开放标准": 164,
    "MNIST 分类器": 165,
    "MNIST数据集": 166,
    "MNIST模型训练": 167,
    "MaxPooling2D": 168,
    "Micro USB 接口": 169,
    "Micro-USB 接口": 170,
    "MnistData": 171,
    "MobileNet": 172,
    "MobileNet V2": 173,
    "MobileNetV2": 174,
    "MobileNetV2模型": 175,
    "NVIDIA Jetson Nano": 176,
    "NVIDIA Jetson Nano 开发板": 177,
    "NVIDIA Jetson 论坛": 178,
    "Object C": 179,
    "OpenCV": 180,
    "OpenCV 安装": 181,
    "OpenCV 安装脚本": 182,
    "OpenCV 编译": 183,
    "OperatorCode": 184,
    "PCB板上针脚的物理位置对应的编号（1~40）": 185,
    "PIN处于高电压点亮LED": 186,
    "PWM接口": 187,
    "Parcel": 188,
    "PoseNet": 189,
    "PoseNet模型": 190,
    "PoseNet示例应用程序": 191,
    "Post training quantization 和 Quantization-aware training": 192,
    "Python": 193,
    "Python 2.7": 194,
    "Python GPIO引脚": 195,
    "Python 官网": 196,
    "Python 模块": 197,
    "Python 源码包": 198,
    "Python 相关程序模块": 199,
    "Python 相关程序模块会拷贝到/opt/python": 200,
    "Python包管理": 201,
    "Python安装": 202,
    "Python程序": 203,
    "Quantization-aware training": 204,
    "RPI.GPIO库": 205,
    "RandomFlip": 206,
    "RandomRotation": 207,
    "Raspberry Camera V2": 208,
    "Raspberry Pi 4": 209,
    "Raspberry Pi、Arducam 等常见的相机模块": 210,
    "Raspbian软件仓库镜像": 211,
    "SD Memory Card Formatter": 212,
    "SPI库": 213,
    "SPI接口（MISO、MOSI、CLK、CS片选信号SPICE0_N）": 214,
    "SavedModel": 215,
    "SavedModel 和 Keras Sequential": 216,
    "SavedModel 和 Keras Sequential 两种模型导出方法和格式": 217,
    "SavedModel 格式": 218,
    "Sequential模型": 219,
    "Swift": 220,
    "Swift 和 Objective-C 编写的原生 iOS 库": 221,
    "SymbolicTensor和apply()方法": 222,
    "TF Mobile": 223,
    "TFLite": 224,
    "TFLite model": 225,
    "TFLite 文件格式": 226,
    "TFLite 模型文件": 227,
    "TFLite 模型文件格式": 228,
    "TFLite 模型文件格式，更注重考虑实时性，内存高效": 229,
    "TFLite 模型转换过程": 230,
    "TFLite 算子库": 231,
    "TFLite 解释器": 232,
    "TFLite 解释执行器": 233,
    "TFLite 转换器": 234,
    "TFLiteConverter": 235,
    "TFLiteConverter.from_concrete_functions()": 236,
    "TFLiteConverter.from_keras_model()": 237,
    "TFLiteConverter.from_saved_model()": 238,
    "TFLite模型转换器": 239,
    "TFLite解释器": 240,
    "TFLite解释器和GPU代理": 241,
    "TFMini": 242,
    "TensorFLow-vis": 243,
    "TensorFlow": 244,
    "TensorFlow 2.x 模型": 245,
    "TensorFlow GPU 版本": 246,
    "TensorFlow Hub": 247,
    "TensorFlow Hub 上的一个模型": 248,
    "TensorFlow Lite": 249,
    "TensorFlow Lite AAR": 250,
    "TensorFlow Lite API": 251,
    "TensorFlow Lite 工作流程": 252,
    "TensorFlow Lite 开发工作流程": 253,
    "TensorFlow Lite 推理": 254,
    "TensorFlow Lite 支持库": 255,
    "TensorFlow Lite 模型": 256,
    "TensorFlow Lite 模型文件": 257,
    "TensorFlow Lite 示例": 258,
    "TensorFlow Lite 算子库": 259,
    "TensorFlow Lite 解释器": 260,
    "TensorFlow Lite 解释器(Interpreter)": 261,
    "TensorFlow Lite 解释器、TensorFlow Lite 转换器、算子库、硬件加速代理": 262,
    "TensorFlow Lite 转换器": 263,
    "TensorFlow Lite 转换器(Converter)": 264,
    "TensorFlow Lite 转换器命令行工具": 265,
    "TensorFlow Lite支持库": 266,
    "TensorFlow Lite模型": 267,
    "TensorFlow Lite的工作流程": 268,
    "TensorFlow Lite的简称": 269,
    "TensorFlow Lite解释器": 270,
    "TensorFlow 官网": 271,
    "TensorFlow 模型": 272,
    "TensorFlow 模型导出": 273,
    "TensorFlow 的 JavaScript 版本": 274,
    "TensorFlow.js": 275,
    "TensorFlow.js 库的导入和版本打印": 276,
    "TensorFlow.js 模块": 277,
    "TensorFlow.js 进行浏览器可视化的一组实用工具库": 278,
    "TensorFlow.js中的中心数据单元，是一维或多维数组": 279,
    "TensorFlow模型的序列化格式": 280,
    "TensorLabel": 281,
    "Tensorflow Lite post-training quantization": 282,
    "Tensorflow.js": 283,
    "Total params: 2,626,821, Trainable params: 368,837, Non-trainable params: 2,257,984": 284,
    "UART串口接口（TXD、RXD）": 285,
    "UART库": 286,
    "USB": 287,
    "USB摄像头": 288,
    "VNC": 289,
    "VNC Viewer": 290,
    "WPS": 291,
    "Web Server for Chrome": 292,
    "Webpack": 293,
    "Wiring Pi": 294,
    "Wiring Pi编号": 295,
    "Wiring Pi编号模式": 296,
    "XML 文件，该文件中会描述人体各个部位的 Haar 特征值": 297,
    "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']": 298,
    "[num_examples, image_width, image_height, channels]": 299,
    "aaptOptions": 300,
    "acc": 301,
    "activation": 302,
    "add_event_detect()函数": 303,
    "allocate_tensors()": 304,
    "android 目录": 305,
    "base_model": 306,
    "batchSize": 307,
    "batch_size": 308,
    "batch_size默认值为32，可设置为64": 309,
    "build.gradle": 310,
    "buildscript": 311,
    "callback": 312,
    "cdn.jsdelivr.net": 313,
    "class_names": 314,
    "compare_faces": 315,
    "conv2d, dropout, global_average_pooling2d, dense": 316,
    "convertToTensor函数": 317,
    "converter.convert": 318,
    "createModel()": 319,
    "daisy, dandelion, roses, sunflowers, tulips": 320,
    "data.js": 321,
    "data.js文件": 322,
    "dense层": 323,
    "dependencies": 324,
    "dispose": 325,
    "dispose和tf.tidy两种内存管理方法": 326,
    "doPrediction函数": 327,
    "epochs": 328,
    "face_cascade.detectMultiScale": 329,
    "face_distance": 330,
    "face_encodings": 331,
    "face_landmarks": 332,
    "face_locations": 333,
    "face_recognition": 334,
    "filters": 335,
    "filters参数决定输出通道数量": 336,
    "fine_tune_at": 337,
    "flatten层": 338,
    "flow_from_directory": 339,
    "flower_classification": 340,
    "flower_classification 项目": 341,
    "flower_classification/android/finish": 342,
    "from_saved_model(), from_keras_model(), from_concrete_functions()": 343,
    "functional模型": 344,
    "get_input_details()": 345,
    "get_output_details()": 346,
    "get_tensor()": 347,
    "gpio readall命令": 348,
    "has unmet peer dependency \"seedrandom@~": 349,
    "hog模型在CPU上运行更快但不太准确，cnn模型更准确但需要GPU加速": 350,
    "hub.KerasLayer": 351,
    "iOS": 352,
    "iOS CocoaPods": 353,
    "iOS 开发人员": 354,
    "images和labels": 355,
    "implementation('org.tensorflow:tensorflow-lite:+')": 356,
    "import * as tf from '@tensorflow/tfjs' console.log(tf.version.tfjs) const shape = [2, 3]; // 2 rows, 3 columns const a = tf.tensor": 357,
    "include_top=False": 358,
    "index": 359,
    "index.html": 360,
    "index.js": 361,
    "inputShape": 362,
    "inputShape, kernelSize, filters, strides, activation, kernelInitializer": 363,
    "inputShape为[1]，units为1，useBias为true": 364,
    "interpreter": 365,
    "interpreter.get_tensor()": 366,
    "invoke()": 367,
    "jtop 命令": 368,
    "jupyter": 369,
    "jupyter_notebook_config.py": 370,
    "kernelInitializer": 371,
    "kernelSize": 372,
    "label.txt": 373,
    "labels.txt": 374,
    "layers.Flatten()": 375,
    "load_image_file": 376,
    "loss": 377,
    "loss, val_loss, acc, val_acc": 378,
    "make install": 379,
    "make 命令": 380,
    "metrics": 381,
    "microSD 卡": 382,
    "microSD 卡插槽": 383,
    "minNeighbors": 384,
    "mnist项目": 385,
    "mobilenetv2_1.00_224": 386,
    "model": 387,
    "model.compile": 388,
    "model.fit": 389,
    "model.fit()": 390,
    "model.predict()": 391,
    "model.tflite": 392,
    "model.tflite和label.txt文件": 393,
    "model.tflite文件": 394,
    "model.trainable = False": 395,
    "model和保存目录路径": 396,
    "nano或vi": 397,
    "nextTestBatch": 398,
    "nextTrainBatch": 399,
    "nextTrainBatch 和 nextTestBatch 方法": 400,
    "noCompress \"tflite\"": 401,
    "normalization_layer": 402,
    "np.argmax()": 403,
    "output_details": 404,
    "package.json": 405,
    "pip": 406,
    "pip install": 407,
    "pip3": 408,
    "poolSize": 409,
    "poolSize, strides": 410,
    "predict()": 411,
    "print(\"button pressed!\")": 412,
    "python": 413,
    "recognizeImage方法": 414,
    "repositories和dependencies": 415,
    "run函数": 416,
    "saved_model_dir": 417,
    "schema.fbs 文件": 418,
    "sequential模型": 419,
    "sequential模型和functional模型": 420,
    "set_tensor()": 421,
    "showAccuracy函数": 422,
    "showConfusion函数": 423,
    "shuffle": 424,
    "shuffle参数": 425,
    "shuffle参数设置为False以确定性顺序返回批处理": 426,
    "softmax激活函数": 427,
    "start 目录和 finish 目录": 428,
    "strides": 429,
    "target_size参数": 430,
    "target_size设置为(224, 224)的正方形图像": 431,
    "tensor()": 432,
    "tensorflow-lite": 433,
    "testXs": 434,
    "tf.keras model": 435,
    "tf.keras.Sequential": 436,
    "tf.keras.callbacks.TensorBoard": 437,
    "tf.keras.layers.Dense": 438,
    "tf.keras.layers.Dense(units=1)": 439,
    "tf.keras.layers.Dense(units=1, input_shape=[1])": 440,
    "tf.keras.layers.Dense(units=16, activation='relu')": 441,
    "tf.keras.losses.SparseCategoricalCrossentropy": 442,
    "tf.keras.models.Sequential": 443,
    "tf.keras.optimizers.Adam()": 444,
    "tf.linspace()": 445,
    "tf.lite.TFLiteConverter": 446,
    "tf.lite.TFLiteConverter.from_keras_model": 447,
    "tf.lite.TFLiteConverter.from_saved_model": 448,
    "tf.losses.meanSquaredError": 449,
    "tf.model()": 450,
    "tf.nn.softmax": 451,
    "tf.nn.softmax()": 452,
    "tf.saved_model.save": 453,
    "tf.sequential()": 454,
    "tf.sequential()和tf.model()两种创建模型的方式": 455,
    "tf.sequential()对象、输入层和输出层": 456,
    "tf.tensor": 457,
    "tf.tidy": 458,
    "tf.tidy()": 459,
    "tf.train.adam()": 460,
    "tf.util.shuffle": 461,
    "tfjs-examples/mnist": 462,
    "tflite_convert": 463,
    "tflite_convert --keras_model_file=/tmp/mobilenet_keras_model.h5 --output_file=/tmp/mobilenet.tflite": 464,
    "tflite_convert --saved_model_dir=/tmp/mobilenet_saved_model --output_file=/tmp/mobilenet.tflite": 465,
    "tfvis.render.scatterplot": 466,
    "tfvis.show.modelSummary": 467,
    "time.sleep()方法": 468,
    "trainXs": 469,
    "train_ds": 470,
    "train_ds, validation_data=val_ds, epochs=NUM_EPOCHS, callbacks=tensorboard_callback": 471,
    "train_generator": 472,
    "train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=val_generator, validation_steps=len(val_generator)": 473,
    "train函数": 474,
    "try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) { interpreter.run(input, output); }": 475,
    "ui.js": 476,
    "units为1，useBias为true": 477,
    "useBias": 478,
    "val_acc": 479,
    "val_ds": 480,
    "val_ds.map": 481,
    "val_generator": 482,
    "val_loss": 483,
    "validationData": 484,
    "validationData设置为[testXs, testYs]": 485,
    "wait_for_edge()函数": 486,
    "yarn": 487,
    "一个使用数据流图进行数值计算的开源软件库": 488,
    "一个多媒体框架，用于后端处理任务，如格式修改、显示驱动程序协调和数据处理": 489,
    "一个强大、简单、易上手的人脸识别开源项目": 490,
    "一个端到端的机器学习开源框架": 491,
    "一个缩减版的 TensorFlow，简化了算子集，也缩小了运行库": 492,
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具": 493,
    "一个预加载了ImageNet训练权重的深度学习模型": 494,
    "一切皆文件": 495,
    "一种数据结构，包含了在解决特定问题时训练得到的机器学习网络的逻辑和知识": 496,
    "一种有效的物品检测方法": 497,
    "一种特定的矩阵用来呈现算法性能的可视化效果": 498,
    "一系列的计算节点": 499,
    "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型": 500,
    "一组帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型的工具": 501,
    "一组数字引脚，可用于将树莓派连接到其他电子设备": 502,
    "上拉电阻": 503,
    "下载 OpenCV": 504,
    "下载和访问mnist数据集": 505,
    "下载源代码使用GIT工具下载代码，然后编译安装": 506,
    "下载特定版本的Python": 507,
    "下载解压": 508,
    "不包含顶层分类层": 509,
    "不包括无线网卡": 510,
    "不支持 CUDA": 511,
    "不支持 CUDA 且版本是固定搭配的": 512,
    "不改变基础模型的各项参数变量": 513,
    "不清除内部函数的返回值": 514,
    "不需要原始模型构建代码就可以运行": 515,
    "不需要原有模型中最后的神经网络层": 516,
    "不需要序列化或可以创造自己的序列化方法": 517,
    "与 TensorFlow 一起安装": 518,
    "与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化": 519,
    "与树莓派结合可以将项目与现实世界轻松的联系起来": 520,
    "丢弃率为0.2": 521,
    "串联在LED和电源之间限制电流": 522,
    "为LED提供电源": 523,
    "主要应用于游戏场景": 524,
    "主要应用于游戏场景，是为了高性能场景创建的序列化库": 525,
    "了解模型效率、调试超参数": 526,
    "二维卷积层": 527,
    "二进制文件小、延迟低、支持设备端机器学习推断": 528,
    "二进制文件很小": 529,
    "交叉熵损失函数": 530,
    "人脸检测": 531,
    "人脸检测、检测面部特征点、给脸部编码、从编码中找出人的名字": 532,
    "人脸识别": 533,
    "人脸识别与商品识别": 534,
    "仅用于开发的程序包": 535,
    "仅适用于卷积神经网络的一个子集": 536,
    "从 MNIST 数据集中随机批量提取 MNIST 图像": 537,
    "从 SavedModel 或 Keras Model 转换": 538,
    "从头编译": 539,
    "从测试集中返回一批图像及其标签": 540,
    "从目录中生成训练数据批次": 541,
    "从目录中生成验证数据批次": 542,
    "从训练集中返回一批随机图像及其标签": 543,
    "以 ldconfig 结束": 544,
    "以依赖项的安装开始": 545,
    "以最小精度下降来训练网络": 546,
    "优化分类任务": 547,
    "优化损失函数和准确率": 548,
    "优化模型": 549,
    "优化模型大小和性能": 550,
    "优化的 FlatBuffer 格式": 551,
    "优化的 FlatBuffer 格式，以 .tflite 为文件扩展名": 552,
    "位于其引脚排针上": 553,
    "体积小，采用核心板可拆的设计，核心板的大小只有70 x 45 mm，可以很方便的集成在各种嵌入式应用中": 554,
    "作为判断训练结果的参数": 555,
    "作为模型优化算法": 556,
    "作为模型的优化器": 557,
    "作为模型的损失函数": 558,
    "作为迁移学习的基础模型": 559,
    "使权重和激活值的 Post training 更简单": 560,
    "使用 GPU 加速模型运算，提高运算效率": 561,
    "使用 JavaScript，降低前端工程师入门门槛": 562,
    "使用 Python API 进行转换": 563,
    "使用 Python 或其他编程语言编写程序": 564,
    "使用 SavedModel 格式存储": 565,
    "使用 TFLite 模型转换器转换成 TFLite 文件格式(FlatBuffers 格式)": 566,
    "使用 TFLite 转换器转换模型": 567,
    "使用 TensorFlow Lite 支持库预处理模型输入和后处理模型输出": 568,
    "使用 TensorFlow Lite 解释器（提供多种语言的 API）在设备端运行模型": 569,
    "使用 TensorFlow Lite 转换器将模型转换为 TensorFlow Lite 格式": 570,
    "使用 from_saved_model() 或 from_keras_model()": 571,
    "使用32个3x3的滤波器": 572,
    "使用3×3的卷积核，并在输出上使用Relu激活函数": 573,
    "使用BCM编号、物理引脚Broad编号": 574,
    "使用C、C++开发并可被其他语言包使用": 575,
    "使用GPU来加速数学运算": 576,
    "使用lambda函数对images进行归一化处理并保持labels不变": 577,
    "使用优化器'sgd'和损失函数'mean_squared_error'": 578,
    "使用低学习率编译模型": 579,
    "使用低学习率重新编译模型": 580,
    "使用层构建模型": 581,
    "使用机器视觉识别障碍物": 582,
    "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响": 583,
    "使用深度可分离的卷积": 584,
    "使用计算机视觉相关模型，包括实时摄像机": 585,
    "使用预编译库": 586,
    "保存完整的TensorFlow模型": 587,
    "保存模型": 588,
    "保存训练数据的类别标签": 589,
    "保护LED和GPIO引脚": 590,
    "保持了很多通用性": 591,
    "保留原来大规模训练的优势": 592,
    "借助低级运算构建模型": 593,
    "允许解释器在设备的 GPU 上运行适当的运算符": 594,
    "全能 IDE": 595,
    "全连接(Full Connected)层": 596,
    "全连接层": 597,
    "全连接网络": 598,
    "共享的内存缓冲区": 599,
    "关联概率与类别标签": 600,
    "关闭LED灯": 601,
    "具有shape属性定义数组形状": 602,
    "兼容度高": 603,
    "内存只有几十KB": 604,
    "内存回收问题突出": 605,
    "内存高效": 606,
    "内置的算子": 607,
    "写一段简单的测试代码": 608,
    "写入镜像": 609,
    "冻结前100层": 610,
    "冻结预训练模型并更新分类器的权重": 611,
    "准确度": 612,
    "准确率指标": 613,
    "减少了内存碎片化": 614,
    "减少服务器运算，提高服务器资源利用和客户端响应速度": 615,
    "出门问问智能音箱": 616,
    "分类器": 617,
    "分类层": 618,
    "分类结果的概率": 619,
    "创建0~1之间平均分配的100个值": 620,
    "创建TFLiteConverter实例并加载Keras模型": 621,
    "创建Tensor实例": 622,
    "创建、训练和导出自定义 TensorFlow Lite 模型": 623,
    "创建了一个安装脚本": 624,
    "创建包含多个 Dense 层的模型": 625,
    "创建实例并加载模型": 626,
    "创建形状为[2,3]的张量": 627,
    "创建解释器、分配张量等功能": 628,
    "创新奇智": 629,
    "创新奇智智能质检一体机": 630,
    "初始化TensorFlow Lite解释器": 631,
    "利用 Android 神经网络 API（Android NN API)": 632,
    "利用在同一域中的较大数据集上训练的模型所学习的特征": 633,
    "利用手机上的加速器，比如 GPU 或者 DSP": 634,
    "利用计算机对图像进行处理、分析和理解，以识别各种不同模式的目标和对象的技术": 635,
    "前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像": 636,
    "剪刀石头布手势识别": 637,
    "功耗非常低，有两种模式： 5W（低功耗模式；可以使用 USB 口供电） 10W（必须使用 Power Jack 外接5V 电源供电）": 638,
    "功能强大的编程语言，易于使用，易于阅读和编写": 639,
    "功能强大的边缘计算设备": 640,
    "功能强大，交互式、富文本，还有丰富的插件、主题修改、多语言支持": 641,
    "功能接线的引脚号（如TXD、PWM0等）": 642,
    "加载 @tensorflow/tfjs 和 @tensorflow/tfjs-vis 两个 TFJS 模块的代码": 643,
    "加载 @tensorflow/tfjs 和 @tensorflow/tfjs-vis 两个 TFJS 模块的脚本": 644,
    "加载和使用 TensorFlow Hub 上的模型": 645,
    "加载和执行TFLite模型": 646,
    "加载和运行TFLite模型": 647,
    "加载数据并准备进行训练, 定义模型结构, 训练模型并监视其性能, 评估模型": 648,
    "加载数据，定义模型，训练循环并指定UI元素": 649,
    "加载模型": 650,
    "加载面孔照片": 651,
    "加速GPU上的模型推理": 652,
    "加速模型推理过程": 653,
    "动态显示训练的过程": 654,
    "包含一个完整的TensorFlow程序，不仅包含权重值，还包含计算": 655,
    "包含像素缩放和数据增强功能": 656,
    "包含命令行工具gpio，用于设置、读写GPIO管脚": 657,
    "包含完整的TensorFlow程序": 658,
    "千兆以太网端口": 659,
    "单一芯片的小型计算机": 660,
    "单个图像的维度为[28,28,1]": 661,
    "占用更少的磁盘和内存，更快更高效": 662,
    "卷积图像分类模型": 663,
    "卷积完成后应用于数据的激活函数": 664,
    "卷积层": 665,
    "卷积层与全连接层": 666,
    "卷积层输入": 667,
    "取消冻结模型的顶层": 668,
    "受限于GPU内存的大小": 669,
    "只使用在C语言中": 670,
    "只提供了基本的转化功能": 671,
    "可以使用树莓派摄像头，IMX219模组800万像素": 672,
    "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的 TensorFlow 预训练模型中选择一个模型直接使用或重新训练": 673,
    "可以创建任何非闭环的计算图": 674,
    "可以利用手机上的加速器，比如 GPU 或者 DSP 等": 675,
    "可以实时识别照相机所拍摄的花卉": 676,
    "可以指定目标尺寸、批次大小和子集类型": 677,
    "可以添加--no-cache-dir参数来避免缓存问题": 678,
    "可以直接使用cv2.videocapture打开": 679,
    "可以直接在浏览器中运行，无需安装或借助后端": 680,
    "可以设置访问密码增强安全性": 681,
    "可以调用不同的硬件加速器比如GPU进行执行": 682,
    "可以跨平台部署": 683,
    "可以通过软件编程进行控制": 684,
    "可以配置为输入或输出": 685,
    "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型": 686,
    "可能存在过度拟合": 687,
    "可能导致模型过拟合": 688,
    "可能导致预训练模型忘记已学内容": 689,
    "可视化模型训练的过程和结果": 690,
    "可视化模型预测结果和原始数据": 691,
    "启动图标": 692,
    "命令行 TensorFlow Lite 转换器命令行工具": 693,
    "命令行与 Python API": 694,
    "命令行工具": 695,
    "命令行工具和 Python API": 696,
    "商品流通过程中，特别是无人货架、智能零售柜等无人零售领域": 697,
    "商品识别": 698,
    "四引脚按键": 699,
    "四脚按键": 700,
    "回调函数": 701,
    "图像分类": 702,
    "图像分类、物体检测、分割和语音处理": 703,
    "图像分类、物体检测、分割和语音处理等应用程序中并行运行多个神经网络": 704,
    "图像分类任务": 705,
    "图像和视频处理": 706,
    "图像识别": 707,
    "图像识别技术": 708,
    "图像识别模型": 709,
    "在 Android 与 iOS 平台上使用": 710,
    "在 Android 应用中使用 TFLite 解释器运行模型": 711,
    "在 Android 设备上运行图像识别模型 MobileNets_v2来识别花卉": 712,
    "在 Node 环境运算速度与 Python 不相上下": 713,
    "在18号引脚处设置": 714,
    "在不同设备上使用硬件加速": 715,
    "在图像中检测面部，如果检测到面部会返回面部所在的矩形区域 Rect(x,y,w,h)": 716,
    "在大规模数据处理上不如Python高效": 717,
    "在官网下载安装包后安装": 718,
    "在小型数据集上训练模型": 719,
    "在展平操作之前依赖于最后一层": 720,
    "在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战": 721,
    "在有 GPU 加速的手机上运行 MobileNet 图像分类，模型运行速度可以提高": 722,
    "在有 GPU 加速的手机上运行图像分类，模型运行速度可以提高 5.5 倍": 723,
    "在模型转换过程中使用训练后量化": 724,
    "在每一个训练周期显示训练情况": 725,
    "在浏览器上开发模型或运行已训练的模型": 726,
    "在浏览器中加载": 727,
    "在浏览器中训练模型": 728,
    "在浏览器环境中实现深度学习的功能": 729,
    "在生产环境中不需要": 730,
    "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化": 731,
    "在移动和嵌入式设备上运行推理": 732,
    "在移动端、嵌入式和物联网设备上运行 TensorFlow 模型": 733,
    "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型": 734,
    "在移动设备和嵌入式设备上运行TensorFlow模型": 735,
    "在给定设备上实现性能、模型大小和准确性的理想平衡": 736,
    "在训练期间验证损失和准确性": 737,
    "在训练顶层分类器并将预训练模型设置为不可训练之后": 738,
    "在设备端运行TFLite模型": 739,
    "在资源有限的硬件上运行": 740,
    "在边缘设备上运行 TensorFlow 模型推理": 741,
    "在边缘设备上运行 TensorFlow 模型推理的官方框架": 742,
    "在靠近物或数据源头的一侧，采用网络、计算、存储、应用核心能力为一体的开放平台，就近提供最近端服务": 743,
    "基于 TF Mobile 的经验，也继承了 TFMini 和内部其他类似项目的很多优秀工作": 744,
    "基于 WebGL 加速的开放源代码 JavaScript 机器学习库": 745,
    "基于一个流线型的架构，使用深度可分离的卷积": 746,
    "基于流线型架构的轻量级深层神经网络": 747,
    "基于现有模型构建 Interpreter": 748,
    "基于现有的模型进行继续训练": 749,
    "基础模型的各项参数变量不会被新的训练修改数据": 750,
    "增加一个事件的检测函数": 751,
    "处理媒体应用程序": 752,
    "处理简单的数据": 753,
    "多个张量": 754,
    "多种级别的量化支持": 755,
    "多种编程语言": 756,
    "大大降低移动端及IoT设备端的深度学习技术门槛": 757,
    "大电流可能损坏LED和供电设备": 758,
    "大而复杂的模型": 759,
    "大量易于学习的教程": 760,
    "头信息": 761,
    "如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，二进制文件的大小不到 300 KB": 762,
    "委托（Delegates）": 763,
    "子图": 764,
    "子图本身的输入和输出": 765,
    "存储已安装软件包的名称和版本": 766,
    "存储模型权重": 767,
    "存放训练好的模型供开发人员复用": 768,
    "学习AI和构建有趣应用程序": 769,
    "学习空间不变的变换": 770,
    "安全检查、身份核验与移动支付": 771,
    "安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB": 772,
    "安装 OpenCV 项目": 773,
    "安装 Python 包依赖项": 774,
    "安装 TensorFlow": 775,
    "安装Python": 776,
    "安装Python包": 777,
    "安装依赖": 778,
    "安装依赖项": 779,
    "安装和升级 pip3": 780,
    "安装所需的系统包": 781,
    "安装相应的依赖包": 782,
    "完全基于 JavaScript 从头开发、训练和部署模型": 783,
    "完全基于神经网络的移动端语音识别": 784,
    "完成分类任务": 785,
    "官方已经停止维护": 786,
    "官方推荐": 787,
    "官方集成到Python的工具": 788,
    "定义模型的拓扑结构": 789,
    "定义的神经元网络层与层之间的关系较为随意": 790,
    "定位图像中的人脸位置": 791,
    "实例化预先训练的模型，并在顶部添加全连接的分类器": 792,
    "实现一个在手机上运行的 app": 793,
    "实现人体姿势估计": 794,
    "实现识别花卉模型": 795,
    "室内避开障碍物": 796,
    "对 SIMD 指令功能特别有益": 797,
    "对images进行归一化处理": 798,
    "对图像数据进行归一化处理": 799,
    "对手写数字的图像进行分类": 800,
    "对数据降维": 801,
    "对模型的权重产生了更一致且变化较小的渐变更新": 802,
    "对现有 CPU 平台的支持": 803,
    "对训练图像随机变换引入多样性": 804,
    "对输入图像进行预处理": 805,
    "对随机目标函数执行一阶梯度优化的算法": 806,
    "导入 TensorFlow Lite 库": 807,
    "将 Keras 模型保存为 SavedModel 格式": 808,
    "将 NPM 模块转换为在线可以引用的免费服务": 809,
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API": 810,
    "将 TensorFlow 模型转换为 TFLite 格式": 811,
    "将 TensorFlow 模型转换为 TensorFlow Lite 格式": 812,
    "将 TensorFlow 模型转换为方便解释器使用的格式": 813,
    "将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能": 814,
    "将Keras模型转换为TensorFlow Lite模型": 815,
    "将SavedModel转换为TFLite格式": 816,
    "将TensorFlow模型转换为TFLite文件格式(FlatBuffers格式)": 817,
    "将maven源google()和jcenter()替换为国内镜像": 818,
    "将三维张量展开到1维": 819,
    "将三维张量展开到一维": 820,
    "将人脸编码列表与候选编码进行比较": 821,
    "将前一层的输出平铺到一个向量中": 822,
    "将原始数据转变为TensorFlow可读的张量格式": 823,
    "将图片分类到1000类": 824,
    "将大规模内存操作放置在其回调中执行": 825,
    "将彩色图像转换为灰度图像，检测图像中的人脸，在边界周围绘制矩形": 826,
    "将所有图像加载到一个模型需要的特定的大小": 827,
    "将模型保存为TFLite兼容格式": 828,
    "将模型加载到内存中": 829,
    "将模型嵌入到二进制文件中，这样就可以在设备上运行和部署模型": 830,
    "将模型显示在浏览器中": 831,
    "将模型转换为移动设备兼容格式": 832,
    "将模型输出概率与类别标签关联": 833,
    "将特征转换为每个图像对应一个1280元素向量": 834,
    "将网络的每一层简单的叠在一起": 835,
    "将输入数据转换成模型接收的形式或排布，如resize原始图像到模型输入大小": 836,
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型": 837,
    "将镜像写入 microSD 卡": 838,
    "小一点的模型": 839,
    "尝试简化 TensorFlow 并在移动设备上运行": 840,
    "工业物联智能设备开发": 841,
    "工作目录": 842,
    "已经训练好的分类器，其中包括面部，眼睛，微笑等": 843,
    "常开触点": 844,
    "常闭触点": 845,
    "应对快速变化需求的软件开发模式": 846,
    "应用于树莓派的GPIO控制库函数": 847,
    "应用于输入数据的滑动卷积滤波器窗口的大小": 848,
    "应用于输入数据的滑动窗口大小": 849,
    "应用于输入数据的滤波器窗口的数量": 850,
    "应用深度学习算法的一种实践应用": 851,
    "应用程序在边缘侧发起，产生更快的网络服务响应，满足行业在实时业务、应用智能、安全与隐私保护等方面的基本需求": 852,
    "底层 Core API 和最高级的 Layers API": 853,
    "廉价且周边设备多": 854,
    "延迟一秒钟": 855,
    "延迟较低": 856,
    "建议最小采用 64 GB UHS-1 卡": 857,
    "开关去抖": 858,
    "开发 Android 应用": 859,
    "开发依赖": 860,
    "开箱即用的开发库，无需编写基础复杂的数学问题": 861,
    "引入优化以减小二进制文件的大小和提高性能": 862,
    "引用 Model 的内存缓冲区的一片区域，提高内存效率": 863,
    "张量": 864,
    "张量(Tensor)": 865,
    "张量形状是(image_height, image_width, color_channels)": 866,
    "张量连续地从一层传递到下一层": 867,
    "归一化操作": 868,
    "当压力撤销时电路断开": 869,
    "当压力施压时电路接通": 870,
    "形状为[null, 10]的张量": 871,
    "形状为[null, 28, 28, 1]的张量": 872,
    "形状是(224,224,3)": 873,
    "微调": 874,
    "微调过程": 875,
    "必须与正在使用的 JetPack 版本一致": 876,
    "必须在开机前先装上去，系统才能识别 CSI 摄像头": 877,
    "快速": 878,
    "快速启动": 879,
    "快速启动深度学习推理演示": 880,
    "忽略由于开关抖动引起的小于": 881,
    "恢复训练": 882,
    "成功配置好 CUDA": 883,
    "手写数字识别": 884,
    "打乱数据集中数据顺序": 885,
    "打乱数据顺序，创建特征向量和标签向量，转换为张量格式，进行归一化操作": 886,
    "打开现有 Android Studio 项目": 887,
    "打开项目图标": 888,
    "执行10个周期": 889,
    "执行TFLite模型推理": 890,
    "执行一个函数并清除所有创建的中间张量，释放它们的GPU内存": 891,
    "执行推理": 892,
    "执行最终的分类": 893,
    "执行模型推理": 894,
    "执行模型推理过程": 895,
    "执行模型文件在输入数据上定义的运算符，输出推理结果": 896,
    "执行模型转换过程生成TFLite模型": 897,
    "拷贝模型和标签文件到assets目录": 898,
    "指定从哪个层开始进行微调的参数": 899,
    "指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录": 900,
    "指定含有 TensorFlow 1.x 或者 2.0 使用 tf.keras model 生成 HDF5 文件的绝对路径目录": 901,
    "指定引脚编号系统": 902,
    "指定输出文件的绝对路径": 903,
    "损失函数使用类别交叉熵": 904,
    "接受 TFLite 模型": 905,
    "控制GPIO引脚": 906,
    "控制LED灯的亮暗": 907,
    "控制外部硬件设备": 908,
    "控制是否以确定性顺序返回批处理": 909,
    "控制树莓派的GPIO": 910,
    "控制迁移学习中微调的起始层": 911,
    "推理速度提高了30%": 912,
    "描述构建和运行示例所需的依赖项": 913,
    "提供 5V⎓2A 的高品质电源为开发者套件供电": 914,
    "提供了一些转换工具压缩模型，进行算子融合并生成代码": 915,
    "提供交互式编程环境": 916,
    "提供低级的机器学习构建模块和高级的类似Keras的API": 917,
    "提供多种语言的 API": 918,
    "提供更多灵活性和控制": 919,
    "提供经过充分认证的模型": 920,
    "提供训练好的模型供开发人员复用": 921,
    "提供预训练模型和演示项目": 922,
    "提问或分享项目": 923,
    "提高模型准确率": 924,
    "提高模型性能": 925,
    "摄像头预捕获的图像宽度、高度、窗口显示的图像宽度、高度、捕获帧率、是否旋转图像": 926,
    "支持 GPU 硬件加速": 927,
    "支持各种环境的部署": 928,
    "支持多种编程语言": 929,
    "支持大规模的模型训练": 930,
    "支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析": 931,
    "支持算子优化和编译优化": 932,
    "支持设备端机器学习推断": 933,
    "支持设备端机器学习推断，延迟较低，并且二进制文件很小": 934,
    "支持量化原生支持": 935,
    "支持预装驱动程序的 RPi 相机，并且可以很容易地用作即插即用外围设备，不需要安装驱动程序": 936,
    "敏捷开发": 937,
    "教育": 938,
    "数据图像的采集、模型的训练、参数的调整、模型文件生成、网页端部署、网络摄像头检查": 939,
    "数据规范化和转换为张量类型": 940,
    "数据转换": 941,
    "数据集": 942,
    "数据预处理": 943,
    "整个安装需要两个小时才能完成": 944,
    "文字处理": 945,
    "无需使用ByteBuffer来处理图像，提供了方便的支持库来简化图像预处理": 946,
    "易于设置和使用，兼容许多流行配件": 947,
    "是异步函数": 948,
    "显示模型架构": 949,
    "显示每个类别的准确度": 950,
    "显示混淆矩阵": 951,
    "普通GPIO口": 952,
    "智能读码机": 953,
    "更换国内源如阿里、清华": 954,
    "更新可视化元素": 955,
    "更注重考虑实时性，内存高效": 956,
    "更谨慎地控制内存何时回收": 957,
    "更轻量、特别为各种端侧设备优化的算子库、能够利用各种硬件加速": 958,
    "更轻量，二进制文件的大小约为 1 MB（针对 32 位 ARM build）": 959,
    "更适合于边缘设备部署": 960,
    "最后的神经网络层": 961,
    "最大池化层": 962,
    "最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口": 963,
    "有一个名字": 964,
    "服装厂质检": 965,
    "机器学习和计算机视觉应用": 966,
    "机器学习和计算机视觉应用，如物体检测、人脸识别、图像分割等视觉任务": 967,
    "构建CNN模型": 968,
    "构建和运行mnist代码": 969,
    "构建和运行机器学习模型": 970,
    "构建小型移动机器人、人脸签到打卡、口罩识别、智能门锁、智能音箱等复杂 AI 系统": 971,
    "构建工具用于编写更大的程序": 972,
    "构建神经网络": 973,
    "构建神经网络的全连接层": 974,
    "构成检测目标的相邻矩形的最小个数": 975,
    "查看图像及其标签": 976,
    "查看开发板系统信息": 977,
    "查看树莓派的GPIO引脚信息": 978,
    "标准算子": 979,
    "标签文件": 980,
    "树莓派": 981,
    "树莓派GPIO端口文件目录": 982,
    "树莓派接口": 983,
    "树莓派的官方编程语言": 984,
    "树莓派系统": 985,
    "树莓派系统升级": 986,
    "树莓派通用输入/输出接口（GPIO）": 987,
    "核心运行时": 988,
    "格式化 microSD 卡": 989,
    "梯度下降": 990,
    "检查模型对新数据的泛化情况": 991,
    "检测人脸": 992,
    "检测关键身体部位位置": 993,
    "检测关键身体部位的位置": 994,
    "检测面部特征点": 995,
    "模型": 996,
    "模型优化": 997,
    "模型优化工具": 998,
    "模型优化工具包": 999,
    "模型可以与 Python 等其他语言模型互转": 1000,
    "模型执行流图": 1001,
    "模型推理": 1002,
    "模型文件和标签文件": 1003,
    "模型期望的形状": 1004,
    "模型的计算节点": 1005,
    "模型的输入特征": 1006,
    "模型的预测目标": 1007,
    "模型精度达到98%": 1008,
    "模型编译": 1009,
    "模型训练": 1010,
    "模型评估": 1011,
    "模型预测": 1012,
    "每一列代表预测值，每一行代表实际的类别": 1013,
    "每个周期由大约110批次组成": 1014,
    "每次批量处理512个图像": 1015,
    "比 CPU 执行更快的浮点矩阵运算": 1016,
    "池化层": 1017,
    "汽车功率（Horsepower）": 1018,
    "汽车油耗（MPG）": 1019,
    "没有操作系统": 1020,
    "活跃开发者社区打造的开源项目": 1021,
    "流入模型第一层的数据的形状": 1022,
    "测试Python开发环境并查看当前Python版本": 1023,
    "测试数据": 1024,
    "测试的软件包、webpack或Babel": 1025,
    "浏览器可以很好可视化机器训练过程": 1026,
    "浏览器可调用设备的摄像头、麦克风等增加应用场景": 1027,
    "混淆矩阵": 1028,
    "添加 TensorFlow Lite 依赖": 1029,
    "清华源": 1030,
    "清理GPIO引脚的设置": 1031,
    "清除张量或变量并释放其GPU内存": 1032,
    "清除所有创建的中间张量并释放它们的GPU内存": 1033,
    "滑动窗口的步长": 1034,
    "激活、设置为输出状态、写入1": 1035,
    "激活函数为relu": 1036,
    "激活函数为softmax": 1037,
    "灵活的架构可以将模型部署到桌面、服务器或移动设备中的 CPU 或 GPU 上": 1038,
    "点亮LED灯": 1039,
    "爱奇艺": 1040,
    "版本变化后 API 函数会改变": 1041,
    "版本变化后API函数会改变": 1042,
    "物理引脚Broad编号": 1043,
    "特别为各种端侧设备优化的算子库": 1044,
    "瓶颈层": 1045,
    "生成 HDF5 文件的绝对路径目录": 1046,
    "生成SavedModel": 1047,
    "生成一个批次一个批次的图片，以生成器的形式给模型训练": 1048,
    "生成一个批次的图片，以生成器的形式给模型训练": 1049,
    "生成批次的图片以进行模型训练": 1050,
    "用5x5在空间位置上进行平均": 1051,
    "用于 5V 电源输入": 1052,
    "用于存储数据的JavaScript文件": 1053,
    "用于工具的配置中心": 1054,
    "用于构建网页的HTML文件": 1055,
    "用于监督学习": 1056,
    "用于编写JavaScript代码的文件": 1057,
    "用于训练模型": 1058,
    "用于随机初始化模型权重的方法": 1059,
    "用于预测": 1060,
    "用作启动设备和主存储器": 1061,
    "用到的算子索引": 1062,
    "用户在自己的工作台中使用 TensorFlow API 构造 TensorFlow 模型": 1063,
    "用来转换 SavedModel 格式模型": 1064,
    "用来转换 concrete functions": 1065,
    "用来转换 tf.keras 模型": 1066,
    "用来连接 DP 屏幕": 1067,
    "由Gordon Henderson编写维护": 1068,
    "由jupyter软件自动生成": 1069,
    "由常开触点、常闭触点组合而成": 1070,
    "电信号从低电平到高电平，或从高电平到低电平状态的改变": 1071,
    "电阻": 1072,
    "登录 Jetson Nano": 1073,
    "目前有130个左右": 1074,
    "目前有130个左右，它与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化": 1075,
    "直接串联3.3V电源会产生大电流": 1076,
    "直接在 Objective-C 代码中使用 C API": 1077,
    "直接引用 TensorFlow.js 发布的 NPM 包中已经打包安装好的 JavaScript 代码": 1078,
    "直接更新树莓派系统": 1079,
    "直接部署或用于迁移学习": 1080,
    "直流桶式插座": 1081,
    "相比 Protocol Buffer 有更高的性能和更小的大小": 1082,
    "硬件加速代理(Hardware accelerator delegate)": 1083,
    "确认 CUDA 已经被正常安装": 1084,
    "神经元权重计算中的偏置量": 1085,
    "离线语音识别": 1086,
    "科沃斯扫地机器人": 1087,
    "移动应用中的OCR处理": 1088,
    "移动端及IoT设备端的深度学习技术": 1089,
    "移动端模型部署": 1090,
    "移动行业处理器接口（MIPI）的相机串行接口（CSI）端口": 1091,
    "移动设备": 1092,
    "端侧机器学习": 1093,
    "第一个卷积层": 1094,
    "第二、三卷积层": 1095,
    "简化图像预处理和输出处理": 1096,
    "简单的 API 用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型": 1097,
    "简单的线性回归的实验": 1098,
    "算子优化": 1099,
    "算子优化和常见的编译优化、量化的原生支持": 1100,
    "算子实现": 1101,
    "算子库": 1102,
    "算子库(Op kernels)": 1103,
    "算子融合、常数折叠、无用代码删除": 1104,
    "类别交叉熵损失函数": 1105,
    "精度达到98%": 1106,
    "精确度不高的任务": 1107,
    "线性堆叠layers的模型": 1108,
    "给脸部编码": 1109,
    "编译 OpenCV": 1110,
    "编译 Python 模块": 1111,
    "编译模型，设置优化器和损失函数": 1112,
    "缩减卷积结果的大小": 1113,
    "缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响": 1114,
    "缩短开发周期": 1115,
    "网易": 1116,
    "能够利用各种硬件加速": 1117,
    "能够执行完整全面的反向传播": 1118,
    "自定制算子": 1119,
    "花卉数据集中的图片": 1120,
    "花卉识别 app": 1121,
    "花卉识别模型": 1122,
    "英伟达官方或开源社区": 1123,
    "获取图像数据、处理位图、调用姿势估计函数、绘制关键点": 1124,
    "获取张量的指针": 1125,
    "获取张量的数据": 1126,
    "获取更多的Jetson平台信息": 1127,
    "获取有趣的项目": 1128,
    "获取概率最大的类别索引": 1129,
    "衡量所有预测中正确预测的百分比": 1130,
    "表示训练集的准确度": 1131,
    "表示训练集的损失值": 1132,
    "表示验证集的准确度": 1133,
    "表示验证集的损失值": 1134,
    "观测开关去抖效果": 1135,
    "视频中的AR效果": 1136,
    "解决JavaScript内存回收问题": 1137,
    "解决特定问题": 1138,
    "解决跨域问题": 1139,
    "解释器和转换器": 1140,
    "解释输出": 1141,
    "计算分类概率": 1142,
    "计算已知人脸和未知人脸特征向量的距离": 1143,
    "计算机视觉应用": 1144,
    "计算能力不高，勉强可以使用一些小规模、并且优化过的网络进行推理，训练的话还是不够用的": 1145,
    "计算节点的输入和输出": 1146,
    "计算预测结果的softmax概率": 1147,
    "让输入输出映射到0-1之间，保证后期更有效地训练": 1148,
    "训练分类器": 1149,
    "训练并评估训练的结果": 1150,
    "训练数据": 1151,
    "训练数据和测试数据": 1152,
    "训练数据集很大且类似于预训练模型训练的原始数据集": 1153,
    "训练期间将不更新预训练网络的权重，只在 MobileNet V2基础模型上训练了几层": 1154,
    "训练期间需要更多的内存": 1155,
    "训练模型": 1156,
    "训练集，用于训练模型": 1157,
    "训练顶层分类器": 1158,
    "训练预训练模型的顶层权重": 1159,
    "训练预训练模型的顶层的权重以及刚添加的分类器的训练": 1160,
    "记录训练日志": 1161,
    "记录训练过程中的日志数据": 1162,
    "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，对量化特别有益": 1163,
    "设置 OpenCV 的内容、位置和方式": 1164,
    "设置 converter.optimizations=[tf.lite.Optimize.DEFAULT]": 1165,
    "设置 model.trainable = False": 1166,
    "设置GPIO引脚模式": 1167,
    "设置model.trainable = False": 1168,
    "设置上拉电阻": 1169,
    "设置为100表示从第100层开始微调": 1170,
    "设置为32，表示一次采样32条训练数据": 1171,
    "设置为50，表示遍历所有样本50次": 1172,
    "设置为true，表示打乱数据集": 1173,
    "设置前100层为不可训练": 1174,
    "设置在训练中基础模型的各项参数变量不会被新的训练修改数据": 1175,
    "设置引脚为输入或输出模式": 1176,
    "设置输入张量值": 1177,
    "评估准确性": 1178,
    "评估分类器的准确性": 1179,
    "评估训练有素的模型的性能": 1180,
    "识别图像里的空间模式，例如线条和物体局部": 1181,
    "识别手写数字": 1182,
    "识别花卉图片": 1183,
    "识别输入图像": 1184,
    "语音识别": 1185,
    "读取传感器数据和控制外部设备": 1186,
    "读取传感器数据，控制 LED 等外部设备": 1187,
    "读取输出张量值": 1188,
    "调整大小、裁剪、旋转和归一化图像": 1189,
    "调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征": 1190,
    "调用 Python API 或命令行进行转换": 1191,
    "调用CSI摄像头和USB摄像头": 1192,
    "调用getModel获取模型": 1193,
    "调用train函数训练模型": 1194,
    "调用不同的硬件加速器比如 GPU 进行执行": 1195,
    "资源有限，不能训练网络，可能导致内存溢出": 1196,
    "跨平台运行，包括 Android、iOS 以及基于 Linux 的 IoT 设备和微控制器": 1197,
    "转换 SavedModel 格式模型": 1198,
    "转换 concrete functions": 1199,
    "转换 tf.keras 模型": 1200,
    "转换和运行 TensorFlow 模型的工具": 1201,
    "转换数据": 1202,
    "转换模型": 1203,
    "软件PWM库": 1204,
    "软件源配置文件": 1205,
    "软链接": 1206,
    "轻量化": 1207,
    "轻量级": 1208,
    "轻量级、快速启动、内存高效": 1209,
    "较大的批次": 1210,
    "输入层": 1211,
    "输入层、隐藏层和输出层": 1212,
    "输入输出用到的 Tensor 索引": 1213,
    "输入（Xs）和标签（Ys）": 1214,
    "输出三维张量，形状为(height, width, channels)": 1215,
    "输出三维张量，形状描述(height, width, channels)": 1216,
    "输出层": 1217,
    "输出模式": 1218,
    "输出电压约为3.3V": 1219,
    "输出通道数为32": 1220,
    "输出通道数为64": 1221,
    "边做边学的理想工具": 1222,
    "边缘": 1223,
    "边缘操作": 1224,
    "边缘计算": 1225,
    "边缘计算设备": 1226,
    "迁移学习": 1227,
    "运行 TensorFlow Lite 模型": 1228,
    "运行Jupyter lab服务": 1229,
    "运行Sync Gradle": 1230,
    "运行TFLite推理并获取输出概率": 1231,
    "运行功率仅为 5 瓦": 1232,
    "运行各种深度学习模型": 1233,
    "运行在 Node.js 或浏览器环境中": 1234,
    "运行已有的 Python 版 TensorFlow 模型": 1235,
    "运行服务监听的IP地址、端口、notebooks内核目录、浏览器开关设置": 1236,
    "运行模型推理": 1237,
    "返回图像中每张人脸的128维人脸编码": 1238,
    "返回张量数据的副本": 1239,
    "返回的是数据的副本而非引用": 1240,
    "进行VNC连接": 1241,
    "进行内存清理工作，防止内存泄露": 1242,
    "进行大量的张量操作时使用可能会很麻烦": 1243,
    "远程桌面访问Jetson Nano": 1244,
    "连接LED灯和限流电阻到GPIO21和GND": 1245,
    "连接显示器、键盘和鼠标或通过SSH/VNC远程访问": 1246,
    "适应性低阶矩估计": 1247,
    "适用于多个平台": 1248,
    "适用于多个平台，提供了一个简单的 API": 1249,
    "选择模型": 1250,
    "选择模型、转换模型、部署到设备、优化模型": 1251,
    "选择镜像、选择驱动器、闪存": 1252,
    "逐步加载单个数据集的图像": 1253,
    "通过 WebGL 在 GPU 上执行计算大幅提高速度": 1254,
    "通过 pip 安装 Jupyter lab，如果网络环境较差导致下载软件包慢，可以考虑更换源": 1255,
    "通过 script 标签引入 index.js": 1256,
    "通过命令行转换模型": 1257,
    "通过脚本标签（script tags）或从 yarn（或者 NPM）安装并使用 Parcel，WebPack 或 Rollup 等工具构建工程": 1258,
    "通过迁移学习实现": 1259,
    "通过限流电阻串联到GPIO21，负极连接到GND": 1260,
    "郁金香(tulips)、玫瑰(roses)、浦公英(dandelion)、向日葵(sunflowers)、雏菊(daisy)": 1261,
    "部署TensorFlow Lite模型": 1262,
    "部署到设备": 1263,
    "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上": 1264,
    "配置Jupyter lab的运行参数": 1265,
    "配置build.gradle文件": 1266,
    "配置文件jupyter_notebook_config.py": 1267,
    "配置模型的优化器、损失函数和评估指标": 1268,
    "配置模型的优化器和损失函数": 1269,
    "配置项目依赖": 1270,
    "采用更小的模型格式，并提供了方便的模型转换器": 1271,
    "释放张量的GPU内存": 1272,
    "量化": 1273,
    "针对移动设备做了很多优化": 1274,
    "错误的连接和编程可能会导致设备损坏或故障": 1275,
    "镜像": 1276,
    "防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件": 1277,
    "防止应用程序中的内存泄漏": 1278,
    "阻塞函数，会阻塞程序执行，直到检测到一个边沿": 1279,
    "降低卷积层对位置的敏感": 1280,
    "降低存储器访问成本": 1281,
    "降低权重的精确表示，并且可选的降低存储和计算的激活值": 1282,
    "降低权重的精确表示，降低存储和计算的激活值": 1283,
    "降低用于读取和存储中间激活值的存储器访问成本": 1284,
    "需满足苛刻的功耗要求": 1285,
    "需要root权限": 1286,
    "需要使用GStreamer读取视频流": 1287,
    "需要大约两个半小时": 1288,
    "需要注意版本变化": 1289,
    "需要相应地增加epochs": 1290,
    "需要设置VNC密码和启用自动登录": 1291,
    "需要调整为模型期望的形状": 1292,
    "需要配置proxy或使用国内镜像": 1293,
    "需要高准确率的任务": 1294,
    "面包板、杜邦线公对母、LED灯、330欧姆电阻": 1295,
    "页面的基本结构，包含div标签、UI元素和JavaScript代码": 1296,
    "项目的清单文件": 1297,
    "预处理模型输入和后处理模型输出": 1298,
    "预处理输入图像": 1299,
    "预测": 1300,
    "预测不受图像顺序的影响": 1301,
    "预测汽车油耗效率": 1302,
    "预测汽车油耗（MPG）": 1303,
    "预测汽车的油耗效率 MPG": 1304,
    "预训练模型": 1305,
    "预训练模型和全连接的分类器": 1306,
    "预训练模型将忘记它学到的东西": 1307,
    "首次打开项目时": 1308,
    "验证集": 1309,
    "验证集，在每个时期结束时对模型进行测试": 1310,
    "高性能": 1311,
    "高性能场景创建的序列化库": 1312,
    "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）": 1313,
    "默认值为32，可以设置为64": 1314,
    "默认分类到1000类": 1315,
    "默认安装 JetPack 安装了对应的 OpenCV": 1316,
    "默认已安装的Python开发环境": 1317
  },
  "id_to_entity": {
    "0": "--enable_v1_converter",
    "1": "--keras_model_file",
    "2": "--output_file",
    "3": "--output_file, --saved_model_dir, --keras_model_file, --enable_v1_converter",
    "4": "--saved_model_dir",
    "5": "-D WITH_QT=OFF 禁用了 Qt5 支持",
    "6": ".tflite",
    "7": "/dev",
    "8": "/etc/apt/sources.list",
    "9": "/opt/python 目录",
    "10": "/sys/class/gpio",
    "11": "/usr/bin/python",
    "12": "128核 NVIDIA Maxwell 架构的 GPU",
    "13": "128核NVIDIA Maxwell架构的GPU",
    "14": "14个引脚用于其他功能",
    "15": "155层网络",
    "16": "2.0.0",
    "17": "2.3.0",
    "18": "2.3.0版本",
    "19": "26个引脚可以用作数字输入或输出",
    "20": "3670 files belonging to 5 classes",
    "21": "3个Conv2D和2个MaxPooling2D层",
    "22": "40 针 GPIO 扩展接口",
    "23": "40个 GPIO 引脚",
    "24": "40个GPIO引脚",
    "25": "4GB 的内存并不能完全使用，其中有一部分（1GB 左右）是和显存共享的",
    "26": "5个节点",
    "27": "5个节点的输出层",
    "28": "6",
    "29": "64位四核的 ARM Cortex-A57",
    "30": "7",
    "31": "734 files for validation",
    "32": "8",
    "33": "800万像素、感光芯片为索尼 IMX219，静态图片分辨率为3280 × 2464、支持1080p30, 720p60以及640 × 480p90视频录像",
    "34": "9",
    "35": "<!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">",
    "36": "<html> <body> <h4>TFJS example<hr/></h4> <div id=\"micro-out-div\">TensorFlow.js Test</div> <script src=\"./index.js\"> </script> </body> </html>",
    "37": "@tensorflow/tfjs",
    "38": "@tensorflow/tfjs-vis",
    "39": "AC8265",
    "40": "ARM Cortex-A72",
    "41": "Adam优化器",
    "42": "Android",
    "43": "Android JCenter Bintray 的 TFLite AAR",
    "44": "Android Studio",
    "45": "Android 应用",
    "46": "Android 开发人员",
    "47": "Android、iOS 和 Linux等移动/嵌入式平台",
    "48": "Android、iOS、基于 Linux 的 IoT 设备和微控制器",
    "49": "Android环境部署",
    "50": "Android部署",
    "51": "B02版本有两路",
    "52": "BATCH_SIZE",
    "53": "BATCH_SIZE设置为512",
    "54": "BCM编号",
    "55": "BCM编号方式",
    "56": "BCM编号模式和物理引脚Broad编号模式",
    "57": "Broadcom针脚号，通常称的GPIO",
    "58": "C",
    "59": "C#",
    "60": "C++",
    "61": "C++ 和 Python 提供的 TensorFlow Lite API",
    "62": "CNN",
    "63": "CSI 摄像头",
    "64": "CSI 相机接口",
    "65": "CSI 端口",
    "66": "CSI摄像头",
    "67": "ClassifierFloatMobileNet类",
    "68": "Classifier类",
    "69": "CocoaPods for Swift or Objective-C",
    "70": "Conv2D",
    "71": "Conv2D, MaxPooling2D, Flatten, Dense层",
    "72": "Core API",
    "73": "DeepLearning.js",
    "74": "Dense",
    "75": "Display Port 接口",
    "76": "Dropout",
    "77": "Enables the converter and flags used in TF 1.x instead of TF 2.x",
    "78": "Etcher",
    "79": "Ethernet 有线网络",
    "80": "Face Recognition",
    "81": "FlatBuffers",
    "82": "FlatBuffers 格式",
    "83": "Full path of the output file",
    "84": "Full path to the Keras H5 model file",
    "85": "Full path to the SavedModel directory",
    "86": "GPIO.cleanup()方法",
    "87": "GPIO.setmod()",
    "88": "GPIO.setup()",
    "89": "GPIO.setup()方法",
    "90": "GPIO.setup(18, GPIO.IN, pull_up_down=GPIO.PUD_UP)",
    "91": "GPIO21",
    "92": "GPIO口",
    "93": "GPIO库",
    "94": "GPIO引脚",
    "95": "GPIO引脚编号模式",
    "96": "GPU",
    "97": "GPU 委托",
    "98": "GPU代理",
    "99": "GStreamer",
    "100": "GStreamer管道",
    "101": "GlobalAveragePooling2D",
    "102": "Google",
    "103": "Google Arts & Culture",
    "104": "Google Assistant",
    "105": "Google Assistant、Google Photos、Uber、Airbnb、网易、爱奇艺、WPS等",
    "106": "Google Edge TPU Coral Dev Board",
    "107": "Google Photos",
    "108": "Google 内部用于计算机视觉场景的解决方案",
    "109": "GpuDelegate",
    "110": "Gradle 同步",
    "111": "HDMI 接口",
    "112": "HIGH电平",
    "113": "HTML",
    "114": "HTML 文件",
    "115": "HTML文件、JS文件和配置文件",
    "116": "Haar 特征分类器",
    "117": "Haar 特征的 cascade 分类器",
    "118": "Haar特征的cascade分类器",
    "119": "Hello AI World",
    "120": "I2C库",
    "121": "I2C接口(SCL、SDA)",
    "122": "IMAGE_WIDTH, IMAGE_HEIGHT, testData, testxs, labels, preds",
    "123": "ImageDataGenerator",
    "124": "ImageProcessor",
    "125": "Intel Neural Compute Stick 2",
    "126": "Interpreter",
    "127": "IoT领域",
    "128": "Java",
    "129": "Java 或 C++ API 执行 TensorFlow Lite 推理",
    "130": "JavaScript",
    "131": "JavaScript 代码",
    "132": "JavaScript 语言版本的扩展",
    "133": "JetBot",
    "134": "JetPack SDK",
    "135": "Jetson",
    "136": "Jetson Community Projects",
    "137": "Jetson Developer Kits",
    "138": "Jetson Nano",
    "139": "Jetson Nano CPU",
    "140": "Jetson Nano 开发板",
    "141": "Jupyter Notebook",
    "142": "Jupyter Notebook 的全面升级",
    "143": "Jupyter Notebook、文本编辑器、终端以及各种个性化组件",
    "144": "Jupyter lab",
    "145": "JupyterLab",
    "146": "Keras H5",
    "147": "Keras Model 和 SavedModel",
    "148": "Keras模型",
    "149": "Keras的模型定义方式",
    "150": "LED",
    "151": "LED灯",
    "152": "LED的控制引脚",
    "153": "LOW电平",
    "154": "Layers API",
    "155": "Layers API和Core API",
    "156": "Linux",
    "157": "Linux 中所有设备文件或特殊文件的存储位置",
    "158": "Linux 开发环境",
    "159": "Linux开发环境",
    "160": "Live Caption",
    "161": "MCU",
    "162": "MIPI",
    "163": "MIPI CSI-2 摄像头接口",
    "164": "MIPI 联盟发起的为移动应用处理器制定的开放标准",
    "165": "MNIST 分类器",
    "166": "MNIST数据集",
    "167": "MNIST模型训练",
    "168": "MaxPooling2D",
    "169": "Micro USB 接口",
    "170": "Micro-USB 接口",
    "171": "MnistData",
    "172": "MobileNet",
    "173": "MobileNet V2",
    "174": "MobileNetV2",
    "175": "MobileNetV2模型",
    "176": "NVIDIA Jetson Nano",
    "177": "NVIDIA Jetson Nano 开发板",
    "178": "NVIDIA Jetson 论坛",
    "179": "Object C",
    "180": "OpenCV",
    "181": "OpenCV 安装",
    "182": "OpenCV 安装脚本",
    "183": "OpenCV 编译",
    "184": "OperatorCode",
    "185": "PCB板上针脚的物理位置对应的编号（1~40）",
    "186": "PIN处于高电压点亮LED",
    "187": "PWM接口",
    "188": "Parcel",
    "189": "PoseNet",
    "190": "PoseNet模型",
    "191": "PoseNet示例应用程序",
    "192": "Post training quantization 和 Quantization-aware training",
    "193": "Python",
    "194": "Python 2.7",
    "195": "Python GPIO引脚",
    "196": "Python 官网",
    "197": "Python 模块",
    "198": "Python 源码包",
    "199": "Python 相关程序模块",
    "200": "Python 相关程序模块会拷贝到/opt/python",
    "201": "Python包管理",
    "202": "Python安装",
    "203": "Python程序",
    "204": "Quantization-aware training",
    "205": "RPI.GPIO库",
    "206": "RandomFlip",
    "207": "RandomRotation",
    "208": "Raspberry Camera V2",
    "209": "Raspberry Pi 4",
    "210": "Raspberry Pi、Arducam 等常见的相机模块",
    "211": "Raspbian软件仓库镜像",
    "212": "SD Memory Card Formatter",
    "213": "SPI库",
    "214": "SPI接口（MISO、MOSI、CLK、CS片选信号SPICE0_N）",
    "215": "SavedModel",
    "216": "SavedModel 和 Keras Sequential",
    "217": "SavedModel 和 Keras Sequential 两种模型导出方法和格式",
    "218": "SavedModel 格式",
    "219": "Sequential模型",
    "220": "Swift",
    "221": "Swift 和 Objective-C 编写的原生 iOS 库",
    "222": "SymbolicTensor和apply()方法",
    "223": "TF Mobile",
    "224": "TFLite",
    "225": "TFLite model",
    "226": "TFLite 文件格式",
    "227": "TFLite 模型文件",
    "228": "TFLite 模型文件格式",
    "229": "TFLite 模型文件格式，更注重考虑实时性，内存高效",
    "230": "TFLite 模型转换过程",
    "231": "TFLite 算子库",
    "232": "TFLite 解释器",
    "233": "TFLite 解释执行器",
    "234": "TFLite 转换器",
    "235": "TFLiteConverter",
    "236": "TFLiteConverter.from_concrete_functions()",
    "237": "TFLiteConverter.from_keras_model()",
    "238": "TFLiteConverter.from_saved_model()",
    "239": "TFLite模型转换器",
    "240": "TFLite解释器",
    "241": "TFLite解释器和GPU代理",
    "242": "TFMini",
    "243": "TensorFLow-vis",
    "244": "TensorFlow",
    "245": "TensorFlow 2.x 模型",
    "246": "TensorFlow GPU 版本",
    "247": "TensorFlow Hub",
    "248": "TensorFlow Hub 上的一个模型",
    "249": "TensorFlow Lite",
    "250": "TensorFlow Lite AAR",
    "251": "TensorFlow Lite API",
    "252": "TensorFlow Lite 工作流程",
    "253": "TensorFlow Lite 开发工作流程",
    "254": "TensorFlow Lite 推理",
    "255": "TensorFlow Lite 支持库",
    "256": "TensorFlow Lite 模型",
    "257": "TensorFlow Lite 模型文件",
    "258": "TensorFlow Lite 示例",
    "259": "TensorFlow Lite 算子库",
    "260": "TensorFlow Lite 解释器",
    "261": "TensorFlow Lite 解释器(Interpreter)",
    "262": "TensorFlow Lite 解释器、TensorFlow Lite 转换器、算子库、硬件加速代理",
    "263": "TensorFlow Lite 转换器",
    "264": "TensorFlow Lite 转换器(Converter)",
    "265": "TensorFlow Lite 转换器命令行工具",
    "266": "TensorFlow Lite支持库",
    "267": "TensorFlow Lite模型",
    "268": "TensorFlow Lite的工作流程",
    "269": "TensorFlow Lite的简称",
    "270": "TensorFlow Lite解释器",
    "271": "TensorFlow 官网",
    "272": "TensorFlow 模型",
    "273": "TensorFlow 模型导出",
    "274": "TensorFlow 的 JavaScript 版本",
    "275": "TensorFlow.js",
    "276": "TensorFlow.js 库的导入和版本打印",
    "277": "TensorFlow.js 模块",
    "278": "TensorFlow.js 进行浏览器可视化的一组实用工具库",
    "279": "TensorFlow.js中的中心数据单元，是一维或多维数组",
    "280": "TensorFlow模型的序列化格式",
    "281": "TensorLabel",
    "282": "Tensorflow Lite post-training quantization",
    "283": "Tensorflow.js",
    "284": "Total params: 2,626,821, Trainable params: 368,837, Non-trainable params: 2,257,984",
    "285": "UART串口接口（TXD、RXD）",
    "286": "UART库",
    "287": "USB",
    "288": "USB摄像头",
    "289": "VNC",
    "290": "VNC Viewer",
    "291": "WPS",
    "292": "Web Server for Chrome",
    "293": "Webpack",
    "294": "Wiring Pi",
    "295": "Wiring Pi编号",
    "296": "Wiring Pi编号模式",
    "297": "XML 文件，该文件中会描述人体各个部位的 Haar 特征值",
    "298": "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']",
    "299": "[num_examples, image_width, image_height, channels]",
    "300": "aaptOptions",
    "301": "acc",
    "302": "activation",
    "303": "add_event_detect()函数",
    "304": "allocate_tensors()",
    "305": "android 目录",
    "306": "base_model",
    "307": "batchSize",
    "308": "batch_size",
    "309": "batch_size默认值为32，可设置为64",
    "310": "build.gradle",
    "311": "buildscript",
    "312": "callback",
    "313": "cdn.jsdelivr.net",
    "314": "class_names",
    "315": "compare_faces",
    "316": "conv2d, dropout, global_average_pooling2d, dense",
    "317": "convertToTensor函数",
    "318": "converter.convert",
    "319": "createModel()",
    "320": "daisy, dandelion, roses, sunflowers, tulips",
    "321": "data.js",
    "322": "data.js文件",
    "323": "dense层",
    "324": "dependencies",
    "325": "dispose",
    "326": "dispose和tf.tidy两种内存管理方法",
    "327": "doPrediction函数",
    "328": "epochs",
    "329": "face_cascade.detectMultiScale",
    "330": "face_distance",
    "331": "face_encodings",
    "332": "face_landmarks",
    "333": "face_locations",
    "334": "face_recognition",
    "335": "filters",
    "336": "filters参数决定输出通道数量",
    "337": "fine_tune_at",
    "338": "flatten层",
    "339": "flow_from_directory",
    "340": "flower_classification",
    "341": "flower_classification 项目",
    "342": "flower_classification/android/finish",
    "343": "from_saved_model(), from_keras_model(), from_concrete_functions()",
    "344": "functional模型",
    "345": "get_input_details()",
    "346": "get_output_details()",
    "347": "get_tensor()",
    "348": "gpio readall命令",
    "349": "has unmet peer dependency \"seedrandom@~",
    "350": "hog模型在CPU上运行更快但不太准确，cnn模型更准确但需要GPU加速",
    "351": "hub.KerasLayer",
    "352": "iOS",
    "353": "iOS CocoaPods",
    "354": "iOS 开发人员",
    "355": "images和labels",
    "356": "implementation('org.tensorflow:tensorflow-lite:+')",
    "357": "import * as tf from '@tensorflow/tfjs' console.log(tf.version.tfjs) const shape = [2, 3]; // 2 rows, 3 columns const a = tf.tensor",
    "358": "include_top=False",
    "359": "index",
    "360": "index.html",
    "361": "index.js",
    "362": "inputShape",
    "363": "inputShape, kernelSize, filters, strides, activation, kernelInitializer",
    "364": "inputShape为[1]，units为1，useBias为true",
    "365": "interpreter",
    "366": "interpreter.get_tensor()",
    "367": "invoke()",
    "368": "jtop 命令",
    "369": "jupyter",
    "370": "jupyter_notebook_config.py",
    "371": "kernelInitializer",
    "372": "kernelSize",
    "373": "label.txt",
    "374": "labels.txt",
    "375": "layers.Flatten()",
    "376": "load_image_file",
    "377": "loss",
    "378": "loss, val_loss, acc, val_acc",
    "379": "make install",
    "380": "make 命令",
    "381": "metrics",
    "382": "microSD 卡",
    "383": "microSD 卡插槽",
    "384": "minNeighbors",
    "385": "mnist项目",
    "386": "mobilenetv2_1.00_224",
    "387": "model",
    "388": "model.compile",
    "389": "model.fit",
    "390": "model.fit()",
    "391": "model.predict()",
    "392": "model.tflite",
    "393": "model.tflite和label.txt文件",
    "394": "model.tflite文件",
    "395": "model.trainable = False",
    "396": "model和保存目录路径",
    "397": "nano或vi",
    "398": "nextTestBatch",
    "399": "nextTrainBatch",
    "400": "nextTrainBatch 和 nextTestBatch 方法",
    "401": "noCompress \"tflite\"",
    "402": "normalization_layer",
    "403": "np.argmax()",
    "404": "output_details",
    "405": "package.json",
    "406": "pip",
    "407": "pip install",
    "408": "pip3",
    "409": "poolSize",
    "410": "poolSize, strides",
    "411": "predict()",
    "412": "print(\"button pressed!\")",
    "413": "python",
    "414": "recognizeImage方法",
    "415": "repositories和dependencies",
    "416": "run函数",
    "417": "saved_model_dir",
    "418": "schema.fbs 文件",
    "419": "sequential模型",
    "420": "sequential模型和functional模型",
    "421": "set_tensor()",
    "422": "showAccuracy函数",
    "423": "showConfusion函数",
    "424": "shuffle",
    "425": "shuffle参数",
    "426": "shuffle参数设置为False以确定性顺序返回批处理",
    "427": "softmax激活函数",
    "428": "start 目录和 finish 目录",
    "429": "strides",
    "430": "target_size参数",
    "431": "target_size设置为(224, 224)的正方形图像",
    "432": "tensor()",
    "433": "tensorflow-lite",
    "434": "testXs",
    "435": "tf.keras model",
    "436": "tf.keras.Sequential",
    "437": "tf.keras.callbacks.TensorBoard",
    "438": "tf.keras.layers.Dense",
    "439": "tf.keras.layers.Dense(units=1)",
    "440": "tf.keras.layers.Dense(units=1, input_shape=[1])",
    "441": "tf.keras.layers.Dense(units=16, activation='relu')",
    "442": "tf.keras.losses.SparseCategoricalCrossentropy",
    "443": "tf.keras.models.Sequential",
    "444": "tf.keras.optimizers.Adam()",
    "445": "tf.linspace()",
    "446": "tf.lite.TFLiteConverter",
    "447": "tf.lite.TFLiteConverter.from_keras_model",
    "448": "tf.lite.TFLiteConverter.from_saved_model",
    "449": "tf.losses.meanSquaredError",
    "450": "tf.model()",
    "451": "tf.nn.softmax",
    "452": "tf.nn.softmax()",
    "453": "tf.saved_model.save",
    "454": "tf.sequential()",
    "455": "tf.sequential()和tf.model()两种创建模型的方式",
    "456": "tf.sequential()对象、输入层和输出层",
    "457": "tf.tensor",
    "458": "tf.tidy",
    "459": "tf.tidy()",
    "460": "tf.train.adam()",
    "461": "tf.util.shuffle",
    "462": "tfjs-examples/mnist",
    "463": "tflite_convert",
    "464": "tflite_convert --keras_model_file=/tmp/mobilenet_keras_model.h5 --output_file=/tmp/mobilenet.tflite",
    "465": "tflite_convert --saved_model_dir=/tmp/mobilenet_saved_model --output_file=/tmp/mobilenet.tflite",
    "466": "tfvis.render.scatterplot",
    "467": "tfvis.show.modelSummary",
    "468": "time.sleep()方法",
    "469": "trainXs",
    "470": "train_ds",
    "471": "train_ds, validation_data=val_ds, epochs=NUM_EPOCHS, callbacks=tensorboard_callback",
    "472": "train_generator",
    "473": "train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=val_generator, validation_steps=len(val_generator)",
    "474": "train函数",
    "475": "try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) { interpreter.run(input, output); }",
    "476": "ui.js",
    "477": "units为1，useBias为true",
    "478": "useBias",
    "479": "val_acc",
    "480": "val_ds",
    "481": "val_ds.map",
    "482": "val_generator",
    "483": "val_loss",
    "484": "validationData",
    "485": "validationData设置为[testXs, testYs]",
    "486": "wait_for_edge()函数",
    "487": "yarn",
    "488": "一个使用数据流图进行数值计算的开源软件库",
    "489": "一个多媒体框架，用于后端处理任务，如格式修改、显示驱动程序协调和数据处理",
    "490": "一个强大、简单、易上手的人脸识别开源项目",
    "491": "一个端到端的机器学习开源框架",
    "492": "一个缩减版的 TensorFlow，简化了算子集，也缩小了运行库",
    "493": "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具",
    "494": "一个预加载了ImageNet训练权重的深度学习模型",
    "495": "一切皆文件",
    "496": "一种数据结构，包含了在解决特定问题时训练得到的机器学习网络的逻辑和知识",
    "497": "一种有效的物品检测方法",
    "498": "一种特定的矩阵用来呈现算法性能的可视化效果",
    "499": "一系列的计算节点",
    "500": "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型",
    "501": "一组帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型的工具",
    "502": "一组数字引脚，可用于将树莓派连接到其他电子设备",
    "503": "上拉电阻",
    "504": "下载 OpenCV",
    "505": "下载和访问mnist数据集",
    "506": "下载源代码使用GIT工具下载代码，然后编译安装",
    "507": "下载特定版本的Python",
    "508": "下载解压",
    "509": "不包含顶层分类层",
    "510": "不包括无线网卡",
    "511": "不支持 CUDA",
    "512": "不支持 CUDA 且版本是固定搭配的",
    "513": "不改变基础模型的各项参数变量",
    "514": "不清除内部函数的返回值",
    "515": "不需要原始模型构建代码就可以运行",
    "516": "不需要原有模型中最后的神经网络层",
    "517": "不需要序列化或可以创造自己的序列化方法",
    "518": "与 TensorFlow 一起安装",
    "519": "与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化",
    "520": "与树莓派结合可以将项目与现实世界轻松的联系起来",
    "521": "丢弃率为0.2",
    "522": "串联在LED和电源之间限制电流",
    "523": "为LED提供电源",
    "524": "主要应用于游戏场景",
    "525": "主要应用于游戏场景，是为了高性能场景创建的序列化库",
    "526": "了解模型效率、调试超参数",
    "527": "二维卷积层",
    "528": "二进制文件小、延迟低、支持设备端机器学习推断",
    "529": "二进制文件很小",
    "530": "交叉熵损失函数",
    "531": "人脸检测",
    "532": "人脸检测、检测面部特征点、给脸部编码、从编码中找出人的名字",
    "533": "人脸识别",
    "534": "人脸识别与商品识别",
    "535": "仅用于开发的程序包",
    "536": "仅适用于卷积神经网络的一个子集",
    "537": "从 MNIST 数据集中随机批量提取 MNIST 图像",
    "538": "从 SavedModel 或 Keras Model 转换",
    "539": "从头编译",
    "540": "从测试集中返回一批图像及其标签",
    "541": "从目录中生成训练数据批次",
    "542": "从目录中生成验证数据批次",
    "543": "从训练集中返回一批随机图像及其标签",
    "544": "以 ldconfig 结束",
    "545": "以依赖项的安装开始",
    "546": "以最小精度下降来训练网络",
    "547": "优化分类任务",
    "548": "优化损失函数和准确率",
    "549": "优化模型",
    "550": "优化模型大小和性能",
    "551": "优化的 FlatBuffer 格式",
    "552": "优化的 FlatBuffer 格式，以 .tflite 为文件扩展名",
    "553": "位于其引脚排针上",
    "554": "体积小，采用核心板可拆的设计，核心板的大小只有70 x 45 mm，可以很方便的集成在各种嵌入式应用中",
    "555": "作为判断训练结果的参数",
    "556": "作为模型优化算法",
    "557": "作为模型的优化器",
    "558": "作为模型的损失函数",
    "559": "作为迁移学习的基础模型",
    "560": "使权重和激活值的 Post training 更简单",
    "561": "使用 GPU 加速模型运算，提高运算效率",
    "562": "使用 JavaScript，降低前端工程师入门门槛",
    "563": "使用 Python API 进行转换",
    "564": "使用 Python 或其他编程语言编写程序",
    "565": "使用 SavedModel 格式存储",
    "566": "使用 TFLite 模型转换器转换成 TFLite 文件格式(FlatBuffers 格式)",
    "567": "使用 TFLite 转换器转换模型",
    "568": "使用 TensorFlow Lite 支持库预处理模型输入和后处理模型输出",
    "569": "使用 TensorFlow Lite 解释器（提供多种语言的 API）在设备端运行模型",
    "570": "使用 TensorFlow Lite 转换器将模型转换为 TensorFlow Lite 格式",
    "571": "使用 from_saved_model() 或 from_keras_model()",
    "572": "使用32个3x3的滤波器",
    "573": "使用3×3的卷积核，并在输出上使用Relu激活函数",
    "574": "使用BCM编号、物理引脚Broad编号",
    "575": "使用C、C++开发并可被其他语言包使用",
    "576": "使用GPU来加速数学运算",
    "577": "使用lambda函数对images进行归一化处理并保持labels不变",
    "578": "使用优化器'sgd'和损失函数'mean_squared_error'",
    "579": "使用低学习率编译模型",
    "580": "使用低学习率重新编译模型",
    "581": "使用层构建模型",
    "582": "使用机器视觉识别障碍物",
    "583": "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响",
    "584": "使用深度可分离的卷积",
    "585": "使用计算机视觉相关模型，包括实时摄像机",
    "586": "使用预编译库",
    "587": "保存完整的TensorFlow模型",
    "588": "保存模型",
    "589": "保存训练数据的类别标签",
    "590": "保护LED和GPIO引脚",
    "591": "保持了很多通用性",
    "592": "保留原来大规模训练的优势",
    "593": "借助低级运算构建模型",
    "594": "允许解释器在设备的 GPU 上运行适当的运算符",
    "595": "全能 IDE",
    "596": "全连接(Full Connected)层",
    "597": "全连接层",
    "598": "全连接网络",
    "599": "共享的内存缓冲区",
    "600": "关联概率与类别标签",
    "601": "关闭LED灯",
    "602": "具有shape属性定义数组形状",
    "603": "兼容度高",
    "604": "内存只有几十KB",
    "605": "内存回收问题突出",
    "606": "内存高效",
    "607": "内置的算子",
    "608": "写一段简单的测试代码",
    "609": "写入镜像",
    "610": "冻结前100层",
    "611": "冻结预训练模型并更新分类器的权重",
    "612": "准确度",
    "613": "准确率指标",
    "614": "减少了内存碎片化",
    "615": "减少服务器运算，提高服务器资源利用和客户端响应速度",
    "616": "出门问问智能音箱",
    "617": "分类器",
    "618": "分类层",
    "619": "分类结果的概率",
    "620": "创建0~1之间平均分配的100个值",
    "621": "创建TFLiteConverter实例并加载Keras模型",
    "622": "创建Tensor实例",
    "623": "创建、训练和导出自定义 TensorFlow Lite 模型",
    "624": "创建了一个安装脚本",
    "625": "创建包含多个 Dense 层的模型",
    "626": "创建实例并加载模型",
    "627": "创建形状为[2,3]的张量",
    "628": "创建解释器、分配张量等功能",
    "629": "创新奇智",
    "630": "创新奇智智能质检一体机",
    "631": "初始化TensorFlow Lite解释器",
    "632": "利用 Android 神经网络 API（Android NN API)",
    "633": "利用在同一域中的较大数据集上训练的模型所学习的特征",
    "634": "利用手机上的加速器，比如 GPU 或者 DSP",
    "635": "利用计算机对图像进行处理、分析和理解，以识别各种不同模式的目标和对象的技术",
    "636": "前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像",
    "637": "剪刀石头布手势识别",
    "638": "功耗非常低，有两种模式： 5W（低功耗模式；可以使用 USB 口供电） 10W（必须使用 Power Jack 外接5V 电源供电）",
    "639": "功能强大的编程语言，易于使用，易于阅读和编写",
    "640": "功能强大的边缘计算设备",
    "641": "功能强大，交互式、富文本，还有丰富的插件、主题修改、多语言支持",
    "642": "功能接线的引脚号（如TXD、PWM0等）",
    "643": "加载 @tensorflow/tfjs 和 @tensorflow/tfjs-vis 两个 TFJS 模块的代码",
    "644": "加载 @tensorflow/tfjs 和 @tensorflow/tfjs-vis 两个 TFJS 模块的脚本",
    "645": "加载和使用 TensorFlow Hub 上的模型",
    "646": "加载和执行TFLite模型",
    "647": "加载和运行TFLite模型",
    "648": "加载数据并准备进行训练, 定义模型结构, 训练模型并监视其性能, 评估模型",
    "649": "加载数据，定义模型，训练循环并指定UI元素",
    "650": "加载模型",
    "651": "加载面孔照片",
    "652": "加速GPU上的模型推理",
    "653": "加速模型推理过程",
    "654": "动态显示训练的过程",
    "655": "包含一个完整的TensorFlow程序，不仅包含权重值，还包含计算",
    "656": "包含像素缩放和数据增强功能",
    "657": "包含命令行工具gpio，用于设置、读写GPIO管脚",
    "658": "包含完整的TensorFlow程序",
    "659": "千兆以太网端口",
    "660": "单一芯片的小型计算机",
    "661": "单个图像的维度为[28,28,1]",
    "662": "占用更少的磁盘和内存，更快更高效",
    "663": "卷积图像分类模型",
    "664": "卷积完成后应用于数据的激活函数",
    "665": "卷积层",
    "666": "卷积层与全连接层",
    "667": "卷积层输入",
    "668": "取消冻结模型的顶层",
    "669": "受限于GPU内存的大小",
    "670": "只使用在C语言中",
    "671": "只提供了基本的转化功能",
    "672": "可以使用树莓派摄像头，IMX219模组800万像素",
    "673": "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的 TensorFlow 预训练模型中选择一个模型直接使用或重新训练",
    "674": "可以创建任何非闭环的计算图",
    "675": "可以利用手机上的加速器，比如 GPU 或者 DSP 等",
    "676": "可以实时识别照相机所拍摄的花卉",
    "677": "可以指定目标尺寸、批次大小和子集类型",
    "678": "可以添加--no-cache-dir参数来避免缓存问题",
    "679": "可以直接使用cv2.videocapture打开",
    "680": "可以直接在浏览器中运行，无需安装或借助后端",
    "681": "可以设置访问密码增强安全性",
    "682": "可以调用不同的硬件加速器比如GPU进行执行",
    "683": "可以跨平台部署",
    "684": "可以通过软件编程进行控制",
    "685": "可以配置为输入或输出",
    "686": "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型",
    "687": "可能存在过度拟合",
    "688": "可能导致模型过拟合",
    "689": "可能导致预训练模型忘记已学内容",
    "690": "可视化模型训练的过程和结果",
    "691": "可视化模型预测结果和原始数据",
    "692": "启动图标",
    "693": "命令行 TensorFlow Lite 转换器命令行工具",
    "694": "命令行与 Python API",
    "695": "命令行工具",
    "696": "命令行工具和 Python API",
    "697": "商品流通过程中，特别是无人货架、智能零售柜等无人零售领域",
    "698": "商品识别",
    "699": "四引脚按键",
    "700": "四脚按键",
    "701": "回调函数",
    "702": "图像分类",
    "703": "图像分类、物体检测、分割和语音处理",
    "704": "图像分类、物体检测、分割和语音处理等应用程序中并行运行多个神经网络",
    "705": "图像分类任务",
    "706": "图像和视频处理",
    "707": "图像识别",
    "708": "图像识别技术",
    "709": "图像识别模型",
    "710": "在 Android 与 iOS 平台上使用",
    "711": "在 Android 应用中使用 TFLite 解释器运行模型",
    "712": "在 Android 设备上运行图像识别模型 MobileNets_v2来识别花卉",
    "713": "在 Node 环境运算速度与 Python 不相上下",
    "714": "在18号引脚处设置",
    "715": "在不同设备上使用硬件加速",
    "716": "在图像中检测面部，如果检测到面部会返回面部所在的矩形区域 Rect(x,y,w,h)",
    "717": "在大规模数据处理上不如Python高效",
    "718": "在官网下载安装包后安装",
    "719": "在小型数据集上训练模型",
    "720": "在展平操作之前依赖于最后一层",
    "721": "在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战",
    "722": "在有 GPU 加速的手机上运行 MobileNet 图像分类，模型运行速度可以提高",
    "723": "在有 GPU 加速的手机上运行图像分类，模型运行速度可以提高 5.5 倍",
    "724": "在模型转换过程中使用训练后量化",
    "725": "在每一个训练周期显示训练情况",
    "726": "在浏览器上开发模型或运行已训练的模型",
    "727": "在浏览器中加载",
    "728": "在浏览器中训练模型",
    "729": "在浏览器环境中实现深度学习的功能",
    "730": "在生产环境中不需要",
    "731": "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化",
    "732": "在移动和嵌入式设备上运行推理",
    "733": "在移动端、嵌入式和物联网设备上运行 TensorFlow 模型",
    "734": "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型",
    "735": "在移动设备和嵌入式设备上运行TensorFlow模型",
    "736": "在给定设备上实现性能、模型大小和准确性的理想平衡",
    "737": "在训练期间验证损失和准确性",
    "738": "在训练顶层分类器并将预训练模型设置为不可训练之后",
    "739": "在设备端运行TFLite模型",
    "740": "在资源有限的硬件上运行",
    "741": "在边缘设备上运行 TensorFlow 模型推理",
    "742": "在边缘设备上运行 TensorFlow 模型推理的官方框架",
    "743": "在靠近物或数据源头的一侧，采用网络、计算、存储、应用核心能力为一体的开放平台，就近提供最近端服务",
    "744": "基于 TF Mobile 的经验，也继承了 TFMini 和内部其他类似项目的很多优秀工作",
    "745": "基于 WebGL 加速的开放源代码 JavaScript 机器学习库",
    "746": "基于一个流线型的架构，使用深度可分离的卷积",
    "747": "基于流线型架构的轻量级深层神经网络",
    "748": "基于现有模型构建 Interpreter",
    "749": "基于现有的模型进行继续训练",
    "750": "基础模型的各项参数变量不会被新的训练修改数据",
    "751": "增加一个事件的检测函数",
    "752": "处理媒体应用程序",
    "753": "处理简单的数据",
    "754": "多个张量",
    "755": "多种级别的量化支持",
    "756": "多种编程语言",
    "757": "大大降低移动端及IoT设备端的深度学习技术门槛",
    "758": "大电流可能损坏LED和供电设备",
    "759": "大而复杂的模型",
    "760": "大量易于学习的教程",
    "761": "头信息",
    "762": "如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，二进制文件的大小不到 300 KB",
    "763": "委托（Delegates）",
    "764": "子图",
    "765": "子图本身的输入和输出",
    "766": "存储已安装软件包的名称和版本",
    "767": "存储模型权重",
    "768": "存放训练好的模型供开发人员复用",
    "769": "学习AI和构建有趣应用程序",
    "770": "学习空间不变的变换",
    "771": "安全检查、身份核验与移动支付",
    "772": "安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB",
    "773": "安装 OpenCV 项目",
    "774": "安装 Python 包依赖项",
    "775": "安装 TensorFlow",
    "776": "安装Python",
    "777": "安装Python包",
    "778": "安装依赖",
    "779": "安装依赖项",
    "780": "安装和升级 pip3",
    "781": "安装所需的系统包",
    "782": "安装相应的依赖包",
    "783": "完全基于 JavaScript 从头开发、训练和部署模型",
    "784": "完全基于神经网络的移动端语音识别",
    "785": "完成分类任务",
    "786": "官方已经停止维护",
    "787": "官方推荐",
    "788": "官方集成到Python的工具",
    "789": "定义模型的拓扑结构",
    "790": "定义的神经元网络层与层之间的关系较为随意",
    "791": "定位图像中的人脸位置",
    "792": "实例化预先训练的模型，并在顶部添加全连接的分类器",
    "793": "实现一个在手机上运行的 app",
    "794": "实现人体姿势估计",
    "795": "实现识别花卉模型",
    "796": "室内避开障碍物",
    "797": "对 SIMD 指令功能特别有益",
    "798": "对images进行归一化处理",
    "799": "对图像数据进行归一化处理",
    "800": "对手写数字的图像进行分类",
    "801": "对数据降维",
    "802": "对模型的权重产生了更一致且变化较小的渐变更新",
    "803": "对现有 CPU 平台的支持",
    "804": "对训练图像随机变换引入多样性",
    "805": "对输入图像进行预处理",
    "806": "对随机目标函数执行一阶梯度优化的算法",
    "807": "导入 TensorFlow Lite 库",
    "808": "将 Keras 模型保存为 SavedModel 格式",
    "809": "将 NPM 模块转换为在线可以引用的免费服务",
    "810": "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API",
    "811": "将 TensorFlow 模型转换为 TFLite 格式",
    "812": "将 TensorFlow 模型转换为 TensorFlow Lite 格式",
    "813": "将 TensorFlow 模型转换为方便解释器使用的格式",
    "814": "将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能",
    "815": "将Keras模型转换为TensorFlow Lite模型",
    "816": "将SavedModel转换为TFLite格式",
    "817": "将TensorFlow模型转换为TFLite文件格式(FlatBuffers格式)",
    "818": "将maven源google()和jcenter()替换为国内镜像",
    "819": "将三维张量展开到1维",
    "820": "将三维张量展开到一维",
    "821": "将人脸编码列表与候选编码进行比较",
    "822": "将前一层的输出平铺到一个向量中",
    "823": "将原始数据转变为TensorFlow可读的张量格式",
    "824": "将图片分类到1000类",
    "825": "将大规模内存操作放置在其回调中执行",
    "826": "将彩色图像转换为灰度图像，检测图像中的人脸，在边界周围绘制矩形",
    "827": "将所有图像加载到一个模型需要的特定的大小",
    "828": "将模型保存为TFLite兼容格式",
    "829": "将模型加载到内存中",
    "830": "将模型嵌入到二进制文件中，这样就可以在设备上运行和部署模型",
    "831": "将模型显示在浏览器中",
    "832": "将模型转换为移动设备兼容格式",
    "833": "将模型输出概率与类别标签关联",
    "834": "将特征转换为每个图像对应一个1280元素向量",
    "835": "将网络的每一层简单的叠在一起",
    "836": "将输入数据转换成模型接收的形式或排布，如resize原始图像到模型输入大小",
    "837": "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型",
    "838": "将镜像写入 microSD 卡",
    "839": "小一点的模型",
    "840": "尝试简化 TensorFlow 并在移动设备上运行",
    "841": "工业物联智能设备开发",
    "842": "工作目录",
    "843": "已经训练好的分类器，其中包括面部，眼睛，微笑等",
    "844": "常开触点",
    "845": "常闭触点",
    "846": "应对快速变化需求的软件开发模式",
    "847": "应用于树莓派的GPIO控制库函数",
    "848": "应用于输入数据的滑动卷积滤波器窗口的大小",
    "849": "应用于输入数据的滑动窗口大小",
    "850": "应用于输入数据的滤波器窗口的数量",
    "851": "应用深度学习算法的一种实践应用",
    "852": "应用程序在边缘侧发起，产生更快的网络服务响应，满足行业在实时业务、应用智能、安全与隐私保护等方面的基本需求",
    "853": "底层 Core API 和最高级的 Layers API",
    "854": "廉价且周边设备多",
    "855": "延迟一秒钟",
    "856": "延迟较低",
    "857": "建议最小采用 64 GB UHS-1 卡",
    "858": "开关去抖",
    "859": "开发 Android 应用",
    "860": "开发依赖",
    "861": "开箱即用的开发库，无需编写基础复杂的数学问题",
    "862": "引入优化以减小二进制文件的大小和提高性能",
    "863": "引用 Model 的内存缓冲区的一片区域，提高内存效率",
    "864": "张量",
    "865": "张量(Tensor)",
    "866": "张量形状是(image_height, image_width, color_channels)",
    "867": "张量连续地从一层传递到下一层",
    "868": "归一化操作",
    "869": "当压力撤销时电路断开",
    "870": "当压力施压时电路接通",
    "871": "形状为[null, 10]的张量",
    "872": "形状为[null, 28, 28, 1]的张量",
    "873": "形状是(224,224,3)",
    "874": "微调",
    "875": "微调过程",
    "876": "必须与正在使用的 JetPack 版本一致",
    "877": "必须在开机前先装上去，系统才能识别 CSI 摄像头",
    "878": "快速",
    "879": "快速启动",
    "880": "快速启动深度学习推理演示",
    "881": "忽略由于开关抖动引起的小于",
    "882": "恢复训练",
    "883": "成功配置好 CUDA",
    "884": "手写数字识别",
    "885": "打乱数据集中数据顺序",
    "886": "打乱数据顺序，创建特征向量和标签向量，转换为张量格式，进行归一化操作",
    "887": "打开现有 Android Studio 项目",
    "888": "打开项目图标",
    "889": "执行10个周期",
    "890": "执行TFLite模型推理",
    "891": "执行一个函数并清除所有创建的中间张量，释放它们的GPU内存",
    "892": "执行推理",
    "893": "执行最终的分类",
    "894": "执行模型推理",
    "895": "执行模型推理过程",
    "896": "执行模型文件在输入数据上定义的运算符，输出推理结果",
    "897": "执行模型转换过程生成TFLite模型",
    "898": "拷贝模型和标签文件到assets目录",
    "899": "指定从哪个层开始进行微调的参数",
    "900": "指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录",
    "901": "指定含有 TensorFlow 1.x 或者 2.0 使用 tf.keras model 生成 HDF5 文件的绝对路径目录",
    "902": "指定引脚编号系统",
    "903": "指定输出文件的绝对路径",
    "904": "损失函数使用类别交叉熵",
    "905": "接受 TFLite 模型",
    "906": "控制GPIO引脚",
    "907": "控制LED灯的亮暗",
    "908": "控制外部硬件设备",
    "909": "控制是否以确定性顺序返回批处理",
    "910": "控制树莓派的GPIO",
    "911": "控制迁移学习中微调的起始层",
    "912": "推理速度提高了30%",
    "913": "描述构建和运行示例所需的依赖项",
    "914": "提供 5V⎓2A 的高品质电源为开发者套件供电",
    "915": "提供了一些转换工具压缩模型，进行算子融合并生成代码",
    "916": "提供交互式编程环境",
    "917": "提供低级的机器学习构建模块和高级的类似Keras的API",
    "918": "提供多种语言的 API",
    "919": "提供更多灵活性和控制",
    "920": "提供经过充分认证的模型",
    "921": "提供训练好的模型供开发人员复用",
    "922": "提供预训练模型和演示项目",
    "923": "提问或分享项目",
    "924": "提高模型准确率",
    "925": "提高模型性能",
    "926": "摄像头预捕获的图像宽度、高度、窗口显示的图像宽度、高度、捕获帧率、是否旋转图像",
    "927": "支持 GPU 硬件加速",
    "928": "支持各种环境的部署",
    "929": "支持多种编程语言",
    "930": "支持大规模的模型训练",
    "931": "支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析",
    "932": "支持算子优化和编译优化",
    "933": "支持设备端机器学习推断",
    "934": "支持设备端机器学习推断，延迟较低，并且二进制文件很小",
    "935": "支持量化原生支持",
    "936": "支持预装驱动程序的 RPi 相机，并且可以很容易地用作即插即用外围设备，不需要安装驱动程序",
    "937": "敏捷开发",
    "938": "教育",
    "939": "数据图像的采集、模型的训练、参数的调整、模型文件生成、网页端部署、网络摄像头检查",
    "940": "数据规范化和转换为张量类型",
    "941": "数据转换",
    "942": "数据集",
    "943": "数据预处理",
    "944": "整个安装需要两个小时才能完成",
    "945": "文字处理",
    "946": "无需使用ByteBuffer来处理图像，提供了方便的支持库来简化图像预处理",
    "947": "易于设置和使用，兼容许多流行配件",
    "948": "是异步函数",
    "949": "显示模型架构",
    "950": "显示每个类别的准确度",
    "951": "显示混淆矩阵",
    "952": "普通GPIO口",
    "953": "智能读码机",
    "954": "更换国内源如阿里、清华",
    "955": "更新可视化元素",
    "956": "更注重考虑实时性，内存高效",
    "957": "更谨慎地控制内存何时回收",
    "958": "更轻量、特别为各种端侧设备优化的算子库、能够利用各种硬件加速",
    "959": "更轻量，二进制文件的大小约为 1 MB（针对 32 位 ARM build）",
    "960": "更适合于边缘设备部署",
    "961": "最后的神经网络层",
    "962": "最大池化层",
    "963": "最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口",
    "964": "有一个名字",
    "965": "服装厂质检",
    "966": "机器学习和计算机视觉应用",
    "967": "机器学习和计算机视觉应用，如物体检测、人脸识别、图像分割等视觉任务",
    "968": "构建CNN模型",
    "969": "构建和运行mnist代码",
    "970": "构建和运行机器学习模型",
    "971": "构建小型移动机器人、人脸签到打卡、口罩识别、智能门锁、智能音箱等复杂 AI 系统",
    "972": "构建工具用于编写更大的程序",
    "973": "构建神经网络",
    "974": "构建神经网络的全连接层",
    "975": "构成检测目标的相邻矩形的最小个数",
    "976": "查看图像及其标签",
    "977": "查看开发板系统信息",
    "978": "查看树莓派的GPIO引脚信息",
    "979": "标准算子",
    "980": "标签文件",
    "981": "树莓派",
    "982": "树莓派GPIO端口文件目录",
    "983": "树莓派接口",
    "984": "树莓派的官方编程语言",
    "985": "树莓派系统",
    "986": "树莓派系统升级",
    "987": "树莓派通用输入/输出接口（GPIO）",
    "988": "核心运行时",
    "989": "格式化 microSD 卡",
    "990": "梯度下降",
    "991": "检查模型对新数据的泛化情况",
    "992": "检测人脸",
    "993": "检测关键身体部位位置",
    "994": "检测关键身体部位的位置",
    "995": "检测面部特征点",
    "996": "模型",
    "997": "模型优化",
    "998": "模型优化工具",
    "999": "模型优化工具包",
    "1000": "模型可以与 Python 等其他语言模型互转",
    "1001": "模型执行流图",
    "1002": "模型推理",
    "1003": "模型文件和标签文件",
    "1004": "模型期望的形状",
    "1005": "模型的计算节点",
    "1006": "模型的输入特征",
    "1007": "模型的预测目标",
    "1008": "模型精度达到98%",
    "1009": "模型编译",
    "1010": "模型训练",
    "1011": "模型评估",
    "1012": "模型预测",
    "1013": "每一列代表预测值，每一行代表实际的类别",
    "1014": "每个周期由大约110批次组成",
    "1015": "每次批量处理512个图像",
    "1016": "比 CPU 执行更快的浮点矩阵运算",
    "1017": "池化层",
    "1018": "汽车功率（Horsepower）",
    "1019": "汽车油耗（MPG）",
    "1020": "没有操作系统",
    "1021": "活跃开发者社区打造的开源项目",
    "1022": "流入模型第一层的数据的形状",
    "1023": "测试Python开发环境并查看当前Python版本",
    "1024": "测试数据",
    "1025": "测试的软件包、webpack或Babel",
    "1026": "浏览器可以很好可视化机器训练过程",
    "1027": "浏览器可调用设备的摄像头、麦克风等增加应用场景",
    "1028": "混淆矩阵",
    "1029": "添加 TensorFlow Lite 依赖",
    "1030": "清华源",
    "1031": "清理GPIO引脚的设置",
    "1032": "清除张量或变量并释放其GPU内存",
    "1033": "清除所有创建的中间张量并释放它们的GPU内存",
    "1034": "滑动窗口的步长",
    "1035": "激活、设置为输出状态、写入1",
    "1036": "激活函数为relu",
    "1037": "激活函数为softmax",
    "1038": "灵活的架构可以将模型部署到桌面、服务器或移动设备中的 CPU 或 GPU 上",
    "1039": "点亮LED灯",
    "1040": "爱奇艺",
    "1041": "版本变化后 API 函数会改变",
    "1042": "版本变化后API函数会改变",
    "1043": "物理引脚Broad编号",
    "1044": "特别为各种端侧设备优化的算子库",
    "1045": "瓶颈层",
    "1046": "生成 HDF5 文件的绝对路径目录",
    "1047": "生成SavedModel",
    "1048": "生成一个批次一个批次的图片，以生成器的形式给模型训练",
    "1049": "生成一个批次的图片，以生成器的形式给模型训练",
    "1050": "生成批次的图片以进行模型训练",
    "1051": "用5x5在空间位置上进行平均",
    "1052": "用于 5V 电源输入",
    "1053": "用于存储数据的JavaScript文件",
    "1054": "用于工具的配置中心",
    "1055": "用于构建网页的HTML文件",
    "1056": "用于监督学习",
    "1057": "用于编写JavaScript代码的文件",
    "1058": "用于训练模型",
    "1059": "用于随机初始化模型权重的方法",
    "1060": "用于预测",
    "1061": "用作启动设备和主存储器",
    "1062": "用到的算子索引",
    "1063": "用户在自己的工作台中使用 TensorFlow API 构造 TensorFlow 模型",
    "1064": "用来转换 SavedModel 格式模型",
    "1065": "用来转换 concrete functions",
    "1066": "用来转换 tf.keras 模型",
    "1067": "用来连接 DP 屏幕",
    "1068": "由Gordon Henderson编写维护",
    "1069": "由jupyter软件自动生成",
    "1070": "由常开触点、常闭触点组合而成",
    "1071": "电信号从低电平到高电平，或从高电平到低电平状态的改变",
    "1072": "电阻",
    "1073": "登录 Jetson Nano",
    "1074": "目前有130个左右",
    "1075": "目前有130个左右，它与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化",
    "1076": "直接串联3.3V电源会产生大电流",
    "1077": "直接在 Objective-C 代码中使用 C API",
    "1078": "直接引用 TensorFlow.js 发布的 NPM 包中已经打包安装好的 JavaScript 代码",
    "1079": "直接更新树莓派系统",
    "1080": "直接部署或用于迁移学习",
    "1081": "直流桶式插座",
    "1082": "相比 Protocol Buffer 有更高的性能和更小的大小",
    "1083": "硬件加速代理(Hardware accelerator delegate)",
    "1084": "确认 CUDA 已经被正常安装",
    "1085": "神经元权重计算中的偏置量",
    "1086": "离线语音识别",
    "1087": "科沃斯扫地机器人",
    "1088": "移动应用中的OCR处理",
    "1089": "移动端及IoT设备端的深度学习技术",
    "1090": "移动端模型部署",
    "1091": "移动行业处理器接口（MIPI）的相机串行接口（CSI）端口",
    "1092": "移动设备",
    "1093": "端侧机器学习",
    "1094": "第一个卷积层",
    "1095": "第二、三卷积层",
    "1096": "简化图像预处理和输出处理",
    "1097": "简单的 API 用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型",
    "1098": "简单的线性回归的实验",
    "1099": "算子优化",
    "1100": "算子优化和常见的编译优化、量化的原生支持",
    "1101": "算子实现",
    "1102": "算子库",
    "1103": "算子库(Op kernels)",
    "1104": "算子融合、常数折叠、无用代码删除",
    "1105": "类别交叉熵损失函数",
    "1106": "精度达到98%",
    "1107": "精确度不高的任务",
    "1108": "线性堆叠layers的模型",
    "1109": "给脸部编码",
    "1110": "编译 OpenCV",
    "1111": "编译 Python 模块",
    "1112": "编译模型，设置优化器和损失函数",
    "1113": "缩减卷积结果的大小",
    "1114": "缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响",
    "1115": "缩短开发周期",
    "1116": "网易",
    "1117": "能够利用各种硬件加速",
    "1118": "能够执行完整全面的反向传播",
    "1119": "自定制算子",
    "1120": "花卉数据集中的图片",
    "1121": "花卉识别 app",
    "1122": "花卉识别模型",
    "1123": "英伟达官方或开源社区",
    "1124": "获取图像数据、处理位图、调用姿势估计函数、绘制关键点",
    "1125": "获取张量的指针",
    "1126": "获取张量的数据",
    "1127": "获取更多的Jetson平台信息",
    "1128": "获取有趣的项目",
    "1129": "获取概率最大的类别索引",
    "1130": "衡量所有预测中正确预测的百分比",
    "1131": "表示训练集的准确度",
    "1132": "表示训练集的损失值",
    "1133": "表示验证集的准确度",
    "1134": "表示验证集的损失值",
    "1135": "观测开关去抖效果",
    "1136": "视频中的AR效果",
    "1137": "解决JavaScript内存回收问题",
    "1138": "解决特定问题",
    "1139": "解决跨域问题",
    "1140": "解释器和转换器",
    "1141": "解释输出",
    "1142": "计算分类概率",
    "1143": "计算已知人脸和未知人脸特征向量的距离",
    "1144": "计算机视觉应用",
    "1145": "计算能力不高，勉强可以使用一些小规模、并且优化过的网络进行推理，训练的话还是不够用的",
    "1146": "计算节点的输入和输出",
    "1147": "计算预测结果的softmax概率",
    "1148": "让输入输出映射到0-1之间，保证后期更有效地训练",
    "1149": "训练分类器",
    "1150": "训练并评估训练的结果",
    "1151": "训练数据",
    "1152": "训练数据和测试数据",
    "1153": "训练数据集很大且类似于预训练模型训练的原始数据集",
    "1154": "训练期间将不更新预训练网络的权重，只在 MobileNet V2基础模型上训练了几层",
    "1155": "训练期间需要更多的内存",
    "1156": "训练模型",
    "1157": "训练集，用于训练模型",
    "1158": "训练顶层分类器",
    "1159": "训练预训练模型的顶层权重",
    "1160": "训练预训练模型的顶层的权重以及刚添加的分类器的训练",
    "1161": "记录训练日志",
    "1162": "记录训练过程中的日志数据",
    "1163": "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，对量化特别有益",
    "1164": "设置 OpenCV 的内容、位置和方式",
    "1165": "设置 converter.optimizations=[tf.lite.Optimize.DEFAULT]",
    "1166": "设置 model.trainable = False",
    "1167": "设置GPIO引脚模式",
    "1168": "设置model.trainable = False",
    "1169": "设置上拉电阻",
    "1170": "设置为100表示从第100层开始微调",
    "1171": "设置为32，表示一次采样32条训练数据",
    "1172": "设置为50，表示遍历所有样本50次",
    "1173": "设置为true，表示打乱数据集",
    "1174": "设置前100层为不可训练",
    "1175": "设置在训练中基础模型的各项参数变量不会被新的训练修改数据",
    "1176": "设置引脚为输入或输出模式",
    "1177": "设置输入张量值",
    "1178": "评估准确性",
    "1179": "评估分类器的准确性",
    "1180": "评估训练有素的模型的性能",
    "1181": "识别图像里的空间模式，例如线条和物体局部",
    "1182": "识别手写数字",
    "1183": "识别花卉图片",
    "1184": "识别输入图像",
    "1185": "语音识别",
    "1186": "读取传感器数据和控制外部设备",
    "1187": "读取传感器数据，控制 LED 等外部设备",
    "1188": "读取输出张量值",
    "1189": "调整大小、裁剪、旋转和归一化图像",
    "1190": "调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征",
    "1191": "调用 Python API 或命令行进行转换",
    "1192": "调用CSI摄像头和USB摄像头",
    "1193": "调用getModel获取模型",
    "1194": "调用train函数训练模型",
    "1195": "调用不同的硬件加速器比如 GPU 进行执行",
    "1196": "资源有限，不能训练网络，可能导致内存溢出",
    "1197": "跨平台运行，包括 Android、iOS 以及基于 Linux 的 IoT 设备和微控制器",
    "1198": "转换 SavedModel 格式模型",
    "1199": "转换 concrete functions",
    "1200": "转换 tf.keras 模型",
    "1201": "转换和运行 TensorFlow 模型的工具",
    "1202": "转换数据",
    "1203": "转换模型",
    "1204": "软件PWM库",
    "1205": "软件源配置文件",
    "1206": "软链接",
    "1207": "轻量化",
    "1208": "轻量级",
    "1209": "轻量级、快速启动、内存高效",
    "1210": "较大的批次",
    "1211": "输入层",
    "1212": "输入层、隐藏层和输出层",
    "1213": "输入输出用到的 Tensor 索引",
    "1214": "输入（Xs）和标签（Ys）",
    "1215": "输出三维张量，形状为(height, width, channels)",
    "1216": "输出三维张量，形状描述(height, width, channels)",
    "1217": "输出层",
    "1218": "输出模式",
    "1219": "输出电压约为3.3V",
    "1220": "输出通道数为32",
    "1221": "输出通道数为64",
    "1222": "边做边学的理想工具",
    "1223": "边缘",
    "1224": "边缘操作",
    "1225": "边缘计算",
    "1226": "边缘计算设备",
    "1227": "迁移学习",
    "1228": "运行 TensorFlow Lite 模型",
    "1229": "运行Jupyter lab服务",
    "1230": "运行Sync Gradle",
    "1231": "运行TFLite推理并获取输出概率",
    "1232": "运行功率仅为 5 瓦",
    "1233": "运行各种深度学习模型",
    "1234": "运行在 Node.js 或浏览器环境中",
    "1235": "运行已有的 Python 版 TensorFlow 模型",
    "1236": "运行服务监听的IP地址、端口、notebooks内核目录、浏览器开关设置",
    "1237": "运行模型推理",
    "1238": "返回图像中每张人脸的128维人脸编码",
    "1239": "返回张量数据的副本",
    "1240": "返回的是数据的副本而非引用",
    "1241": "进行VNC连接",
    "1242": "进行内存清理工作，防止内存泄露",
    "1243": "进行大量的张量操作时使用可能会很麻烦",
    "1244": "远程桌面访问Jetson Nano",
    "1245": "连接LED灯和限流电阻到GPIO21和GND",
    "1246": "连接显示器、键盘和鼠标或通过SSH/VNC远程访问",
    "1247": "适应性低阶矩估计",
    "1248": "适用于多个平台",
    "1249": "适用于多个平台，提供了一个简单的 API",
    "1250": "选择模型",
    "1251": "选择模型、转换模型、部署到设备、优化模型",
    "1252": "选择镜像、选择驱动器、闪存",
    "1253": "逐步加载单个数据集的图像",
    "1254": "通过 WebGL 在 GPU 上执行计算大幅提高速度",
    "1255": "通过 pip 安装 Jupyter lab，如果网络环境较差导致下载软件包慢，可以考虑更换源",
    "1256": "通过 script 标签引入 index.js",
    "1257": "通过命令行转换模型",
    "1258": "通过脚本标签（script tags）或从 yarn（或者 NPM）安装并使用 Parcel，WebPack 或 Rollup 等工具构建工程",
    "1259": "通过迁移学习实现",
    "1260": "通过限流电阻串联到GPIO21，负极连接到GND",
    "1261": "郁金香(tulips)、玫瑰(roses)、浦公英(dandelion)、向日葵(sunflowers)、雏菊(daisy)",
    "1262": "部署TensorFlow Lite模型",
    "1263": "部署到设备",
    "1264": "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上",
    "1265": "配置Jupyter lab的运行参数",
    "1266": "配置build.gradle文件",
    "1267": "配置文件jupyter_notebook_config.py",
    "1268": "配置模型的优化器、损失函数和评估指标",
    "1269": "配置模型的优化器和损失函数",
    "1270": "配置项目依赖",
    "1271": "采用更小的模型格式，并提供了方便的模型转换器",
    "1272": "释放张量的GPU内存",
    "1273": "量化",
    "1274": "针对移动设备做了很多优化",
    "1275": "错误的连接和编程可能会导致设备损坏或故障",
    "1276": "镜像",
    "1277": "防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件",
    "1278": "防止应用程序中的内存泄漏",
    "1279": "阻塞函数，会阻塞程序执行，直到检测到一个边沿",
    "1280": "降低卷积层对位置的敏感",
    "1281": "降低存储器访问成本",
    "1282": "降低权重的精确表示，并且可选的降低存储和计算的激活值",
    "1283": "降低权重的精确表示，降低存储和计算的激活值",
    "1284": "降低用于读取和存储中间激活值的存储器访问成本",
    "1285": "需满足苛刻的功耗要求",
    "1286": "需要root权限",
    "1287": "需要使用GStreamer读取视频流",
    "1288": "需要大约两个半小时",
    "1289": "需要注意版本变化",
    "1290": "需要相应地增加epochs",
    "1291": "需要设置VNC密码和启用自动登录",
    "1292": "需要调整为模型期望的形状",
    "1293": "需要配置proxy或使用国内镜像",
    "1294": "需要高准确率的任务",
    "1295": "面包板、杜邦线公对母、LED灯、330欧姆电阻",
    "1296": "页面的基本结构，包含div标签、UI元素和JavaScript代码",
    "1297": "项目的清单文件",
    "1298": "预处理模型输入和后处理模型输出",
    "1299": "预处理输入图像",
    "1300": "预测",
    "1301": "预测不受图像顺序的影响",
    "1302": "预测汽车油耗效率",
    "1303": "预测汽车油耗（MPG）",
    "1304": "预测汽车的油耗效率 MPG",
    "1305": "预训练模型",
    "1306": "预训练模型和全连接的分类器",
    "1307": "预训练模型将忘记它学到的东西",
    "1308": "首次打开项目时",
    "1309": "验证集",
    "1310": "验证集，在每个时期结束时对模型进行测试",
    "1311": "高性能",
    "1312": "高性能场景创建的序列化库",
    "1313": "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）",
    "1314": "默认值为32，可以设置为64",
    "1315": "默认分类到1000类",
    "1316": "默认安装 JetPack 安装了对应的 OpenCV",
    "1317": "默认已安装的Python开发环境"
  }
}