[
  [
    "TensorFlow Lite",
    "用途",
    "在移动端、嵌入式和物联网设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow 模型",
    "是什么",
    "一种数据结构，包含了在解决特定问题时训练得到的机器学习网络的逻辑和知识"
  ],
  [
    "TensorFlow 模型",
    "用途",
    "解决特定问题"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "转换和运行 TensorFlow 模型的工具"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "存放训练好的模型供开发人员复用"
  ],
  [
    "TensorFlow Hub",
    "特点",
    "提供经过充分认证的模型"
  ],
  [
    "预训练模型",
    "用途",
    "直接部署或用于迁移学习"
  ],
  [
    "MobileNet",
    "示例",
    "TensorFlow Hub 上的一个模型"
  ],
  [
    "hub.KerasLayer",
    "用途",
    "加载和使用 TensorFlow Hub 上的模型"
  ],
  [
    "TensorFlow Lite 转换器",
    "可以接受",
    "Keras Model 和 SavedModel"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为 TFLite 格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "执行步骤",
    "调用 Python API 或命令行进行转换"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "支持算子优化和编译优化"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "支持量化原生支持"
  ],
  [
    "TensorFlow Lite 转换器",
    "组成部分",
    "tf.lite.TFLiteConverter"
  ],
  [
    "tf.lite.TFLiteConverter",
    "用途",
    "从 SavedModel 或 Keras Model 转换"
  ],
  [
    "tf.lite.TFLiteConverter",
    "执行步骤",
    "使用 from_saved_model() 或 from_keras_model()"
  ],
  [
    "tflite_convert",
    "用途",
    "通过命令行转换模型"
  ],
  [
    "算子优化",
    "包含",
    "算子融合、常数折叠、无用代码删除"
  ],
  [
    "量化",
    "特点",
    "在模型转换过程中使用训练后量化"
  ],
  [
    "量化",
    "执行步骤",
    "设置 converter.optimizations=[tf.lite.Optimize.DEFAULT]"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "执行模型文件在输入数据上定义的运算符，输出推理结果"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "适用于多个平台，提供了一个简单的 API"
  ],
  [
    "TensorFlow Lite 解释器",
    "组成部分",
    "GPU 委托"
  ],
  [
    "GPU 委托",
    "用途",
    "允许解释器在设备的 GPU 上运行适当的运算符"
  ],
  [
    "GPU",
    "特点",
    "比 CPU 执行更快的浮点矩阵运算"
  ],
  [
    "MobileNet",
    "示例",
    "在有 GPU 加速的手机上运行图像分类，模型运行速度可以提高 5.5 倍"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "优化模型大小和性能"
  ],
  [
    "量化",
    "用途",
    "降低权重的精确表示，并且可选的降低存储和计算的激活值"
  ],
  [
    "量化",
    "优点",
    "对现有 CPU 平台的支持"
  ],
  [
    "量化",
    "优点",
    "降低存储器访问成本"
  ],
  [
    "量化",
    "优点",
    "对 SIMD 指令功能特别有益"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "Post training quantization 和 Quantization-aware training"
  ],
  [
    "MobileNet V2",
    "用途",
    "实现识别花卉模型"
  ],
  [
    "MobileNet V2",
    "特点",
    "基于一个流线型的架构，使用深度可分离的卷积"
  ],
  [
    "迁移学习",
    "用途",
    "利用在同一域中的较大数据集上训练的模型所学习的特征"
  ],
  [
    "迁移学习",
    "步骤",
    "实例化预先训练的模型，并在顶部添加全连接的分类器"
  ],
  [
    "微调",
    "用途",
    "调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征"
  ],
  [
    "ImageDataGenerator",
    "用途",
    "生成一个批次一个批次的图片，以生成器的形式给模型训练"
  ],
  [
    "flow_from_directory",
    "用途",
    "逐步加载单个数据集的图像"
  ],
  [
    "MobileNet V2",
    "是",
    "基于流线型架构的轻量级深层神经网络"
  ],
  [
    "MobileNet V2",
    "用途",
    "图像分类任务"
  ],
  [
    "MobileNet V2",
    "特点",
    "使用深度可分离的卷积"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "预训练模型和全连接的分类器"
  ],
  [
    "迁移学习",
    "用途",
    "在小型数据集上训练模型"
  ],
  [
    "迁移学习",
    "步骤",
    "冻结预训练模型并更新分类器的权重"
  ],
  [
    "微调",
    "用途",
    "提高模型性能"
  ],
  [
    "微调",
    "条件",
    "训练数据集很大且类似于预训练模型训练的原始数据集"
  ],
  [
    "ImageDataGenerator",
    "用途",
    "生成批次的图片以进行模型训练"
  ],
  [
    "ImageDataGenerator",
    "特点",
    "包含像素缩放和数据增强功能"
  ],
  [
    "flow_from_directory",
    "用途",
    "逐步加载单个数据集的图像"
  ],
  [
    "flow_from_directory",
    "参数",
    "target_size设置为(224, 224)的正方形图像"
  ],
  [
    "flow_from_directory",
    "参数",
    "batch_size默认值为32，可设置为64"
  ],
  [
    "flow_from_directory",
    "参数",
    "shuffle参数设置为False以确定性顺序返回批处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "端侧机器学习"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "移动应用中的OCR处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "视频中的AR效果"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "文字处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "图像和视频处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "离线语音识别"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "IoT领域"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "工业物联智能设备开发"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "高性能"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "模型优化工具"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "Google Photos"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "Google Arts & Culture"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "Google Assistant"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "网易"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "爱奇艺"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "WPS"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "出门问问智能音箱"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "科沃斯扫地机器人"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "创新奇智智能质检一体机"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "智能读码机"
  ],
  [
    "Google Assistant",
    "用途",
    "语音识别"
  ],
  [
    "Google Assistant",
    "特点",
    "完全基于神经网络的移动端语音识别"
  ],
  [
    "Google Assistant",
    "示例",
    "Live Caption"
  ],
  [
    "MCU",
    "是什么",
    "单一芯片的小型计算机"
  ],
  [
    "MCU",
    "特点",
    "没有操作系统"
  ],
  [
    "MCU",
    "特点",
    "内存只有几十KB"
  ],
  [
    "科沃斯扫地机器人",
    "用途",
    "室内避开障碍物"
  ],
  [
    "科沃斯扫地机器人",
    "特点",
    "使用机器视觉识别障碍物"
  ],
  [
    "科沃斯扫地机器人",
    "结果",
    "推理速度提高了30%"
  ],
  [
    "创新奇智",
    "用途",
    "服装厂质检"
  ],
  [
    "tf.keras model",
    "用途",
    "生成 HDF5 文件的绝对路径目录"
  ],
  [
    "TensorFlow 模型导出",
    "支持",
    "SavedModel 和 Keras Sequential 两种模型导出方法和格式"
  ],
  [
    "SavedModel",
    "示例",
    "tflite_convert --saved_model_dir=/tmp/mobilenet_saved_model --output_file=/tmp/mobilenet.tflite"
  ],
  [
    "Keras H5",
    "示例",
    "tflite_convert --keras_model_file=/tmp/mobilenet_keras_model.h5 --output_file=/tmp/mobilenet.tflite"
  ],
  [
    "aaptOptions",
    "用途",
    "防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件"
  ],
  [
    "aaptOptions",
    "组成部分",
    "noCompress \"tflite\""
  ],
  [
    "Android环境部署",
    "步骤",
    "运行Sync Gradle"
  ],
  [
    "Android Studio",
    "条件",
    "需要配置proxy或使用国内镜像"
  ],
  [
    "build.gradle",
    "修改内容",
    "将maven源google()和jcenter()替换为国内镜像"
  ],
  [
    "buildscript",
    "组成部分",
    "repositories和dependencies"
  ],
  [
    "TensorFlow Lite",
    "是",
    "在边缘设备上运行 TensorFlow 模型推理的官方框架"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "跨平台运行，包括 Android、iOS 以及基于 Linux 的 IoT 设备和微控制器"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在边缘设备上运行 TensorFlow 模型推理"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "特别为各种端侧设备优化的算子库"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "能够利用各种硬件加速"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "更轻量，二进制文件的大小约为 1 MB（针对 32 位 ARM build）"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，二进制文件的大小不到 300 KB"
  ],
  [
    "TF Mobile",
    "是",
    "一个缩减版的 TensorFlow，简化了算子集，也缩小了运行库"
  ],
  [
    "TF Mobile",
    "用途",
    "尝试简化 TensorFlow 并在移动设备上运行"
  ],
  [
    "TFMini",
    "是",
    "Google 内部用于计算机视觉场景的解决方案"
  ],
  [
    "TFMini",
    "用途",
    "提供了一些转换工具压缩模型，进行算子融合并生成代码"
  ],
  [
    "TFMini",
    "用途",
    "将模型嵌入到二进制文件中，这样就可以在设备上运行和部署模型"
  ],
  [
    "TFMini",
    "特点",
    "针对移动设备做了很多优化"
  ],
  [
    "TFMini",
    "缺点",
    "在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战"
  ],
  [
    "TensorFlow Lite",
    "发展历史",
    "基于 TF Mobile 的经验，也继承了 TFMini 和内部其他类似项目的很多优秀工作"
  ],
  [
    "MobileNet V2",
    "用途",
    "将图片分类到1000类"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "最后的神经网络层"
  ],
  [
    "MobileNet V2",
    "特点",
    "默认分类到1000类"
  ],
  [
    "include_top=False",
    "用途",
    "不需要原有模型中最后的神经网络层"
  ],
  [
    "迁移学习",
    "特点",
    "不改变基础模型的各项参数变量"
  ],
  [
    "迁移学习",
    "优点",
    "保留原来大规模训练的优势"
  ],
  [
    "model.trainable = False",
    "用途",
    "设置在训练中基础模型的各项参数变量不会被新的训练修改数据"
  ],
  [
    "瓶颈层",
    "特点",
    "保持了很多通用性"
  ],
  [
    "瓶颈层",
    "用途",
    "在展平操作之前依赖于最后一层"
  ],
  [
    "池化层",
    "用途",
    "对数据降维"
  ],
  [
    "输出层",
    "组成部分",
    "5个节点"
  ],
  [
    "GlobalAveragePooling2D",
    "用途",
    "将特征转换为每个图像对应一个1280元素向量"
  ],
  [
    "GlobalAveragePooling2D",
    "特点",
    "用5x5在空间位置上进行平均"
  ],
  [
    "TFLite 模型文件格式",
    "采用",
    "FlatBuffers"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "更注重考虑实时性，内存高效"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "减少了内存碎片化"
  ],
  [
    "schema.fbs 文件",
    "定义",
    "TFLite 模型文件格式"
  ],
  [
    "TFLite 模型文件",
    "组成部分",
    "子图"
  ],
  [
    "TFLite 模型文件",
    "组成部分",
    "算子库"
  ],
  [
    "TFLite 模型文件",
    "组成部分",
    "共享的内存缓冲区"
  ],
  [
    "张量",
    "用途",
    "存储模型权重"
  ],
  [
    "张量",
    "用途",
    "计算节点的输入和输出"
  ],
  [
    "张量",
    "特点",
    "引用 Model 的内存缓冲区的一片区域，提高内存效率"
  ],
  [
    "算子实现",
    "组成部分",
    "OperatorCode"
  ],
  [
    "OperatorCode",
    "可以是",
    "内置的算子"
  ],
  [
    "OperatorCode",
    "可以是",
    "自定制算子"
  ],
  [
    "OperatorCode",
    "特点",
    "有一个名字"
  ],
  [
    "模型的计算节点",
    "组成部分",
    "用到的算子索引"
  ],
  [
    "模型的计算节点",
    "组成部分",
    "输入输出用到的 Tensor 索引"
  ],
  [
    "子图",
    "组成部分",
    "一系列的计算节点"
  ],
  [
    "子图",
    "组成部分",
    "多个张量"
  ],
  [
    "子图",
    "组成部分",
    "子图本身的输入和输出"
  ],
  [
    "花卉识别 app",
    "用途",
    "在 Android 设备上运行图像识别模型 MobileNets_v2来识别花卉"
  ],
  [
    "花卉识别 app",
    "组成部分",
    "TensorFlow Lite 解释器"
  ],
  [
    "花卉识别 app",
    "组成部分",
    "TensorFlow Lite 支持库"
  ],
  [
    "花卉识别 app",
    "特点",
    "可以实时识别照相机所拍摄的花卉"
  ],
  [
    "花卉识别模型",
    "实现方式",
    "通过迁移学习实现"
  ],
  [
    "花卉识别模型",
    "转换工具",
    "TFLite 转换器"
  ],
  [
    "TensorFlow Lite 支持库",
    "用途",
    "预处理模型输入和后处理模型输出"
  ],
  [
    "花卉识别 app",
    "执行步骤",
    "使用 TFLite 转换器转换模型"
  ],
  [
    "花卉识别 app",
    "执行步骤",
    "在 Android 应用中使用 TFLite 解释器运行模型"
  ],
  [
    "花卉识别 app",
    "执行步骤",
    "使用 TensorFlow Lite 支持库预处理模型输入和后处理模型输出"
  ],
  [
    "花卉识别 app",
    "执行步骤",
    "实现一个在手机上运行的 app"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "优化模型大小和性能"
  ],
  [
    "模型优化",
    "目标",
    "在给定设备上实现性能、模型大小和准确性的理想平衡"
  ],
  [
    "大而复杂的模型",
    "用途",
    "需要高准确率的任务"
  ],
  [
    "小一点的模型",
    "用途",
    "精确度不高的任务"
  ],
  [
    "小一点的模型",
    "优点",
    "占用更少的磁盘和内存，更快更高效"
  ],
  [
    "量化",
    "用途",
    "降低权重的精确表示，降低存储和计算的激活值"
  ],
  [
    "量化",
    "优点",
    "对现有 CPU 平台的支持"
  ],
  [
    "量化",
    "优点",
    "降低用于读取和存储中间激活值的存储器访问成本"
  ],
  [
    "量化",
    "优点",
    "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，对量化特别有益"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "多种级别的量化支持"
  ],
  [
    "Tensorflow Lite post-training quantization",
    "用途",
    "使权重和激活值的 Post training 更简单"
  ],
  [
    "Quantization-aware training",
    "用途",
    "以最小精度下降来训练网络"
  ],
  [
    "Quantization-aware training",
    "条件",
    "仅适用于卷积神经网络的一个子集"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "执行模型文件在输入数据上定义的运算符，输出推理结果"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "适用于多个平台"
  ],
  [
    "TensorFlow Lite 解释器",
    "提供",
    "简单的 API 用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型"
  ],
  [
    "Java",
    "调用方式",
    "try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) { interpreter.run(input, output); }"
  ],
  [
    "GPU",
    "优点",
    "比 CPU 执行更快的浮点矩阵运算"
  ],
  [
    "GPU",
    "示例",
    "在有 GPU 加速的手机上运行 MobileNet 图像分类，模型运行速度可以提高"
  ],
  [
    "MobileNet V2",
    "用途",
    "将图片分类到1000类"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "瓶颈层"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "分类层"
  ],
  [
    "MobileNet V2",
    "特点",
    "默认分类到1000类"
  ],
  [
    "include_top=False",
    "用途",
    "不需要原有模型中最后的神经网络层"
  ],
  [
    "迁移学习",
    "特点",
    "不改变基础模型的各项参数变量"
  ],
  [
    "迁移学习",
    "优点",
    "保留原来大规模训练的优势"
  ],
  [
    "model.trainable = False",
    "用途",
    "基础模型的各项参数变量不会被新的训练修改数据"
  ],
  [
    "瓶颈层",
    "特点",
    "保持了很多通用性"
  ],
  [
    "GlobalAveragePooling2D",
    "用途",
    "将特征转换为每个图像对应一个1280元素向量"
  ],
  [
    "tf.keras.Sequential",
    "组成部分",
    "base_model"
  ],
  [
    "tf.keras.Sequential",
    "组成部分",
    "Conv2D"
  ],
  [
    "tf.keras.Sequential",
    "组成部分",
    "Dropout"
  ],
  [
    "tf.keras.Sequential",
    "组成部分",
    "GlobalAveragePooling2D"
  ],
  [
    "tf.keras.Sequential",
    "组成部分",
    "Dense"
  ],
  [
    "Conv2D",
    "特点",
    "使用32个3x3的滤波器"
  ],
  [
    "Conv2D",
    "特点",
    "激活函数为relu"
  ],
  [
    "Dropout",
    "特点",
    "丢弃率为0.2"
  ],
  [
    "Dense",
    "特点",
    "5个节点的输出层"
  ],
  [
    "Dense",
    "特点",
    "激活函数为softmax"
  ],
  [
    "model.compile",
    "组成部分",
    "Adam优化器"
  ],
  [
    "model.compile",
    "组成部分",
    "类别交叉熵损失函数"
  ],
  [
    "model.compile",
    "组成部分",
    "准确率指标"
  ],
  [
    "MobileNet V2",
    "用途",
    "创建、训练和导出自定义 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "模型文件和标签文件"
  ],
  [
    "Android 应用",
    "用途",
    "识别花卉图片"
  ],
  [
    "TensorFlow Lite 示例",
    "来源",
    "TensorFlow 官网"
  ],
  [
    "flower_classification",
    "组成部分",
    "android 目录"
  ],
  [
    "flower_classification 项目",
    "包含",
    "start 目录和 finish 目录"
  ],
  [
    "Android Studio",
    "用途",
    "开发 Android 应用"
  ],
  [
    "TFLite 模型转换过程",
    "步骤",
    "用户在自己的工作台中使用 TensorFlow API 构造 TensorFlow 模型"
  ],
  [
    "TFLite 模型转换过程",
    "步骤",
    "使用 TFLite 模型转换器转换成 TFLite 文件格式(FlatBuffers 格式)"
  ],
  [
    "TFLite 解释器",
    "用途",
    "接受 TFLite 模型"
  ],
  [
    "TFLite 解释器",
    "用途",
    "调用不同的硬件加速器比如 GPU 进行执行"
  ],
  [
    "TFLite 文件格式",
    "是",
    "FlatBuffers 格式"
  ],
  [
    "Keras模型",
    "转换为",
    "TensorFlow Lite模型"
  ],
  [
    "TensorFlow Lite模型",
    "保存为",
    "model.tflite文件"
  ],
  [
    "TensorFlow",
    "包含",
    "TensorFlow Lite"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "算子库(Op kernels)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为方便解释器使用的格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "引入优化以减小二进制文件的大小和提高性能"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "目前有130个左右"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "与 TensorFlow 的核心算子库略有不同，并做了移动设备相关的优化"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "利用手机上的加速器，比如 GPU 或者 DSP"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "利用 Android 神经网络 API（Android NN API)"
  ],
  [
    "tf.saved_model.save",
    "用途",
    "生成SavedModel"
  ],
  [
    "tf.saved_model.save",
    "参数",
    "model和保存目录路径"
  ],
  [
    "SavedModel",
    "是",
    "TensorFlow模型的序列化格式"
  ],
  [
    "SavedModel",
    "特点",
    "可以跨平台部署"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite 模型",
    "特点",
    "优化的 FlatBuffer 格式"
  ],
  [
    "TensorFlow Lite 模型",
    "文件扩展名",
    ".tflite"
  ],
  [
    "TensorFlow Lite 转换器",
    "使用方法",
    "命令行与 Python API"
  ],
  [
    "Google",
    "推荐",
    "使用 Python API 进行转换"
  ],
  [
    "命令行工具",
    "特点",
    "只提供了基本的转化功能"
  ],
  [
    "FlatBuffers",
    "用途",
    "主要应用于游戏场景"
  ],
  [
    "FlatBuffers",
    "特点",
    "高性能场景创建的序列化库"
  ],
  [
    "FlatBuffers",
    "优点",
    "相比 Protocol Buffer 有更高的性能和更小的大小"
  ],
  [
    "FlatBuffers",
    "用途",
    "更适合于边缘设备部署"
  ],
  [
    "tflite_convert",
    "属于",
    "命令行 TensorFlow Lite 转换器命令行工具"
  ],
  [
    "tflite_convert",
    "安装方式",
    "与 TensorFlow 一起安装"
  ],
  [
    "--output_file",
    "参数说明",
    "Full path of the output file"
  ],
  [
    "--saved_model_dir",
    "参数说明",
    "Full path to the SavedModel directory"
  ],
  [
    "--keras_model_file",
    "参数说明",
    "Full path to the Keras H5 model file"
  ],
  [
    "--enable_v1_converter",
    "参数说明",
    "Enables the converter and flags used in TF 1.x instead of TF 2.x"
  ],
  [
    "Android Studio",
    "用途",
    "打开现有 Android Studio 项目"
  ],
  [
    "Android Studio",
    "组成部分",
    "启动图标"
  ],
  [
    "Android Studio",
    "组成部分",
    "打开项目图标"
  ],
  [
    "flower_classification/android/finish",
    "属于",
    "工作目录"
  ],
  [
    "model.tflite",
    "属于",
    "TensorFlow Lite 模型文件"
  ],
  [
    "label.txt",
    "属于",
    "标签文件"
  ],
  [
    "build.gradle",
    "用途",
    "配置项目依赖"
  ],
  [
    "Gradle 同步",
    "条件",
    "首次打开项目时"
  ],
  [
    "tensorflow-lite",
    "用途",
    "导入 TensorFlow Lite 库"
  ],
  [
    "dependencies",
    "组成部分",
    "build.gradle"
  ],
  [
    "implementation('org.tensorflow:tensorflow-lite:+')",
    "用途",
    "添加 TensorFlow Lite 依赖"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "用途",
    "转换模型"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "输入参数",
    "saved_model_dir"
  ],
  [
    "tf.lite.TFLiteConverter",
    "属于",
    "TensorFlow Lite"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "轻量级"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "快速启动"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "内存高效"
  ],
  [
    "TFLite 解释执行器",
    "组成部分",
    "核心运行时"
  ],
  [
    "TFLite 解释执行器",
    "组成部分",
    "标准算子"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "加载模型"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "转换数据"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "运行模型推理"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "解释输出"
  ],
  [
    "TFLite",
    "用途",
    "移动设备"
  ],
  [
    "TFLite",
    "支持语言",
    "Java"
  ],
  [
    "TFLite",
    "支持语言",
    "C++"
  ],
  [
    "TFLite",
    "支持语言",
    "Python"
  ],
  [
    "TFLite",
    "支持语言",
    "C"
  ],
  [
    "TFLite",
    "支持语言",
    "Object C"
  ],
  [
    "TFLite",
    "支持语言",
    "C#"
  ],
  [
    "TFLite",
    "支持语言",
    "Swift"
  ],
  [
    "TFLite",
    "部署方式",
    "从头编译"
  ],
  [
    "TFLite",
    "部署方式",
    "使用预编译库"
  ],
  [
    "TFLite",
    "部署方式",
    "Android JCenter Bintray 的 TFLite AAR"
  ],
  [
    "TFLite",
    "部署方式",
    "iOS CocoaPods"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "155层网络"
  ],
  [
    "微调",
    "步骤",
    "取消冻结模型的顶层"
  ],
  [
    "微调",
    "步骤",
    "设置前100层为不可训练"
  ],
  [
    "微调",
    "步骤",
    "使用低学习率重新编译模型"
  ],
  [
    "微调",
    "用途",
    "提高模型准确率"
  ],
  [
    "微调",
    "结果",
    "模型精度达到98%"
  ],
  [
    "微调",
    "缺点",
    "可能导致模型过拟合"
  ],
  [
    "TFLite",
    "用途",
    "将模型转换为移动设备兼容格式"
  ],
  [
    "SavedModel",
    "特点",
    "包含完整的TensorFlow程序"
  ],
  [
    "SavedModel",
    "特点",
    "不需要原始模型构建代码就可以运行"
  ],
  [
    "模型训练",
    "步骤",
    "设置model.trainable = False"
  ],
  [
    "模型训练",
    "步骤",
    "训练预训练模型的顶层权重"
  ],
  [
    "模型训练",
    "条件",
    "在训练顶层分类器并将预训练模型设置为不可训练之后"
  ],
  [
    "梯度下降",
    "缺点",
    "可能导致预训练模型忘记已学内容"
  ],
  [
    "mobilenetv2_1.00_224",
    "组成部分",
    "conv2d, dropout, global_average_pooling2d, dense"
  ],
  [
    "mobilenetv2_1.00_224",
    "特点",
    "Total params: 2,626,821, Trainable params: 368,837, Non-trainable params: 2,257,984"
  ],
  [
    "model.fit",
    "执行步骤",
    "train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=val_generator, validation_steps=len(val_generator)"
  ],
  [
    "微调",
    "条件",
    "设置 model.trainable = False"
  ],
  [
    "微调",
    "用途",
    "训练预训练模型的顶层的权重以及刚添加的分类器的训练"
  ],
  [
    "微调",
    "特点",
    "训练期间将不更新预训练网络的权重，只在 MobileNet V2基础模型上训练了几层"
  ],
  [
    "微调",
    "结果",
    "预训练模型将忘记它学到的东西"
  ],
  [
    "微调",
    "步骤",
    "取消冻结模型的顶层"
  ],
  [
    "MobileNet V2",
    "用途",
    "训练顶层分类器"
  ],
  [
    "MobileNet V2",
    "特点",
    "前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像"
  ],
  [
    "train_generator",
    "用途",
    "从目录中生成训练数据批次"
  ],
  [
    "val_generator",
    "用途",
    "从目录中生成验证数据批次"
  ],
  [
    "flow_from_directory",
    "特点",
    "可以指定目标尺寸、批次大小和子集类型"
  ],
  [
    "MobileNetV2",
    "是什么",
    "一个预加载了ImageNet训练权重的深度学习模型"
  ],
  [
    "MobileNetV2",
    "用途",
    "作为迁移学习的基础模型"
  ],
  [
    "base_model",
    "组成部分",
    "MobileNetV2模型"
  ],
  [
    "base_model",
    "特点",
    "不包含顶层分类层"
  ],
  [
    "labels.txt",
    "用途",
    "保存训练数据的类别标签"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "执行步骤",
    "选择模型、转换模型、部署到设备、优化模型"
  ],
  [
    "选择模型",
    "用途",
    "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的 TensorFlow 预训练模型中选择一个模型直接使用或重新训练"
  ],
  [
    "转换模型",
    "用途",
    "使用 TensorFlow Lite 转换器将模型转换为 TensorFlow Lite 格式"
  ],
  [
    "部署到设备",
    "用途",
    "使用 TensorFlow Lite 解释器（提供多种语言的 API）在设备端运行模型"
  ],
  [
    "优化模型",
    "用途",
    "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "提供多种语言的 API"
  ],
  [
    "模型优化工具包",
    "用途",
    "缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响"
  ],
  [
    "TensorFlow Lite解释器",
    "用途",
    "执行模型推理过程"
  ],
  [
    "TensorFlow Lite解释器",
    "组成部分",
    "模型执行流图"
  ],
  [
    "ClassifierFloatMobileNet类",
    "包含",
    "model.tflite和label.txt文件"
  ],
  [
    "Classifier类",
    "包含",
    "TFLite解释器和GPU代理"
  ],
  [
    "GPU代理",
    "用途",
    "加速模型推理过程"
  ],
  [
    "TFLite解释器",
    "执行步骤",
    "创建实例并加载模型"
  ],
  [
    "TensorFlow Lite支持库",
    "用途",
    "简化图像预处理和输出处理"
  ],
  [
    "ImageProcessor",
    "用途",
    "对输入图像进行预处理"
  ],
  [
    "ImageProcessor",
    "执行步骤",
    "调整大小、裁剪、旋转和归一化图像"
  ],
  [
    "recognizeImage方法",
    "执行步骤",
    "运行TFLite推理并获取输出概率"
  ],
  [
    "TensorLabel",
    "用途",
    "将模型输出概率与类别标签关联"
  ],
  [
    "PoseNet模型",
    "用途",
    "实现人体姿势估计"
  ],
  [
    "PoseNet模型",
    "执行步骤",
    "检测关键身体部位的位置"
  ],
  [
    "PoseNet示例应用程序",
    "执行步骤",
    "获取图像数据、处理位图、调用姿势估计函数、绘制关键点"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=1, input_shape=[1])"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=16, activation='relu')"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=1)"
  ],
  [
    "model.compile",
    "用途",
    "配置模型的优化器和损失函数"
  ],
  [
    "model.compile",
    "特点",
    "使用优化器'sgd'和损失函数'mean_squared_error'"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件小、延迟低、支持设备端机器学习推断"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "TensorFlow Lite 解释器、TensorFlow Lite 转换器、算子库、硬件加速代理"
  ],
  [
    "TensorFlow Lite",
    "应用",
    "Google Assistant、Google Photos、Uber、Airbnb、网易、爱奇艺、WPS等"
  ],
  [
    "TensorFlow Lite",
    "支持平台",
    "Android、iOS、基于 Linux 的 IoT 设备和微控制器"
  ],
  [
    "TensorFlow Lite",
    "优点",
    "更轻量、特别为各种端侧设备优化的算子库、能够利用各种硬件加速"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "轻量级、快速启动、内存高效"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为 TensorFlow Lite 格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "优化工作",
    "算子优化和常见的编译优化、量化的原生支持"
  ],
  [
    "FlatBuffers",
    "用途",
    "TFLite 模型文件格式，更注重考虑实时性，内存高效"
  ],
  [
    "TensorFlow Lite 工作流程",
    "步骤",
    "选择模型、转换模型、部署到设备、优化模型"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "提供训练好的模型供开发人员复用"
  ],
  [
    "MobileNet",
    "用途",
    "图像识别模型"
  ],
  [
    "fine_tune_at",
    "是什么",
    "指定从哪个层开始进行微调的参数"
  ],
  [
    "fine_tune_at",
    "用途",
    "控制迁移学习中微调的起始层"
  ],
  [
    "fine_tune_at",
    "示例",
    "设置为100表示从第100层开始微调"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite 模型",
    "特点",
    "优化的 FlatBuffer 格式，以 .tflite 为文件扩展名"
  ],
  [
    "TensorFlow Lite 转换器",
    "组成部分",
    "命令行工具和 Python API"
  ],
  [
    "FlatBuffers",
    "用途",
    "主要应用于游戏场景，是为了高性能场景创建的序列化库"
  ],
  [
    "FlatBuffers",
    "优点",
    "相比 Protocol Buffer 有更高的性能和更小的大小"
  ],
  [
    "FlatBuffers",
    "用途",
    "更适合于边缘设备部署"
  ],
  [
    "tflite_convert",
    "是",
    "TensorFlow Lite 转换器命令行工具"
  ],
  [
    "tflite_convert",
    "包含",
    "--output_file, --saved_model_dir, --keras_model_file, --enable_v1_converter"
  ],
  [
    "--output_file",
    "用途",
    "指定输出文件的绝对路径"
  ],
  [
    "--saved_model_dir",
    "用途",
    "指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录"
  ],
  [
    "--keras_model_file",
    "用途",
    "指定含有 TensorFlow 1.x 或者 2.0 使用 tf.keras model 生成 HDF5 文件的绝对路径目录"
  ],
  [
    "TensorFlow 模型导出",
    "包含",
    "SavedModel 和 Keras Sequential"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是",
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API"
  ],
  [
    "tf.lite.TFLiteConverter",
    "包含",
    "from_saved_model(), from_keras_model(), from_concrete_functions()"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "用途",
    "用来转换 SavedModel 格式模型"
  ],
  [
    "TFLiteConverter.from_keras_model()",
    "用途",
    "用来转换 tf.keras 模型"
  ],
  [
    "TFLiteConverter.from_concrete_functions()",
    "用途",
    "用来转换 concrete functions"
  ],
  [
    "TensorFlow 2.x 模型",
    "特点",
    "使用 SavedModel 格式存储"
  ],
  [
    "tf.lite.TFLiteConverter",
    "用途",
    "将Keras模型转换为TensorFlow Lite模型"
  ],
  [
    "tf.lite.TFLiteConverter.from_keras_model",
    "步骤",
    "创建TFLiteConverter实例并加载Keras模型"
  ],
  [
    "converter.convert",
    "步骤",
    "执行模型转换过程生成TFLite模型"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在不同设备上使用硬件加速"
  ],
  [
    "TensorFlow Lite 解释器",
    "包含",
    "委托（Delegates）"
  ],
  [
    "GPU 委托",
    "用途",
    "允许解释器在设备的 GPU 上运行适当的运算符"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在 Android 与 iOS 平台上使用"
  ],
  [
    "Android 开发人员",
    "用途",
    "TensorFlow Lite AAR"
  ],
  [
    "iOS 开发人员",
    "用途",
    "CocoaPods for Swift or Objective-C"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一组帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型的工具"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "支持设备端机器学习推断"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "延迟较低"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件很小"
  ],
  [
    "TensorFlow",
    "是什么",
    "一个端到端的机器学习开源框架"
  ],
  [
    "TensorFlow",
    "特点",
    "支持大规模的模型训练"
  ],
  [
    "TensorFlow",
    "特点",
    "支持各种环境的部署"
  ],
  [
    "TensorFlow",
    "特点",
    "支持多种编程语言"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "移动端及IoT设备端的深度学习技术"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "轻量化"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "快速"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "兼容度高"
  ],
  [
    "TensorFlow Lite",
    "结果",
    "大大降低移动端及IoT设备端的深度学习技术门槛"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是什么",
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "用途",
    "转换 SavedModel 格式模型"
  ],
  [
    "TFLiteConverter.from_keras_model()",
    "用途",
    "转换 tf.keras 模型"
  ],
  [
    "TFLiteConverter.from_concrete_functions()",
    "用途",
    "转换 concrete functions"
  ],
  [
    "TensorFlow 2.x 模型",
    "存储格式",
    "SavedModel 格式"
  ],
  [
    "TensorFlow 2.x 模型",
    "生成方式",
    "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）"
  ],
  [
    "tf.keras.models.Sequential",
    "示例",
    "创建包含多个 Dense 层的模型"
  ],
  [
    "tf.keras.layers.Dense",
    "用途",
    "构建神经网络的全连接层"
  ],
  [
    "model.compile",
    "用途",
    "编译模型，设置优化器和损失函数"
  ],
  [
    "model.fit",
    "用途",
    "训练模型"
  ],
  [
    "tf.saved_model.save",
    "用途",
    "将 Keras 模型保存为 SavedModel 格式"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "155层网络"
  ],
  [
    "微调过程",
    "步骤",
    "冻结前100层"
  ],
  [
    "微调过程",
    "步骤",
    "使用低学习率编译模型"
  ],
  [
    "微调过程",
    "步骤",
    "恢复训练"
  ],
  [
    "模型编译",
    "用途",
    "优化损失函数和准确率"
  ],
  [
    "模型训练",
    "结果",
    "精度达到98%"
  ],
  [
    "模型训练",
    "缺点",
    "可能存在过度拟合"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "移动端模型部署"
  ],
  [
    "SavedModel",
    "特点",
    "包含完整的TensorFlow程序"
  ],
  [
    "TFLiteConverter",
    "用途",
    "将SavedModel转换为TFLite格式"
  ],
  [
    "Android部署",
    "步骤",
    "拷贝模型和标签文件到assets目录"
  ],
  [
    "Android部署",
    "步骤",
    "配置build.gradle文件"
  ],
  [
    "Android部署",
    "步骤",
    "初始化TensorFlow Lite解释器"
  ],
  [
    "Interpreter",
    "用途",
    "执行TFLite模型推理"
  ],
  [
    "GpuDelegate",
    "用途",
    "加速GPU上的模型推理"
  ],
  [
    "ImageProcessor",
    "用途",
    "预处理输入图像"
  ],
  [
    "TensorLabel",
    "用途",
    "关联概率与类别标签"
  ],
  [
    "PoseNet",
    "用途",
    "实现人体姿势估计"
  ],
  [
    "PoseNet",
    "特点",
    "检测关键身体部位位置"
  ],
  [
    "TensorFlow Lite 转换器",
    "间接包含",
    "from_saved_model(), from_keras_model(), from_concrete_functions()"
  ],
  [
    "TFLite 模型文件",
    "间接包含",
    "一系列的计算节点"
  ],
  [
    "TFLite 模型文件",
    "间接包含",
    "多个张量"
  ],
  [
    "TFLite 模型文件",
    "间接包含",
    "子图本身的输入和输出"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "GPU 委托"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "委托（Delegates）"
  ],
  [
    "tf.keras.Sequential",
    "间接包含",
    "MobileNetV2模型"
  ],
  [
    "TensorFlow",
    "间接包含",
    "转换和运行 TensorFlow 模型的工具"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Post training quantization 和 Quantization-aware training"
  ],
  [
    "TensorFlow",
    "间接包含",
    "特别为各种端侧设备优化的算子库"
  ],
  [
    "TensorFlow",
    "间接包含",
    "多种级别的量化支持"
  ],
  [
    "TensorFlow",
    "间接包含",
    "模型文件和标签文件"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "算子库(Op kernels)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 解释器、TensorFlow Lite 转换器、算子库、硬件加速代理"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "在移动端、嵌入式和物联网设备上运行 TensorFlow 模型"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "优化模型大小和性能"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "端侧机器学习"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "移动应用中的OCR处理"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "视频中的AR效果"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "文字处理"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "图像和视频处理"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "离线语音识别"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "IoT领域"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "工业物联智能设备开发"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "在边缘设备上运行 TensorFlow 模型推理"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "利用手机上的加速器，比如 GPU 或者 DSP"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "利用 Android 神经网络 API（Android NN API)"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "支持设备端机器学习推断"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "移动端及IoT设备端的深度学习技术"
  ],
  [
    "tf.lite.TFLiteConverter",
    "可能用途",
    "移动端模型部署"
  ],
  [
    "TensorFlow Lite 解释器",
    "可能与...相关",
    "TensorFlow Lite 解释器"
  ],
  [
    "GPU 委托",
    "可能与...相关",
    "GPU 委托"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "TensorFlow Lite"
  ],
  [
    "量化",
    "可能与...相关",
    "量化"
  ],
  [
    "flow_from_directory",
    "可能与...相关",
    "flow_from_directory"
  ],
  [
    "MobileNet V2",
    "可能与...相关",
    "MobileNet V2"
  ],
  [
    "include_top=False",
    "可能与...相关",
    "include_top=False"
  ],
  [
    "迁移学习",
    "可能与...相关",
    "迁移学习"
  ],
  [
    "瓶颈层",
    "可能与...相关",
    "瓶颈层"
  ],
  [
    "GlobalAveragePooling2D",
    "可能与...相关",
    "GlobalAveragePooling2D"
  ],
  [
    "TensorFlow Lite 转换器",
    "可能与...相关",
    "TensorFlow Lite 转换器"
  ],
  [
    "FlatBuffers",
    "可能与...相关",
    "FlatBuffers"
  ],
  [
    "微调",
    "可能与...相关",
    "微调"
  ],
  [
    "SavedModel",
    "可能与...相关",
    "SavedModel"
  ],
  [
    "PoseNet模型",
    "可能与...相关",
    "PoseNet"
  ]
]