[
  [
    "TensorFlow Lite",
    "是什么",
    "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "支持设备端机器学习推断"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "延迟较低"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件很小"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "155层网络"
  ],
  [
    "微调",
    "步骤",
    "取消冻结模型的顶层"
  ],
  [
    "微调",
    "步骤",
    "设置前100层为不可训练"
  ],
  [
    "微调",
    "步骤",
    "使用低学习率重新编译模型"
  ],
  [
    "微调",
    "用途",
    "提高模型准确率"
  ],
  [
    "微调",
    "结果",
    "模型精度达到98%"
  ],
  [
    "微调",
    "缺点",
    "可能导致模型过拟合"
  ],
  [
    "TFLite",
    "用途",
    "将TensorFlow模型转换为移动设备兼容格式"
  ],
  [
    "SavedModel",
    "特点",
    "包含完整的TensorFlow程序（权重和计算）"
  ],
  [
    "SavedModel",
    "优点",
    "不需要原始模型构建代码就可以运行"
  ],
  [
    "MobileNet V2",
    "用途",
    "创建、训练和导出自定义 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "模型文件和标签文件"
  ],
  [
    "Android 应用",
    "用途",
    "识别花卉图片"
  ],
  [
    "TensorFlow Lite 示例",
    "来源",
    "TensorFlow 官网"
  ],
  [
    "TensorFlow Lite 示例",
    "获取方式",
    "从 github 下载源码"
  ],
  [
    "flower_classification 项目",
    "组成部分",
    "start 目录和 finish 目录"
  ],
  [
    "start 目录",
    "特点",
    "项目模板"
  ],
  [
    "finish 目录",
    "特点",
    "项目完整代码"
  ],
  [
    "Android 部署",
    "条件",
    "安装 Android Studio"
  ],
  [
    "Android Studio",
    "用途",
    "打开现有 Android Studio 项目"
  ],
  [
    "Android Studio",
    "组成部分",
    "启动图标"
  ],
  [
    "Android Studio",
    "组成部分",
    "打开项目图标"
  ],
  [
    "TensorFlow Lite 模型文件",
    "用途",
    "用于 flower_classification 项目"
  ],
  [
    "build.gradle",
    "用途",
    "配置项目依赖"
  ],
  [
    "build.gradle",
    "组成部分",
    "dependencies"
  ],
  [
    "dependencies",
    "包含",
    "org.tensorflow:tensorflow-lite:+"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow 模型",
    "是什么",
    "一种数据结构，包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "转换、运行 TensorFlow 模型所需的所有工具"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "存放训练好的模型供开发人员复用"
  ],
  [
    "TensorFlow Hub",
    "特点",
    "提供已经训练好且经过充分认证的模型"
  ],
  [
    "预训练模型",
    "用途",
    "可以直接部署或用于迁移学习"
  ],
  [
    "MobileNet",
    "示例",
    "TensorFlow Hub 上可搜索到的模型之一"
  ],
  [
    "hub.KerasLayer",
    "用途",
    "用于加载 TensorFlow Hub 上的模型"
  ],
  [
    "MobileNet V2",
    "用途",
    "将图片分类到1000类"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "最后的神经网络层"
  ],
  [
    "MobileNet V2",
    "特点",
    "默认分类到1000类"
  ],
  [
    "include_top=False",
    "用途",
    "不需要原有模型中最后的神经网络层"
  ],
  [
    "迁移学习",
    "特点",
    "不改变基础模型的各项参数变量"
  ],
  [
    "迁移学习",
    "用途",
    "保留原来大规模训练的优势"
  ],
  [
    "model.trainable = False",
    "用途",
    "基础模型的各项参数变量不会被新的训练修改数据"
  ],
  [
    "瓶颈层",
    "特点",
    "保持了很多通用性"
  ],
  [
    "瓶颈层",
    "用途",
    "在展平操作之前依赖于最后一层"
  ],
  [
    "池化层",
    "用途",
    "对数据降维"
  ],
  [
    "输出层",
    "组成部分",
    "5个节点"
  ],
  [
    "GlobalAveragePooling2D",
    "用途",
    "将特征转换为每个图像对应一个1280元素向量"
  ],
  [
    "tf.keras.Sequential",
    "组成部分",
    "base_model, Conv2D, Dropout, GlobalAveragePooling2D, Dense"
  ],
  [
    "Conv2D",
    "特点",
    "32个过滤器，3x3大小，激活函数为relu"
  ],
  [
    "Dropout",
    "特点",
    "0.2的丢弃率"
  ],
  [
    "Dense",
    "特点",
    "5个节点，激活函数为softmax"
  ],
  [
    "模型编译",
    "组成部分",
    "optimizer, loss, metrics"
  ],
  [
    "optimizer",
    "示例",
    "tf.keras.optimizers.Adam()"
  ],
  [
    "loss",
    "示例",
    "categorical_crossentropy"
  ],
  [
    "metrics",
    "示例",
    "accuracy"
  ],
  [
    "TFLite 模型转换过程",
    "步骤",
    "用户在自己的工作台中使用 TensorFlow API 构造 TensorFlow 模型"
  ],
  [
    "TFLite 模型转换过程",
    "步骤",
    "使用 TFLite 模型转换器转换成 TFLite 文件格式(FlatBuffers 格式)"
  ],
  [
    "TFLite 解释器",
    "用途",
    "接受 TFLite 模型"
  ],
  [
    "TFLite 解释器",
    "用途",
    "调用不同的硬件加速器比如 GPU 进行执行"
  ],
  [
    "TFLite 文件格式",
    "是",
    "FlatBuffers 格式"
  ],
  [
    "mobilenetv2_1.00_224",
    "组成部分",
    "conv2d, dropout, global_average_pooling2d, dense"
  ],
  [
    "mobilenetv2_1.00_224",
    "特点",
    "Total params: 2,626,821, Trainable params: 368,837, Non-trainable params: 2,257,984"
  ],
  [
    "model.fit",
    "执行步骤",
    "train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=val_generator, validation_steps=len(val_generator)"
  ],
  [
    "微调",
    "条件",
    "设置 model.trainable = False"
  ],
  [
    "微调",
    "用途",
    "提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练"
  ],
  [
    "微调",
    "特点",
    "训练期间将不更新预训练网络的权重，只在 MobileNet V2基础模型上训练了几层"
  ],
  [
    "微调",
    "条件",
    "在训练顶层分类器并将预先训练的模型设置为不可训练之后"
  ],
  [
    "微调",
    "结果",
    "如果联合训练所有层，则梯度更新的幅度将太大，并且预训练模型将忘记它学到的东西"
  ],
  [
    "微调",
    "执行步骤",
    "微调少量顶层而不是整个 MobileNet 模型"
  ],
  [
    "微调",
    "特点",
    "前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像"
  ],
  [
    "微调",
    "特点",
    "随着层越来越高，这些功能越来越多地针对训练模型的数据集"
  ],
  [
    "微调",
    "用途",
    "使这些专用功能适应新数据集，而不是覆盖通用学习"
  ],
  [
    "微调",
    "执行步骤",
    "取消冻结模型的顶层"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "执行步骤",
    "选择模型、转换模型、部署到设备和优化模型"
  ],
  [
    "选择模型",
    "用途",
    "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的 TensorFlow 预训练模型中选择一个模型直接使用或重新训练"
  ],
  [
    "转换模型",
    "用途",
    "使用 TensorFlow Lite 转换器将模型转换为 TensorFlow Lite 格式"
  ],
  [
    "部署到设备",
    "用途",
    "使用 TensorFlow Lite 解释器（提供多种语言的 API）在设备端运行模型"
  ],
  [
    "优化模型",
    "用途",
    "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将自定义模型转换为 TensorFlow Lite 格式"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在设备端运行模型"
  ],
  [
    "模型优化工具包",
    "用途",
    "缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响"
  ],
  [
    "TensorFlow Lite解释器",
    "用途",
    "执行模型推理过程"
  ],
  [
    "TensorFlow Lite解释器",
    "组成部分",
    "模型执行流图"
  ],
  [
    "ClassifierFloatMobileNet类",
    "包含",
    "model.tflite和label.txt"
  ],
  [
    "Classifier类",
    "包含",
    "TFLite解释器tflite和GPU代理gpuDelegate"
  ],
  [
    "GPU代理",
    "用途",
    "加速模型推理过程"
  ],
  [
    "TensorFlow Lite支持库",
    "用途",
    "简化图像预处理和模型输出处理"
  ],
  [
    "图像预处理",
    "执行步骤",
    "数据转换、执行推理、解释输出"
  ],
  [
    "ImageProcessor",
    "用途",
    "构建图像处理流程"
  ],
  [
    "ResizeWithCropOrPadOp",
    "用途",
    "调整图像大小"
  ],
  [
    "ResizeOp",
    "用途",
    "缩放图像"
  ],
  [
    "Rot90Op",
    "用途",
    "旋转图像"
  ],
  [
    "TensorLabel",
    "用途",
    "关联概率与类别标签"
  ],
  [
    "PoseNet模型",
    "用途",
    "实现人体姿势估计"
  ],
  [
    "PoseNet模型",
    "特点",
    "检测关键身体部位的位置"
  ],
  [
    "PoseNet示例应用程序",
    "执行步骤",
    "获取图像数据、创建位图、调用estimateSinglePose()、绘制骨架"
  ],
  [
    "aaptOptions",
    "用途",
    "防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件"
  ],
  [
    "aaptOptions",
    "组成部分",
    "noCompress \"tflite\""
  ],
  [
    "Android环境部署",
    "步骤",
    "运行Sync Gradle"
  ],
  [
    "Android Studio",
    "条件",
    "配置proxy或使用国内镜像"
  ],
  [
    "build.gradle",
    "修改",
    "将maven源google()和jcenter()替换为国内镜像"
  ],
  [
    "buildscript",
    "组成部分",
    "repositories和dependencies"
  ],
  [
    "TensorFlow",
    "是什么",
    "一个端到端的机器学习开源框架"
  ],
  [
    "TensorFlow",
    "特点",
    "支持大规模的模型训练"
  ],
  [
    "TensorFlow",
    "特点",
    "支持各种环境的部署"
  ],
  [
    "TensorFlow",
    "特点",
    "支持多种编程语言"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "移动端及IoT设备端的深度学习技术"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "轻量化"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "快速"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "兼容度高"
  ],
  [
    "TensorFlow",
    "包含",
    "TensorFlow Lite"
  ],
  [
    "tf.keras model",
    "用途",
    "生成 HDF5 文件的绝对路径目录"
  ],
  [
    "TensorFlow 模型导出",
    "支持",
    "SavedModel 和 Keras Sequential 两种模型导出方法和格式"
  ],
  [
    "SavedModel",
    "示例",
    "tflite_convert --saved_model_dir=/tmp/mobilenet_saved_model --output_file=/tmp/mobilenet.tflite"
  ],
  [
    "Keras H5",
    "示例",
    "tflite_convert --keras_model_file=/tmp/mobilenet_keras_model.h5 --output_file=/tmp/mobilenet.tflite"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite 模型",
    "特点",
    "优化的 FlatBuffer 格式"
  ],
  [
    "TensorFlow Lite 模型",
    "文件扩展名",
    ".tflite"
  ],
  [
    "TensorFlow Lite 转换器",
    "使用方式",
    "命令行与 Python API"
  ],
  [
    "Google",
    "推荐",
    "使用 Python API 进行转换"
  ],
  [
    "命令行工具",
    "特点",
    "只提供了基本的转化功能"
  ],
  [
    "转换后的原模型",
    "格式",
    "FlatBuffers 格式"
  ],
  [
    "FlatBuffers",
    "用途",
    "主要应用于游戏场景"
  ],
  [
    "FlatBuffers",
    "特点",
    "为了高性能场景创建的序列化库"
  ],
  [
    "FlatBuffers",
    "优点",
    "相比 Protocol Buffer 有更高的性能和更小的大小"
  ],
  [
    "FlatBuffers",
    "用途",
    "更适合于边缘设备部署"
  ],
  [
    "tflite_convert",
    "属于",
    "命令行 TensorFlow Lite 转换器命令行工具"
  ],
  [
    "tflite_convert",
    "安装方式",
    "与 TensorFlow 一起安装"
  ],
  [
    "tflite_convert",
    "参数",
    "--output_file"
  ],
  [
    "--output_file",
    "类型",
    "string"
  ],
  [
    "--output_file",
    "描述",
    "Full path of the output file"
  ],
  [
    "tflite_convert",
    "参数",
    "--saved_model_dir"
  ],
  [
    "--saved_model_dir",
    "类型",
    "string"
  ],
  [
    "--saved_model_dir",
    "描述",
    "Full path to the SavedModel directory"
  ],
  [
    "tflite_convert",
    "参数",
    "--keras_model_file"
  ],
  [
    "--keras_model_file",
    "类型",
    "string"
  ],
  [
    "--keras_model_file",
    "描述",
    "Full path to the Keras H5 model file"
  ],
  [
    "tflite_convert",
    "参数",
    "--enable_v1_converter"
  ],
  [
    "--enable_v1_converter",
    "类型",
    "bool"
  ],
  [
    "--enable_v1_converter",
    "默认值",
    "False"
  ],
  [
    "--enable_v1_converter",
    "描述",
    "Enables the converter and flags used in TF 1.x instead of TF 2.x"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "用途",
    "将SavedModel转换为TFLite模型"
  ],
  [
    "tf.lite.TFLiteConverter",
    "包含",
    "from_saved_model方法"
  ],
  [
    "saved_model_dir",
    "是",
    "SavedModel的目录路径"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "算子库(Op kernels)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "采用更小的模型格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为方便解释器使用的格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "引入优化以减小二进制文件的大小和提高性能"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "安卓应用只需 1 兆左右的运行环境"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "目前有130个左右"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "做了移动设备相关的优化"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "利用手机上的加速器，比如 GPU 或者 DSP"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "利用 Android 神经网络 API（Android NN API)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "Python API"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是什么",
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "用途",
    "转换 SavedModel 格式模型"
  ],
  [
    "TFLiteConverter.from_keras_model()",
    "用途",
    "转换 tf.keras 模型"
  ],
  [
    "TFLiteConverter.from_concrete_functions()",
    "用途",
    "转换 concrete functions"
  ],
  [
    "TensorFlow 2.x 模型",
    "特点",
    "使用 SavedModel 格式存储"
  ],
  [
    "TensorFlow 2.x 模型",
    "生成方式",
    "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）"
  ],
  [
    "SavedModel",
    "示例",
    "转换为 TensorFlow Lite 模型的代码示例"
  ],
  [
    "Keras 模型",
    "示例",
    "转换为 TensorFlow Lite 模型的代码示例"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "155层"
  ],
  [
    "微调过程",
    "步骤",
    "冻结前100层"
  ],
  [
    "微调过程",
    "步骤",
    "使用低学习率编译模型"
  ],
  [
    "微调过程",
    "步骤",
    "恢复训练"
  ],
  [
    "模型编译",
    "用途",
    "优化模型性能"
  ],
  [
    "模型编译",
    "组成部分",
    "损失函数categorical_crossentropy"
  ],
  [
    "模型编译",
    "组成部分",
    "优化器Adam"
  ],
  [
    "模型编译",
    "组成部分",
    "评估指标accuracy"
  ],
  [
    "微调结果",
    "特点",
    "精度达到98%"
  ],
  [
    "微调结果",
    "缺点",
    "验证损失高于训练损失"
  ],
  [
    "微调结果",
    "缺点",
    "可能存在过度拟合"
  ],
  [
    "TFLite",
    "用途",
    "模型部署"
  ],
  [
    "TFLite",
    "特点",
    "不需要原始模型构建代码"
  ],
  [
    "SavedModel",
    "组成部分",
    "权重值"
  ],
  [
    "SavedModel",
    "组成部分",
    "计算图"
  ],
  [
    "Android部署",
    "步骤",
    "下载源码"
  ],
  [
    "Android部署",
    "步骤",
    "安装Android Studio"
  ],
  [
    "Android部署",
    "步骤",
    "配置build.gradle"
  ],
  [
    "Android部署",
    "步骤",
    "初始化TensorFlow Lite解释器"
  ],
  [
    "Android部署",
    "步骤",
    "执行推理"
  ],
  [
    "Android部署",
    "步骤",
    "试运行应用"
  ],
  [
    "TensorFlow Lite解释器",
    "用途",
    "执行模型推理"
  ],
  [
    "TensorFlow Lite解释器",
    "组成部分",
    "GPU代理"
  ],
  [
    "TensorFlow Lite解释器",
    "组成部分",
    "TFLite interpreter"
  ],
  [
    "推理过程",
    "步骤",
    "数据转换"
  ],
  [
    "推理过程",
    "步骤",
    "执行推理"
  ],
  [
    "推理过程",
    "步骤",
    "解释输出"
  ],
  [
    "PoseNet",
    "用途",
    "人体姿势估计"
  ],
  [
    "PoseNet",
    "特点",
    "检测关键身体部位的位置"
  ],
  [
    "PoseNet示例应用",
    "步骤",
    "获取图像数据并转换格式"
  ],
  [
    "PoseNet示例应用",
    "步骤",
    "创建位图对象"
  ],
  [
    "PoseNet示例应用",
    "步骤",
    "调用estimateSinglePose()函数"
  ],
  [
    "PoseNet示例应用",
    "步骤",
    "绘制骨架"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "执行模型文件在输入数据上定义的运算符，输出推理结果"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "适用于多个平台"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "提供了一个简单的 API，用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型"
  ],
  [
    "Java",
    "示例",
    "调用解释器的方式：try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) { interpreter.run(input, output); }"
  ],
  [
    "GPU",
    "优点",
    "比 CPU 执行更快的浮点矩阵运算"
  ],
  [
    "GPU",
    "示例",
    "在有 GPU 加速的手机上运行 MobileNet 图像分类，模型运行速度可以提高"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件很小，支持设备端机器学习推断，延迟较低"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "TensorFlow Lite 解释器(Interpreter)、TensorFlow Lite 转换器(Converter)、算子库(Op kernels)、硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow Lite",
    "应用",
    "Google Assistant、Google Photos、Uber、Airbnb、网易、爱奇艺、WPS等公司的应用"
  ],
  [
    "TensorFlow Lite",
    "应用",
    "图像、文本和语音处理"
  ],
  [
    "TensorFlow Lite",
    "应用",
    "工业物联智能设备的开发"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "支持微控制器(MCU)，可以应用于 IoT 领域"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "模型大小只有20 KB 左右"
  ],
  [
    "TensorFlow Lite",
    "工作原理",
    "采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "轻量级、快速启动、内存高效"
  ],
  [
    "TensorFlow Lite 解释器",
    "工作原理",
    "将模型直接映射到内存中，同时有一个静态执行计划"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为 TensorFlow Lite 专用的模型文件格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "支持算子优化和常见的编译优化，比如算子融合、常数折叠或无用代码删除等"
  ],
  [
    "FlatBuffers 格式",
    "特点",
    "内存高效，支持将文件映射到内存中，然后直接进行读取和解释"
  ],
  [
    "TensorFlow Lite 工作流程",
    "执行步骤",
    "选择模型、转换模型、部署到设备、优化模型"
  ],
  [
    "MobileNet",
    "用途",
    "图像识别项目"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "提供预训练模型，开发人员可以复用这些已经训练好且经过充分认证的模型"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "执行模型文件在输入数据上定义的运算符，输出推理结果"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "适用于多个平台，提供了一个简单的 API"
  ],
  [
    "TensorFlow Lite 解释器",
    "组成部分",
    "GPU 委托"
  ],
  [
    "GPU 委托",
    "用途",
    "允许解释器在设备的 GPU 上运行适当的运算符"
  ],
  [
    "GPU",
    "优点",
    "比 CPU 执行更快的浮点矩阵运算"
  ],
  [
    "MobileNet 图像分类",
    "示例",
    "在有 GPU 加速的手机上运行，模型运行速度可以提高 5.5 倍"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在 Android 与 iOS 平台上使用"
  ],
  [
    "TensorFlow Lite AAR",
    "用途",
    "Android 开发人员使用"
  ],
  [
    "CocoaPods",
    "用途",
    "iOS 开发人员使用"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "优化模型大小和性能"
  ],
  [
    "量化",
    "用途",
    "降低权重的精确表示，并且可选的降低存储和计算的激活值"
  ],
  [
    "量化",
    "优点",
    "对现有 CPU 平台的支持"
  ],
  [
    "量化",
    "优点",
    "降低存储器访问成本"
  ],
  [
    "量化",
    "优点",
    "对 SIMD 指令功能特别有益"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "Post training quantization"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "Quantization-aware training"
  ],
  [
    "MobileNet V2",
    "用途",
    "进行迁移学习，实现识别花卉模型"
  ],
  [
    "MobileNet V2",
    "特点",
    "使用深度可分离的卷积来构建轻量级的深层神经网络"
  ],
  [
    "MobileNet V2",
    "用途",
    "图像分类任务"
  ],
  [
    "迁移学习",
    "步骤",
    "实例化预先训练的模型，并在顶部添加全连接的分类器"
  ],
  [
    "迁移学习",
    "步骤",
    "冻结预训练的模型，仅在训练期间更新分类器的权重"
  ],
  [
    "微调",
    "用途",
    "调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征"
  ],
  [
    "ImageDataGenerator",
    "用途",
    "生成一个批次一个批次的图片，以生成器的形式给模型训练"
  ],
  [
    "flow_from_directory",
    "用途",
    "逐步加载单个数据集的图像"
  ],
  [
    "Keras模型",
    "转换为",
    "TensorFlow Lite模型"
  ],
  [
    "TensorFlow Lite模型",
    "保存为",
    "model.tflite文件"
  ],
  [
    "TensorFlow",
    "用于",
    "转换Keras模型到TensorFlow Lite模型"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在不同设备上使用硬件加速"
  ],
  [
    "TensorFlow Lite 解释器",
    "包含",
    "GPU 委托"
  ],
  [
    "GPU 委托",
    "用途",
    "允许解释器在设备的 GPU 上运行适当的运算符"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在 Android 与 iOS 平台上使用"
  ],
  [
    "Android 开发人员",
    "用途",
    "使用 TensorFlow Lite AAR"
  ],
  [
    "iOS 开发人员",
    "用途",
    "使用 CocoaPods for Swift or Objective-C"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上"
  ],
  [
    "fine_tune_at",
    "是什么",
    "指定从哪个层开始进行微调的参数"
  ],
  [
    "fine_tune_at",
    "示例",
    "100"
  ],
  [
    "fine_tune",
    "用途",
    "从指定层开始进行模型微调"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "轻量级"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "快速启动"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "内存高效"
  ],
  [
    "TFLite 解释执行器",
    "组成部分",
    "核心运行时"
  ],
  [
    "TFLite 解释执行器",
    "组成部分",
    "标准算子"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "加载模型"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "转换数据"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "运行模型推理"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "解释输出"
  ],
  [
    "TFLite",
    "用途",
    "执行模型推理"
  ],
  [
    "TFLite",
    "支持语言",
    "Java"
  ],
  [
    "TFLite",
    "支持语言",
    "C++"
  ],
  [
    "TFLite",
    "支持语言",
    "Python"
  ],
  [
    "TFLite",
    "支持语言",
    "C"
  ],
  [
    "TFLite",
    "支持语言",
    "Object C"
  ],
  [
    "TFLite",
    "支持语言",
    "C#"
  ],
  [
    "TFLite",
    "支持语言",
    "Swift"
  ],
  [
    "TFLite",
    "部署方式",
    "从头自己编译"
  ],
  [
    "TFLite",
    "部署方式",
    "使用已编译好的库"
  ],
  [
    "TFLite",
    "部署方式",
    "Android 开发者使用 JCenter Bintray 的 TFLite AAR"
  ],
  [
    "TFLite",
    "部署方式",
    "iOS 开发者通过 CocoaPods 获取"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense"
  ],
  [
    "tf.keras.layers.Dense",
    "特点",
    "units=1, input_shape=[1]"
  ],
  [
    "tf.keras.layers.Dense",
    "特点",
    "units=16, activation='relu'"
  ],
  [
    "tf.keras.layers.Dense",
    "特点",
    "units=1"
  ],
  [
    "model.compile",
    "用途",
    "optimizer='sgd', loss='mean_squared_error'"
  ],
  [
    "TFLite 模型文件格式",
    "是",
    "FlatBuffers"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "注重实时性，内存高效"
  ],
  [
    "TFLite 模型文件格式",
    "用途",
    "在内存有限的移动环境中使用"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "支持将文件映射到内存中直接读取和解释，不需要额外解析"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "减少内存碎片化"
  ],
  [
    "TFLite 模型文件",
    "组成部分",
    "子图、算子库和共享的内存缓冲区"
  ],
  [
    "TFLite 模型文件",
    "定义",
    "由 schema.fbs 文件使用 FlatBuffers 定义"
  ],
  [
    "张量",
    "用途",
    "存储模型权重或计算节点的输入和输出"
  ],
  [
    "张量",
    "特点",
    "引用 Model 的内存缓冲区的一片区域，提高内存效率"
  ],
  [
    "算子实现",
    "组成部分",
    "OperatorCode"
  ],
  [
    "OperatorCode",
    "特点",
    "可以是内置的算子或自定制算子，有一个名字"
  ],
  [
    "模型的计算节点",
    "组成部分",
    "用到的算子索引和输入输出用到的 Tensor 索引"
  ],
  [
    "子图",
    "组成部分",
    "一系列的计算节点、多个张量，以及子图本身的输入和输出"
  ],
  [
    "tf.saved_model.save",
    "用途",
    "生成SavedModel"
  ],
  [
    "tf.saved_model.save",
    "参数",
    "model"
  ],
  [
    "tf.saved_model.save",
    "参数",
    "\"saved_model_keras_dir\""
  ],
  [
    "SavedModel",
    "生成方式",
    "使用tf.saved_model.save函数"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite 模型",
    "特点",
    "优化的 FlatBuffer 格式，以 .tflite 为文件扩展名"
  ],
  [
    "TensorFlow Lite 转换器",
    "组成部分",
    "命令行工具和 Python API"
  ],
  [
    "FlatBuffers",
    "用途",
    "主要应用于游戏场景，是为了高性能场景创建的序列化库"
  ],
  [
    "FlatBuffers",
    "优点",
    "相比 Protocol Buffer 有更高的性能和更小的大小"
  ],
  [
    "FlatBuffers",
    "用途",
    "更适合于边缘设备部署"
  ],
  [
    "tflite_convert",
    "是",
    "TensorFlow Lite 转换器命令行工具"
  ],
  [
    "tflite_convert",
    "参数",
    "--output_file, --saved_model_dir, --keras_model_file, --enable_v1_converter"
  ],
  [
    "TensorFlow 模型导出",
    "支持格式",
    "SavedModel 和 Keras Sequential"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是",
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API"
  ],
  [
    "tf.lite.TFLiteConverter",
    "类方法",
    "from_saved_model(), from_keras_model(), from_concrete_functions()"
  ],
  [
    "TensorFlow 2.x 模型",
    "存储格式",
    "SavedModel 格式"
  ],
  [
    "TensorFlow 2.x 模型",
    "生成方式",
    "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "优化模型大小和性能"
  ],
  [
    "模型优化",
    "目标",
    "在给定设备上实现性能、模型大小和准确性的理想平衡"
  ],
  [
    "大而复杂的模型",
    "用途",
    "需要高准确率的任务"
  ],
  [
    "小一点的模型",
    "用途",
    "精确度不高的任务"
  ],
  [
    "小一点的模型",
    "优点",
    "占用更少的磁盘和内存，更快更高效"
  ],
  [
    "量化",
    "用途",
    "降低权重的精确表示，降低存储和计算的激活值"
  ],
  [
    "量化",
    "优点",
    "对现有 CPU 平台的支持"
  ],
  [
    "量化",
    "优点",
    "降低用于读取和存储中间激活值的存储器访问成本"
  ],
  [
    "量化",
    "优点",
    "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，对量化特别有益"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "多种级别的量化支持"
  ],
  [
    "Tensorflow Lite post-training quantization",
    "用途",
    "使权重和激活值的 Post training 更简单"
  ],
  [
    "Quantization-aware training",
    "用途",
    "以最小精度下降来训练网络"
  ],
  [
    "Quantization-aware training",
    "条件",
    "仅适用于卷积神经网络的一个子集"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "实现花卉识别 app"
  ],
  [
    "花卉识别 app",
    "运行平台",
    "Android 设备"
  ],
  [
    "花卉识别 app",
    "使用模型",
    "MobileNets_v2"
  ],
  [
    "花卉识别 app",
    "功能",
    "实时识别照相机所拍摄的花卉"
  ],
  [
    "花卉识别模型",
    "实现方法",
    "迁移学习"
  ],
  [
    "花卉识别模型",
    "转换工具",
    "TFLite 转换器"
  ],
  [
    "Android 应用",
    "使用组件",
    "TFLite 解释器"
  ],
  [
    "TensorFlow Lite 支持库",
    "用途",
    "预处理模型输入和后处理模型输出"
  ],
  [
    "MobileNet V2",
    "是",
    "基于流线型架构的轻量级深层神经网络"
  ],
  [
    "MobileNet V2",
    "用途",
    "图像分类任务"
  ],
  [
    "MobileNet V2",
    "特点",
    "使用深度可分离的卷积"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "预训练模型和全连接的分类器"
  ],
  [
    "迁移学习",
    "用途",
    "在小型数据集上训练模型"
  ],
  [
    "迁移学习",
    "执行步骤",
    "冻结预训练模型并更新分类器权重"
  ],
  [
    "微调",
    "用途",
    "提高模型性能"
  ],
  [
    "微调",
    "执行步骤",
    "调整预训练模型的顶层权重"
  ],
  [
    "ImageDataGenerator",
    "用途",
    "生成批次的图片数据用于模型训练"
  ],
  [
    "ImageDataGenerator",
    "特点",
    "支持像素缩放和数据增强"
  ],
  [
    "flow_from_directory",
    "用途",
    "逐步加载单个数据集的图像"
  ],
  [
    "flow_from_directory",
    "参数",
    "target_size用于设置图像大小"
  ],
  [
    "flow_from_directory",
    "参数",
    "batch_size用于设置每批图像数量"
  ],
  [
    "tf.lite.TFLiteConverter",
    "用途",
    "将Keras模型转换为TFLite模型"
  ],
  [
    "tf.lite.TFLiteConverter.from_keras_model",
    "步骤",
    "创建TFLite转换器实例"
  ],
  [
    "converter.convert",
    "步骤",
    "执行模型转换过程"
  ],
  [
    "tflite_model",
    "结果",
    "转换后得到的TFLite格式模型"
  ],
  [
    "train_generator",
    "用途",
    "从指定目录加载训练图像数据"
  ],
  [
    "train_generator",
    "特点",
    "支持批量加载图像数据"
  ],
  [
    "val_generator",
    "用途",
    "从指定目录加载验证图像数据"
  ],
  [
    "val_generator",
    "特点",
    "支持批量加载图像数据"
  ],
  [
    "MobileNetV2",
    "是什么",
    "预加载了ImageNet训练权重的深度学习模型"
  ],
  [
    "MobileNetV2",
    "用途",
    "作为迁移学习的基础模型"
  ],
  [
    "MobileNetV2",
    "组成部分",
    "不包括顶层分类层"
  ],
  [
    "labels.txt",
    "用途",
    "保存训练数据的类别标签"
  ],
  [
    "TensorFlow Lite",
    "是",
    "在边缘设备上运行 TensorFlow 模型推理的官方框架"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "跨平台运行，包括 Android、iOS 以及基于 Linux 的 IoT 设备和微控制器"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在边缘设备上运行 TensorFlow 模型推理"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "优化的算子库"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "能够利用各种硬件加速"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "轻量，二进制文件的大小约为 1 MB（针对 32 位 ARM build）"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，二进制文件的大小不到 300 KB"
  ],
  [
    "TF Mobile",
    "是",
    "Google 尝试简化 TensorFlow 并在移动设备上运行的缩减版 TensorFlow"
  ],
  [
    "TF Mobile",
    "特点",
    "简化了算子集，缩小了运行库"
  ],
  [
    "TFMini",
    "是",
    "Google 内部用于计算机视觉场景的解决方案"
  ],
  [
    "TFMini",
    "用途",
    "提供转换工具压缩模型，进行算子融合并生成代码"
  ],
  [
    "TFMini",
    "特点",
    "将模型嵌入到二进制文件中，可以在设备上运行和部署模型"
  ],
  [
    "TFMini",
    "缺点",
    "在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战"
  ],
  [
    "TensorFlow Lite",
    "发展来源",
    "基于 TF Mobile 的经验，继承了 TFMini 和内部其他类似项目的优秀工作"
  ],
  [
    "TFLite 转换器",
    "可以接受",
    "不同形式的模型，包括 Keras Model 和 SavedModel"
  ],
  [
    "TFLite 转换器",
    "用途",
    "将 TensorFlow 模型转换为 TFLite 格式"
  ],
  [
    "TFLite 转换器",
    "组成部分",
    "Python API 和命令行工具"
  ],
  [
    "TFLite 转换器",
    "执行步骤",
    "调用 tf.lite.TFLiteConverter.from_saved_model() 或 TFLiteConverter.from_keras_model()"
  ],
  [
    "TFLite 转换器",
    "执行步骤",
    "使用命令行 tflite_convert 进行转换"
  ],
  [
    "TFLite 转换器",
    "特点",
    "支持算子优化和常见的编译优化"
  ],
  [
    "TFLite 转换器",
    "特点",
    "支持量化原生支持"
  ],
  [
    "TFLite 转换器",
    "优化工作",
    "算子融合、常数折叠或无用代码删除"
  ],
  [
    "TFLite 转换器",
    "优化工作",
    "实现了一组优化的算子内核"
  ],
  [
    "TFLite 转换器",
    "优化工作",
    "支持训练后量化"
  ],
  [
    "训练后量化",
    "特点",
    "不需要改变模型，最少情况只需多加一行代码"
  ],
  [
    "MobileNet V2",
    "用途",
    "将图片分类到1000类"
  ],
  [
    "MobileNet V2",
    "特点",
    "默认包含最后的神经网络层（分类到1000类）"
  ],
  [
    "include_top=False",
    "用途",
    "不需要原有模型中最后的神经网络层（分类到1000类）"
  ],
  [
    "include_top=False",
    "结果",
    "可以增加自己的输出层"
  ],
  [
    "迁移学习",
    "特点",
    "不改变基础模型的各项参数变量"
  ],
  [
    "model.trainable = False",
    "用途",
    "基础模型的各项参数变量不会被新的训练修改数据"
  ],
  [
    "瓶颈层",
    "特点",
    "保持了很多通用性"
  ],
  [
    "瓶颈层",
    "用途",
    "用于特征提取"
  ],
  [
    "池化层",
    "用途",
    "对数据降维"
  ],
  [
    "输出层",
    "组成部分",
    "5个节点"
  ],
  [
    "GlobalAveragePooling2D",
    "用途",
    "将特征转换为每个图像对应一个1280元素向量"
  ],
  [
    "Conv2D",
    "用途",
    "特征提取"
  ],
  [
    "Dropout",
    "用途",
    "防止过拟合"
  ],
  [
    "build.gradle",
    "间接包含",
    "org.tensorflow:tensorflow-lite:+"
  ],
  [
    "TensorFlow",
    "间接包含",
    "模型文件和标签文件"
  ],
  [
    "TensorFlow",
    "间接包含",
    "转换、运行 TensorFlow 模型所需的所有工具"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "算子库(Op kernels)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Python API"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)、TensorFlow Lite 转换器(Converter)、算子库(Op kernels)、硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Post training quantization"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Quantization-aware training"
  ],
  [
    "TensorFlow",
    "间接包含",
    "多种级别的量化支持"
  ],
  [
    "TensorFlow",
    "间接包含",
    "优化的算子库"
  ],
  [
    "MobileNet V2",
    "可能与...相关",
    "MobileNet V2"
  ],
  [
    "迁移学习",
    "可能与...相关",
    "迁移学习"
  ],
  [
    "model.trainable = False",
    "可能与...相关",
    "model.trainable = False"
  ],
  [
    "瓶颈层",
    "可能与...相关",
    "瓶颈层"
  ],
  [
    "池化层",
    "可能与...相关",
    "池化层"
  ],
  [
    "输出层",
    "可能与...相关",
    "输出层"
  ],
  [
    "GlobalAveragePooling2D",
    "可能与...相关",
    "GlobalAveragePooling2D"
  ],
  [
    "PoseNet模型",
    "可能与...相关",
    "PoseNet"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "TensorFlow Lite"
  ],
  [
    "TensorFlow Lite 转换器",
    "可能与...相关",
    "TensorFlow Lite 转换器"
  ],
  [
    "FlatBuffers",
    "可能与...相关",
    "FlatBuffers"
  ],
  [
    "--output_file",
    "可能与...相关",
    "--saved_model_dir"
  ],
  [
    "--output_file",
    "可能与...相关",
    "--keras_model_file"
  ],
  [
    "--saved_model_dir",
    "可能与...相关",
    "--keras_model_file"
  ],
  [
    "TensorFlow 2.x 模型",
    "可能与...相关",
    "TensorFlow 2.x 模型"
  ],
  [
    "SavedModel",
    "可能与...相关",
    "Keras 模型"
  ],
  [
    "Android部署",
    "可能与...相关",
    "推理过程"
  ],
  [
    "TensorFlow Lite解释器",
    "可能与...相关",
    "TFLite"
  ],
  [
    "TensorFlow Lite 解释器",
    "可能与...相关",
    "TensorFlow Lite 解释器"
  ],
  [
    "GPU",
    "可能与...相关",
    "GPU"
  ],
  [
    "GPU 委托",
    "可能与...相关",
    "GPU 委托"
  ],
  [
    "量化",
    "可能与...相关",
    "量化"
  ],
  [
    "flow_from_directory",
    "可能与...相关",
    "flow_from_directory"
  ],
  [
    "train_generator",
    "可能与...相关",
    "val_generator"
  ]
]