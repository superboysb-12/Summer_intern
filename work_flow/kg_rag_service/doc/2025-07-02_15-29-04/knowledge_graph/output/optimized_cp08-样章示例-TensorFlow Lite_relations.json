[
  [
    "mobilenetv2_1.00_224",
    "组成部分",
    "conv2d, dropout, global_average_pooling2d, dense"
  ],
  [
    "mobilenetv2_1.00_224",
    "特点",
    "Total params: 2,626,821, Trainable params: 368,837, Non-trainable params: 2,257,984"
  ],
  [
    "model.fit",
    "执行步骤",
    "train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=val_generator, validation_steps=len(val_generator)"
  ],
  [
    "微调",
    "条件",
    "设置 model.trainable = False"
  ],
  [
    "微调",
    "用途",
    "提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练"
  ],
  [
    "微调",
    "特点",
    "训练期间将不更新预训练网络的权重，只在 MobileNet V2基础模型上训练了几层"
  ],
  [
    "微调",
    "结果",
    "预训练模型将忘记它学到的东西"
  ],
  [
    "微调",
    "执行步骤",
    "取消冻结模型的顶层，设置 base_model.trainable = True"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "155层网络结构"
  ],
  [
    "微调",
    "步骤",
    "取消冻结模型的顶层"
  ],
  [
    "微调",
    "步骤",
    "设置前100层为不可训练"
  ],
  [
    "微调",
    "步骤",
    "使用低学习率重新编译模型"
  ],
  [
    "微调",
    "结果",
    "模型精度提高到98%"
  ],
  [
    "微调",
    "缺点",
    "可能导致模型过拟合"
  ],
  [
    "TFLite",
    "用途",
    "将TensorFlow模型转换为轻量级格式"
  ],
  [
    "SavedModel",
    "特点",
    "包含完整的TensorFlow程序"
  ],
  [
    "SavedModel",
    "特点",
    "不需要原始模型构建代码就可以运行"
  ],
  [
    "模型训练",
    "步骤",
    "设置model.trainable = False"
  ],
  [
    "模型训练",
    "步骤",
    "训练预训练模型的顶层权重"
  ],
  [
    "模型训练",
    "条件",
    "需先训练顶层分类器并设置预训练模型为不可训练"
  ],
  [
    "梯度更新",
    "缺点",
    "幅度过大会导致预训练模型遗忘已学特征"
  ],
  [
    "CNN层",
    "特点",
    "前几层学习通用特征"
  ],
  [
    "CNN层",
    "特点",
    "高层学习针对特定数据集的专用特征"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "算子库(Op kernels)"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "采用更小的模型格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为方便解释器使用的格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "引入优化以减小二进制文件的大小和提高性能"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "有130个左右"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "与 TensorFlow 的核心算子库略有不同"
  ],
  [
    "TensorFlow Lite 算子库",
    "特点",
    "做了移动设备相关的优化"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在安卓应用只需 1 兆左右的运行环境"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在 MCU 上甚至可以小于 100KB"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "利用手机上的加速器，比如 GPU 或者 DSP"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "利用 Android 神经网络 API（Android NN API)"
  ],
  [
    "fine_tune_at",
    "用途",
    "指定从哪个层开始进行微调"
  ],
  [
    "fine_tune_at",
    "示例",
    "100"
  ],
  [
    "TFLite 模型文件格式",
    "是",
    "FlatBuffers"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "更注重考虑实时性，内存高效"
  ],
  [
    "TFLite 模型文件格式",
    "用途",
    "在内存有限的移动环境中使用"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析"
  ],
  [
    "TFLite 模型文件格式",
    "特点",
    "减少了内存碎片化"
  ],
  [
    "schema.fbs 文件",
    "用途",
    "使用 FlatBuffers 定义了 TFLite 模型文件格式"
  ],
  [
    "TFLite 模型文件",
    "特点",
    "是一个层次的结构"
  ],
  [
    "TFLite 模型",
    "包含",
    "子图"
  ],
  [
    "TFLite 模型",
    "包含",
    "算子库和共享的内存缓冲区"
  ],
  [
    "张量",
    "用途",
    "存储模型权重"
  ],
  [
    "张量",
    "用途",
    "计算节点的输入和输出"
  ],
  [
    "张量",
    "特点",
    "引用 Model 的内存缓冲区的一片区域，提高内存效率"
  ],
  [
    "算子实现",
    "包含",
    "OperatorCode"
  ],
  [
    "OperatorCode",
    "可以是",
    "内置的算子"
  ],
  [
    "OperatorCode",
    "可以是",
    "自定制算子"
  ],
  [
    "OperatorCode",
    "包含",
    "名字"
  ],
  [
    "模型的计算节点",
    "包含",
    "用到的算子索引"
  ],
  [
    "模型的计算节点",
    "包含",
    "输入输出用到的 Tensor 索引"
  ],
  [
    "子图",
    "包含",
    "一系列的计算节点"
  ],
  [
    "子图",
    "包含",
    "多个张量"
  ],
  [
    "子图",
    "包含",
    "子图本身的输入和输出"
  ],
  [
    "MobileNet V2",
    "用途",
    "创建、训练和导出自定义 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "模型文件和标签文件"
  ],
  [
    "Android 应用",
    "用途",
    "识别花卉图片"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "可从 github 下载源码"
  ],
  [
    "flower_classification",
    "组成部分",
    "android/start 目录下的项目模板和 finish 目录下的完整代码"
  ],
  [
    "Android Studio",
    "条件",
    "需要确认版本"
  ],
  [
    "TFLite 模型转换过程",
    "步骤",
    "用户在自己的工作台中使用 TensorFlow API 构造 TensorFlow 模型"
  ],
  [
    "TFLite 模型转换过程",
    "步骤",
    "使用 TFLite 模型转换器转换成 TFLite 文件格式(FlatBuffers 格式)"
  ],
  [
    "TFLite 解释器",
    "用途",
    "接受 TFLite 模型"
  ],
  [
    "TFLite 解释器",
    "用途",
    "调用不同的硬件加速器比如 GPU 进行执行"
  ],
  [
    "TFLite 文件格式",
    "是",
    "FlatBuffers 格式"
  ],
  [
    "Android Studio",
    "用途",
    "打开现有 Android Studio 项目"
  ],
  [
    "Android Studio",
    "组成部分",
    "启动图标"
  ],
  [
    "Android Studio",
    "组成部分",
    "打开项目图标"
  ],
  [
    "flower_classification/android/finish",
    "属于",
    "examples/lite/codelabs"
  ],
  [
    "TensorFlow Lite 模型文件",
    "组成部分",
    "model.tflite"
  ],
  [
    "TensorFlow Lite 模型文件",
    "组成部分",
    "label.txt"
  ],
  [
    "build.gradle",
    "用途",
    "配置项目依赖"
  ],
  [
    "build.gradle",
    "组成部分",
    "dependencies"
  ],
  [
    "tensorflow-lite",
    "用途",
    "实现 TensorFlow Lite 功能"
  ],
  [
    "Gradle 同步",
    "条件",
    "模型文件已拷贝到 assets 目录"
  ],
  [
    "MobileNet V2",
    "包含",
    "155层"
  ],
  [
    "微调过程",
    "步骤",
    "冻结前100层"
  ],
  [
    "微调过程",
    "步骤",
    "使用低学习率编译模型"
  ],
  [
    "微调过程",
    "步骤",
    "恢复训练"
  ],
  [
    "模型编译",
    "组成部分",
    "categorical_crossentropy损失函数"
  ],
  [
    "模型编译",
    "组成部分",
    "Adam优化器"
  ],
  [
    "模型编译",
    "组成部分",
    "accuracy评估指标"
  ],
  [
    "TFLite模型",
    "特点",
    "不需要原始模型构建代码就可以运行"
  ],
  [
    "TFLite模型",
    "组成部分",
    "权重值和计算"
  ],
  [
    "TFLite转换",
    "步骤",
    "使用tf.saved_model.save保存模型"
  ],
  [
    "TFLite转换",
    "步骤",
    "使用TFLiteConverter转换模型"
  ],
  [
    "Android部署",
    "步骤",
    "将模型文件拷贝到assets目录"
  ],
  [
    "Android部署",
    "步骤",
    "修改build.gradle配置"
  ],
  [
    "Android部署",
    "步骤",
    "初始化TensorFlow Lite解释器"
  ],
  [
    "TensorFlow Lite解释器",
    "用途",
    "执行模型推理"
  ],
  [
    "推理过程",
    "步骤",
    "数据转换"
  ],
  [
    "推理过程",
    "步骤",
    "执行推理"
  ],
  [
    "推理过程",
    "步骤",
    "解释输出"
  ],
  [
    "PoseNet模型",
    "用途",
    "人体姿势估计"
  ],
  [
    "PoseNet模型",
    "特点",
    "检测关键身体部位的位置"
  ],
  [
    "aaptOptions",
    "用途",
    "防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件"
  ],
  [
    "aaptOptions",
    "组成部分",
    "noCompress \"tflite\""
  ],
  [
    "Android环境部署",
    "步骤",
    "运行Sync Gradle"
  ],
  [
    "Android Studio",
    "条件",
    "配置proxy或使用国内镜像"
  ],
  [
    "build.gradle",
    "修改",
    "将maven源google()和jcenter()替换为国内镜像"
  ],
  [
    "buildscript",
    "组成部分",
    "repositories和dependencies"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "轻量级"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "快速启动"
  ],
  [
    "TFLite 解释执行器",
    "特点",
    "内存高效"
  ],
  [
    "TFLite 解释执行器",
    "组成部分",
    "核心运行时"
  ],
  [
    "TFLite 解释执行器",
    "组成部分",
    "标准算子"
  ],
  [
    "TFLite 解释执行器",
    "用途",
    "在移动设备上执行模型推理"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "加载模型"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "转换数据"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "运行模型推理"
  ],
  [
    "TFLite 解释执行器",
    "执行步骤",
    "解释输出"
  ],
  [
    "TFLite",
    "支持语言",
    "Java"
  ],
  [
    "TFLite",
    "支持语言",
    "C++"
  ],
  [
    "TFLite",
    "支持语言",
    "Python"
  ],
  [
    "TFLite",
    "支持语言",
    "C"
  ],
  [
    "TFLite",
    "支持语言",
    "Object C"
  ],
  [
    "TFLite",
    "支持语言",
    "C#"
  ],
  [
    "TFLite",
    "支持语言",
    "Swift"
  ],
  [
    "TFLite",
    "部署方式",
    "从头编译"
  ],
  [
    "TFLite",
    "部署方式",
    "使用已编译好的库"
  ],
  [
    "TFLite",
    "部署方式",
    "Android 开发者使用 JCenter Bintray 的 TFLite AAR"
  ],
  [
    "TFLite",
    "部署方式",
    "iOS 开发者通过 CocoaPods 获取"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "执行步骤",
    "选择模型、转换模型、部署到设备和优化模型"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "包含",
    "选择模型"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "包含",
    "转换模型"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "包含",
    "部署到设备"
  ],
  [
    "TensorFlow Lite 开发工作流程",
    "包含",
    "优化模型"
  ],
  [
    "选择模型",
    "用途",
    "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的 TensorFlow 预训练模型中选择一个模型直接使用或重新训练"
  ],
  [
    "转换模型",
    "用途",
    "使用 TensorFlow Lite 转换器将模型转换为 TensorFlow Lite 格式"
  ],
  [
    "部署到设备",
    "用途",
    "使用 TensorFlow Lite 解释器（提供多种语言的 API）在设备端运行模型"
  ],
  [
    "优化模型",
    "用途",
    "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "提供多种语言的 API"
  ],
  [
    "模型优化工具包",
    "用途",
    "缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite 模型",
    "特点",
    "优化的 FlatBuffer 格式"
  ],
  [
    "TensorFlow Lite 模型",
    "文件扩展名",
    ".tflite"
  ],
  [
    "TensorFlow Lite 转换器",
    "使用方式",
    "命令行与 Python API"
  ],
  [
    "Google",
    "推荐",
    "使用 Python API 进行转换"
  ],
  [
    "命令行工具",
    "特点",
    "只提供了基本的转化功能"
  ],
  [
    "FlatBuffers",
    "用途",
    "主要应用于游戏场景"
  ],
  [
    "FlatBuffers",
    "特点",
    "为了高性能场景创建的序列化库"
  ],
  [
    "FlatBuffers",
    "优点",
    "相比 Protocol Buffer 有更高的性能和更小的大小"
  ],
  [
    "FlatBuffers",
    "用途",
    "更适合于边缘设备部署"
  ],
  [
    "tflite_convert",
    "属于",
    "命令行 TensorFlow Lite 转换器命令行工具"
  ],
  [
    "tflite_convert",
    "安装方式",
    "与 TensorFlow 一起安装"
  ],
  [
    "--output_file",
    "参数说明",
    "类型: string. Full path of the output file"
  ],
  [
    "--saved_model_dir",
    "参数说明",
    "类型: string. Full path to the SavedModel directory"
  ],
  [
    "--keras_model_file",
    "参数说明",
    "类型: string. Full path to the Keras H5 model file"
  ],
  [
    "--enable_v1_converter",
    "参数说明",
    "类型: bool. (default False) Enables the converter and flags used in TF 1.x instead of TF 2.x"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在移动端、嵌入式和物联网设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow 模型",
    "是什么",
    "一种数据结构，包含了在解决特定问题时训练得到的机器学习网络的逻辑和知识"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "转换和运行 TensorFlow 模型所需的工具"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "存放训练好的模型供开发人员复用"
  ],
  [
    "TensorFlow Hub",
    "特点",
    "提供经过充分认证的模型"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "节省训练时间和计算资源"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "直接部署或用于迁移学习"
  ],
  [
    "TensorFlow Hub",
    "组成部分",
    "Text, Image, Video 和 Publishers 等类别"
  ],
  [
    "MobileNet",
    "示例",
    "TensorFlow Hub 上可搜索到的模型"
  ],
  [
    "hub.KerasLayer",
    "用途",
    "加载 TensorFlow Hub 上的模型"
  ],
  [
    "TensorFlow Lite解释器",
    "用途",
    "执行模型推理"
  ],
  [
    "TensorFlow Lite解释器",
    "组成部分",
    "模型执行流图"
  ],
  [
    "ClassifierFloatMobileNet类",
    "包含",
    "model.tflite和label.txt"
  ],
  [
    "Classifier类",
    "包含",
    "TFLite解释器和GPU代理"
  ],
  [
    "GPU代理",
    "用途",
    "加速模型推理"
  ],
  [
    "TFLite解释器",
    "执行步骤",
    "创建实例并加载模型"
  ],
  [
    "TensorFlow Lite支持库",
    "用途",
    "简化图像预处理和输出处理"
  ],
  [
    "ImageProcessor",
    "用途",
    "预处理输入图像"
  ],
  [
    "ImageProcessor",
    "执行步骤",
    "调整大小、裁剪、旋转和归一化图像"
  ],
  [
    "recognizeImage方法",
    "执行步骤",
    "运行TFLite推理并获取输出概率"
  ],
  [
    "TensorLabel",
    "用途",
    "将模型输出与类别标签关联"
  ],
  [
    "PoseNet模型",
    "用途",
    "估计图像或视频中的人体姿势"
  ],
  [
    "PoseNet模型",
    "执行步骤",
    "检测关键身体部位的位置"
  ],
  [
    "PoseNet示例应用程序",
    "执行步骤",
    "获取图像数据、处理图像、调用模型、绘制关键点"
  ],
  [
    "tf.keras model",
    "用途",
    "生成 HDF5 文件的绝对路径目录"
  ],
  [
    "TensorFlow 模型导出",
    "支持",
    "SavedModel 和 Keras Sequential 两种模型导出方法和格式"
  ],
  [
    "SavedModel",
    "示例",
    "tflite_convert --saved_model_dir=/tmp/mobilenet_saved_model --output_file=/tmp/mobilenet.tflite"
  ],
  [
    "Keras H5",
    "示例",
    "tflite_convert --keras_model_file=/tmp/mobilenet_keras_model.h5 --output_file=/tmp/mobilenet.tflite"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "用途",
    "转换模型"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "输入参数",
    "saved_model_dir"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是",
    "TensorFlow Lite模型转换器"
  ],
  [
    "模型转换",
    "步骤",
    "使用tf.lite.TFLiteConverter.from_saved_model方法"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件的大小约为 1 MB（针对 32 位 ARM build）"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "TensorFlow Lite 解释器(Interpreter)、TensorFlow Lite 转换器(Converter)、算子库(Op kernels)、硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow Lite",
    "应用",
    "Google Assistant，Google Photos，Uber，Airbnb，网易，爱奇艺，WPS 等"
  ],
  [
    "TensorFlow Lite",
    "支持设备",
    "Android、iOS、嵌入式设备、以及极小的 MCU 设备"
  ],
  [
    "TensorFlow Lite",
    "发展历史",
    "基于 TF Mobile 的经验，继承了 TFMini 和内部其他类似项目的优秀工作"
  ],
  [
    "TensorFlow Lite",
    "优化",
    "算子优化和常见的编译优化，比如算子融合、常数折叠或无用代码删除等"
  ],
  [
    "TensorFlow Lite",
    "模型格式",
    "采用 FlatBuffers 格式，支持将文件映射到内存中，然后直接进行读取和解释"
  ],
  [
    "TensorFlow Lite 解释执行器",
    "特点",
    "轻量级、快速启动、内存高效"
  ],
  [
    "TensorFlow Lite 解释执行器",
    "执行步骤",
    "加载模型、转换数据、运行模型推理、解释输出"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为 TensorFlow Lite 格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "优化",
    "算子优化和常见的编译优化，比如算子融合、常数折叠或无用代码删除等"
  ],
  [
    "FlatBuffers",
    "特点",
    "内存高效，支持将文件映射到内存中，然后直接进行读取和解释"
  ],
  [
    "TensorFlow Lite 工作流程",
    "步骤",
    "选择模型、转换模型、部署到设备、优化模型"
  ],
  [
    "TensorFlow Hub",
    "用途",
    "提供训练好的模型，开发人员可以复用这些已经训练好且经过充分认证的模型"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "端侧机器学习"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "移动应用中的OCR处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "视频中的AR效果"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "文字处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "图像和视频处理"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "离线语音识别"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "IoT领域"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "工业物联智能设备开发"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "高性能"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "模型优化工具"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "微控制器(MCU)支持"
  ],
  [
    "网易",
    "用途",
    "TensorFlow Lite进行OCR处理"
  ],
  [
    "爱奇艺",
    "用途",
    "TensorFlow Lite进行视频中的AR效果"
  ],
  [
    "WPS",
    "用途",
    "TensorFlow Lite进行文字处理"
  ],
  [
    "Google Photos",
    "用途",
    "TensorFlow Lite进行图像处理"
  ],
  [
    "Google Assistant",
    "用途",
    "TensorFlow Lite进行语音识别"
  ],
  [
    "Google Pixel 4",
    "用途",
    "TensorFlow Lite进行Live Caption功能"
  ],
  [
    "出门问问智能音箱",
    "用途",
    "TensorFlow Lite进行热词唤醒"
  ],
  [
    "科沃斯扫地机器人",
    "用途",
    "TensorFlow Lite避开障碍物"
  ],
  [
    "创新奇智",
    "用途",
    "TensorFlow Lite开发智能质检一体机和智能读码机"
  ],
  [
    "MCU",
    "是什么",
    "单一芯片的小型计算机"
  ],
  [
    "MCU",
    "特点",
    "没有操作系统，只有内存"
  ],
  [
    "MCU",
    "用途",
    "IoT领域"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "Google Assistant"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "Google Photos"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "Uber"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "Airbnb"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "网易"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "爱奇艺"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "WPS"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "Google Arts & Culture"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "出门问问智能音箱"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "科沃斯扫地机器人"
  ],
  [
    "TensorFlow Lite",
    "示例",
    "创新奇智"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将输入的 TensorFlow 模型生成 TensorFlow Lite 模型"
  ],
  [
    "TensorFlow Lite 模型",
    "特点",
    "优化的 FlatBuffer 格式，以 .tflite 为文件扩展名"
  ],
  [
    "TensorFlow Lite 转换器",
    "包含",
    "命令行工具和 Python API"
  ],
  [
    "Python API",
    "特点",
    "Google 推荐使用"
  ],
  [
    "命令行工具",
    "特点",
    "只提供了基本的转化功能"
  ],
  [
    "FlatBuffers",
    "用途",
    "主要应用于游戏场景"
  ],
  [
    "FlatBuffers",
    "特点",
    "为了高性能场景创建的序列化库"
  ],
  [
    "FlatBuffers",
    "优点",
    "相比 Protocol Buffer 有更高的性能和更小的大小"
  ],
  [
    "FlatBuffers",
    "用途",
    "更适合于边缘设备部署"
  ],
  [
    "tflite_convert",
    "是",
    "TensorFlow Lite 转换器命令行工具"
  ],
  [
    "tflite_convert",
    "包含",
    "--output_file, --saved_model_dir, --keras_model_file, --enable_v1_converter 参数"
  ],
  [
    "--output_file",
    "用途",
    "指定输出文件的绝对路径"
  ],
  [
    "--saved_model_dir",
    "用途",
    "指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录"
  ],
  [
    "--keras_model_file",
    "用途",
    "指定含有 TensorFlow 1.x 或者 2.0 使用 tf.keras model 生成 HDF5 文件的绝对路径目录"
  ],
  [
    "TensorFlow 模型导出",
    "包含",
    "SavedModel 和 Keras Sequential 两种模型导出方法和格式"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是",
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API"
  ],
  [
    "tf.lite.TFLiteConverter",
    "包含",
    "from_saved_model(), from_keras_model(), from_concrete_functions() 类方法"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "用途",
    "用来转换 SavedModel 格式模型"
  ],
  [
    "TFLiteConverter.from_keras_model()",
    "用途",
    "用来转换 tf.keras 模型"
  ],
  [
    "TFLiteConverter.from_concrete_functions()",
    "用途",
    "用来转换 concrete functions"
  ],
  [
    "TensorFlow 2.x 模型",
    "特点",
    "使用 SavedModel 格式存储"
  ],
  [
    "Keras模型",
    "转换为",
    "TensorFlow Lite模型"
  ],
  [
    "TensorFlow Lite模型",
    "保存为",
    "model.tflite文件"
  ],
  [
    "TensorFlow",
    "包含",
    "Keras"
  ],
  [
    "TensorFlow Lite",
    "是",
    "TensorFlow的轻量级版本"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "执行模型文件在输入数据上定义的运算符，输出推理结果"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "适用于多个平台"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "提供了一个简单的 API，用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型"
  ],
  [
    "Java",
    "示例",
    "调用解释器的方式：try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) { interpreter.run(input, output); }"
  ],
  [
    "GPU",
    "优点",
    "比 CPU 执行更快的浮点矩阵运算"
  ],
  [
    "GPU",
    "示例",
    "在有 GPU 加速的手机上运行 MobileNet 图像分类，模型运行速度可以提高"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "Python API"
  ],
  [
    "tf.lite.TFLiteConverter",
    "是什么",
    "将 TensorFlow 模型格式转换为 TensorFlow Lite 的 Python API"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "用途",
    "转换 SavedModel 格式模型"
  ],
  [
    "TFLiteConverter.from_keras_model()",
    "用途",
    "转换 tf.keras 模型"
  ],
  [
    "TFLiteConverter.from_concrete_functions()",
    "用途",
    "转换 concrete functions"
  ],
  [
    "TensorFlow 2.x 模型",
    "特点",
    "使用 SavedModel 格式存储"
  ],
  [
    "TensorFlow 2.x 模型",
    "组成部分",
    "高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）"
  ],
  [
    "tf.keras.models.Sequential",
    "示例",
    "创建模型的高级API示例"
  ],
  [
    "tf.saved_model.save",
    "用途",
    "生成 SavedModel"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在不同设备上使用硬件加速"
  ],
  [
    "TensorFlow Lite 解释器",
    "包含",
    "委托（Delegates）"
  ],
  [
    "GPU 委托",
    "用途",
    "允许解释器在设备的 GPU 上运行适当的运算符"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在 Android 与 iOS 平台上使用"
  ],
  [
    "Android 开发人员",
    "用途",
    "使用 TensorFlow Lite AAR"
  ],
  [
    "iOS 开发人员",
    "用途",
    "使用 CocoaPods for Swift or Objective-C"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=1, input_shape=[1])"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=16, activation='relu')"
  ],
  [
    "tf.keras.models.Sequential",
    "组成部分",
    "tf.keras.layers.Dense(units=1)"
  ],
  [
    "model.compile",
    "用途",
    "配置模型的优化器和损失函数"
  ],
  [
    "model.compile",
    "特点",
    "使用优化器'sgd'和损失函数'mean_squared_error'"
  ],
  [
    "tf.saved_model.save",
    "用途",
    "生成SavedModel"
  ],
  [
    "tf.saved_model.save",
    "参数",
    "model"
  ],
  [
    "tf.saved_model.save",
    "参数",
    "saved_model_keras_dir"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "优化模型大小和性能"
  ],
  [
    "模型优化",
    "目标",
    "在给定设备上实现性能、模型大小和准确性的理想平衡"
  ],
  [
    "大而复杂的模型",
    "特点",
    "需要高准确率"
  ],
  [
    "小一点的模型",
    "特点",
    "占用更少的磁盘和内存，更快更高效"
  ],
  [
    "量化",
    "用途",
    "降低权重的精确表示，降低存储和计算的激活值"
  ],
  [
    "量化",
    "优点",
    "对现有 CPU 平台的支持"
  ],
  [
    "量化",
    "优点",
    "降低用于读取和存储中间激活值的存储器访问成本"
  ],
  [
    "量化",
    "优点",
    "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，对量化特别有益"
  ],
  [
    "TensorFlow Lite",
    "包含",
    "多种级别的量化支持"
  ],
  [
    "Tensorflow Lite post-training quantization",
    "用途",
    "使权重和激活值的 Post training 更简单"
  ],
  [
    "Quantization-aware training",
    "用途",
    "以最小精度下降来训练网络"
  ],
  [
    "Quantization-aware training",
    "条件",
    "仅适用于卷积神经网络的一个子集"
  ],
  [
    "Python 代码片段",
    "示例",
    "使用预训练量化进行模型转换"
  ],
  [
    "花卉识别 app",
    "用途",
    "识别照相机所拍摄的花卉"
  ],
  [
    "花卉识别 app",
    "组成部分",
    "TensorFlow Lite"
  ],
  [
    "花卉识别 app",
    "组成部分",
    "MobileNets_v2"
  ],
  [
    "花卉识别 app",
    "执行步骤",
    "通过迁移学习实现花卉识别模型"
  ],
  [
    "花卉识别 app",
    "执行步骤",
    "使用 TFLite 转换器转换模型"
  ],
  [
    "花卉识别 app",
    "执行步骤",
    "在 Android 应用中使用 TFLite 解释器运行它"
  ],
  [
    "花卉识别 app",
    "执行步骤",
    "使用 TensorFlow Lite 支持库预处理模型输入和后处理模型输出"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "实现花卉识别 app"
  ],
  [
    "MobileNets_v2",
    "用途",
    "在 Android 设备上运行图像识别模型"
  ],
  [
    "TFLite 转换器",
    "用途",
    "转换模型"
  ],
  [
    "TFLite 解释器",
    "用途",
    "在 Android 应用中运行模型"
  ],
  [
    "TensorFlow Lite 支持库",
    "用途",
    "预处理模型输入和后处理模型输出"
  ],
  [
    "TensorFlow",
    "是什么",
    "一个端到端的机器学习开源框架"
  ],
  [
    "TensorFlow",
    "特点",
    "支持大规模的模型训练和各种环境的部署"
  ],
  [
    "TensorFlow",
    "用途",
    "服务器和移动端的部署"
  ],
  [
    "TensorFlow",
    "支持",
    "Python, C++, Java, Swift, Javascript等多种语言"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "轻量、快速、兼容度高"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "移动端及IoT设备端的深度学习技术"
  ],
  [
    "TensorFlow Lite",
    "优点",
    "大大降低移动端及IoT设备端的深度学习技术门槛"
  ],
  [
    "TensorFlow Lite",
    "属于",
    "TensorFlow团队开发的产品"
  ],
  [
    "TensorFlow",
    "包含",
    "TensorFlow Lite"
  ],
  [
    "TensorFlow Lite",
    "是",
    "在边缘设备上运行 TensorFlow 模型推理的官方框架"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "跨平台运行，包括 Android、iOS 以及基于 Linux 的 IoT 设备和微控制器"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "在边缘设备上运行 TensorFlow 模型推理"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "特别为各种端侧设备优化的算子库"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "能够利用各种硬件加速"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件的大小约为 1 MB（针对 32 位 ARM build）"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，二进制文件的大小不到 300 KB"
  ],
  [
    "TF Mobile",
    "是",
    "一个缩减版的 TensorFlow，简化了算子集，也缩小了运行库"
  ],
  [
    "TF Mobile",
    "用途",
    "尝试简化 TensorFlow 并在移动设备上运行"
  ],
  [
    "TFMini",
    "是",
    "Google 内部用于计算机视觉场景的解决方案"
  ],
  [
    "TFMini",
    "用途",
    "提供了一些转换工具压缩模型，进行算子融合并生成代码"
  ],
  [
    "TFMini",
    "用途",
    "将模型嵌入到二进制文件中，这样就可以在设备上运行和部署模型"
  ],
  [
    "TFMini",
    "特点",
    "针对移动设备做了很多优化"
  ],
  [
    "TFMini",
    "缺点",
    "在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战"
  ],
  [
    "TensorFlow Lite",
    "发展历史",
    "基于 TF Mobile 的经验，也继承了 TFMini 和内部其他类似项目的很多优秀工作"
  ],
  [
    "tf.lite.TFLiteConverter",
    "用途",
    "将Keras模型转换为TensorFlow Lite模型"
  ],
  [
    "tf.lite.TFLiteConverter.from_keras_model",
    "步骤",
    "创建TFLiteConverter实例并加载Keras模型"
  ],
  [
    "converter.convert",
    "步骤",
    "执行模型转换过程"
  ],
  [
    "MobileNet V2",
    "是",
    "基于流线型架构的轻量级深层神经网络"
  ],
  [
    "MobileNet V2",
    "用途",
    "图像分类任务"
  ],
  [
    "MobileNet V2",
    "特点",
    "使用深度可分离的卷积"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "预训练模型和全连接的分类器"
  ],
  [
    "迁移学习",
    "用途",
    "在小型数据集上训练模型"
  ],
  [
    "迁移学习",
    "步骤",
    "冻结预训练模型并更新分类器权重"
  ],
  [
    "卷积基",
    "用途",
    "提取图像特征"
  ],
  [
    "微调",
    "用途",
    "提高模型性能"
  ],
  [
    "微调",
    "条件",
    "训练数据集很大且类似于预训练模型的数据集"
  ],
  [
    "ImageDataGenerator",
    "用途",
    "生成批次的图片数据"
  ],
  [
    "ImageDataGenerator",
    "特点",
    "支持像素缩放和数据增强"
  ],
  [
    "flow_from_directory",
    "用途",
    "逐步加载数据集图像"
  ],
  [
    "flow_from_directory",
    "参数",
    "target_size和batch_size"
  ],
  [
    "target_size",
    "用途",
    "设置图像加载的特定大小"
  ],
  [
    "batch_size",
    "用途",
    "设置训练时随机选出的图像数量"
  ],
  [
    "train_generator",
    "用途",
    "从指定目录生成训练数据批次"
  ],
  [
    "train_generator",
    "特点",
    "支持图像大小调整和批次划分"
  ],
  [
    "val_generator",
    "用途",
    "从指定目录生成验证数据批次"
  ],
  [
    "val_generator",
    "特点",
    "支持图像大小调整和批次划分"
  ],
  [
    "MobileNetV2",
    "是什么",
    "预加载了ImageNet训练权重的深度学习模型"
  ],
  [
    "MobileNetV2",
    "用途",
    "作为迁移学习的基础模型"
  ],
  [
    "MobileNetV2",
    "特点",
    "支持自定义输入形状和是否包含顶层分类器"
  ],
  [
    "TensorFlow Lite 转换器",
    "可以接受",
    "Keras Model 和 SavedModel"
  ],
  [
    "TensorFlow Lite 转换器",
    "用途",
    "将 TensorFlow 模型转换为 TFLite 格式"
  ],
  [
    "TensorFlow Lite 转换器",
    "调用方式",
    "Python API 或命令行"
  ],
  [
    "TFLiteConverter.from_saved_model()",
    "用途",
    "从 SavedModel 转换模型"
  ],
  [
    "TFLiteConverter.from_keras_model()",
    "用途",
    "从 Keras Model 转换模型"
  ],
  [
    "tflite_convert",
    "用途",
    "通过命令行转换模型"
  ],
  [
    "TensorFlow Lite 转换器",
    "优化工作",
    "算子优化和常见的编译优化"
  ],
  [
    "算子优化",
    "包含",
    "算子融合、常数折叠、无用代码删除"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "实现了一组优化的算子内核"
  ],
  [
    "优化的算子内核",
    "用途",
    "在移动设备上实现性能大幅度提升"
  ],
  [
    "TensorFlow Lite 转换器",
    "特点",
    "支持量化"
  ],
  [
    "训练后量化",
    "特点",
    "不需要改变模型"
  ],
  [
    "训练后量化",
    "执行步骤",
    "设置 converter.optimizations=[tf.lite.Optimize.DEFAULT]"
  ],
  [
    "TensorFlow Lite",
    "是什么",
    "一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "支持设备端机器学习推断"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "延迟较低"
  ],
  [
    "TensorFlow Lite",
    "特点",
    "二进制文件很小"
  ],
  [
    "MobileNet V2",
    "用途",
    "将图片分类到1000类"
  ],
  [
    "MobileNet V2",
    "特点",
    "默认包含1000类的分类层"
  ],
  [
    "include_top=False",
    "用途",
    "移除原有模型中最后的神经网络层（分类到1000类）"
  ],
  [
    "迁移学习",
    "特点",
    "不改变基础模型的各项参数变量"
  ],
  [
    "迁移学习",
    "优点",
    "保留原来大规模训练的优势"
  ],
  [
    "model.trainable = False",
    "用途",
    "设置在训练中基础模型的参数不会被新的训练修改"
  ],
  [
    "瓶颈层",
    "特点",
    "保持了很多通用性"
  ],
  [
    "瓶颈层",
    "用途",
    "用于特征提取"
  ],
  [
    "池化层",
    "用途",
    "对数据降维"
  ],
  [
    "输出层",
    "组成部分",
    "5个节点"
  ],
  [
    "GlobalAveragePooling2D",
    "用途",
    "将特征转换为每个图像对应一个1280元素向量"
  ],
  [
    "MobileNet V2",
    "用途",
    "将图片分类到1000类"
  ],
  [
    "MobileNet V2",
    "组成部分",
    "瓶颈层"
  ],
  [
    "MobileNet V2",
    "特点",
    "保留原来大规模训练的优势"
  ],
  [
    "include_top=False",
    "用途",
    "不需要原有模型中最后的神经网络层"
  ],
  [
    "迁移学习",
    "特点",
    "不改变基础模型的各项参数变量"
  ],
  [
    "model.trainable = False",
    "用途",
    "设置在训练中基础模型的各项参数变量不会被新的训练修改数据"
  ],
  [
    "瓶颈层",
    "特点",
    "保持了很多通用性"
  ],
  [
    "GlobalAveragePooling2D",
    "用途",
    "将特征转换为每个图像对应一个1280元素向量"
  ],
  [
    "tf.keras.Sequential",
    "组成部分",
    "base_model, Conv2D, Dropout, GlobalAveragePooling2D, Dense"
  ],
  [
    "Dense",
    "特点",
    "5个节点的输出层"
  ],
  [
    "model.compile",
    "组成部分",
    "optimizer, loss, metrics"
  ],
  [
    "Adam",
    "用途",
    "优化模型"
  ],
  [
    "categorical_crossentropy",
    "用途",
    "损失函数"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "执行模型文件在输入数据上定义的运算符，输出推理结果"
  ],
  [
    "TensorFlow Lite 解释器",
    "特点",
    "适用于多个平台，提供了一个简单的 API"
  ],
  [
    "TensorFlow Lite 解释器",
    "组成部分",
    "GPU 委托"
  ],
  [
    "GPU 委托",
    "用途",
    "允许解释器在设备的 GPU 上运行适当的运算符"
  ],
  [
    "GPU",
    "优点",
    "比 CPU 执行更快的浮点矩阵运算"
  ],
  [
    "MobileNet 图像分类",
    "示例",
    "在有 GPU 加速的手机上运行，模型运行速度可以提高 5.5 倍"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "在 Android 与 iOS 平台上使用"
  ],
  [
    "TensorFlow Lite AAR",
    "用途",
    "Android 开发人员使用"
  ],
  [
    "CocoaPods",
    "用途",
    "iOS 开发人员使用"
  ],
  [
    "TensorFlow Lite 解释器",
    "用途",
    "部署在 Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux 系统上"
  ],
  [
    "TensorFlow Lite",
    "用途",
    "优化模型大小和性能"
  ],
  [
    "量化",
    "用途",
    "降低权重的精确表示，并且可选的降低存储和计算的激活值"
  ],
  [
    "量化",
    "优点",
    "对现有 CPU 平台的支持"
  ],
  [
    "量化",
    "优点",
    "降低存储器访问成本"
  ],
  [
    "量化",
    "优点",
    "对 SIMD 指令功能特别有益"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "Post training quantization"
  ],
  [
    "TensorFlow Lite",
    "组成部分",
    "Quantization-aware training"
  ],
  [
    "MobileNet V2",
    "用途",
    "进行迁移学习，实现识别花卉模型"
  ],
  [
    "MobileNet V2",
    "特点",
    "基于一个流线型的架构，使用深度可分离的卷积"
  ],
  [
    "MobileNet V2",
    "用途",
    "图像分类任务"
  ],
  [
    "迁移学习",
    "用途",
    "利用在同一域中的较大数据集上训练的模型所学习的特征"
  ],
  [
    "ImageDataGenerator",
    "用途",
    "生成一个批次一个批次的图片，以生成器的形式给模型训练"
  ],
  [
    "flow_from_directory",
    "用途",
    "逐步加载单个数据集的图像"
  ],
  [
    "TFLite 模型",
    "间接包含",
    "一系列的计算节点"
  ],
  [
    "TFLite 模型",
    "间接包含",
    "多个张量"
  ],
  [
    "TFLite 模型",
    "间接包含",
    "子图本身的输入和输出"
  ],
  [
    "算子实现",
    "间接包含",
    "名字"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "算子库(Op kernels)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "模型文件和标签文件"
  ],
  [
    "TensorFlow",
    "间接包含",
    "转换和运行 TensorFlow 模型所需的工具"
  ],
  [
    "TensorFlow",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)、TensorFlow Lite 转换器(Converter)、算子库(Op kernels)、硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "TensorFlow",
    "间接包含",
    "微控制器(MCU)支持"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Python API"
  ],
  [
    "TensorFlow",
    "间接包含",
    "多种级别的量化支持"
  ],
  [
    "TensorFlow",
    "间接包含",
    "特别为各种端侧设备优化的算子库"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Post training quantization"
  ],
  [
    "TensorFlow",
    "间接包含",
    "Quantization-aware training"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "TensorFlow Lite 转换器(Converter)"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "算子库(Op kernels)"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "模型文件和标签文件"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "转换和运行 TensorFlow 模型所需的工具"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "TensorFlow Lite 解释器(Interpreter)、TensorFlow Lite 转换器(Converter)、算子库(Op kernels)、硬件加速代理(Hardware accelerator delegate)"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "微控制器(MCU)支持"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "Python API"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "多种级别的量化支持"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "特别为各种端侧设备优化的算子库"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "Post training quantization"
  ],
  [
    "花卉识别 app",
    "间接包含",
    "Quantization-aware training"
  ],
  [
    "SavedModel",
    "可能与...相关",
    "TFLite模型"
  ],
  [
    "TensorFlow Lite解释器",
    "可能与...相关",
    "TensorFlow Lite解释器"
  ],
  [
    "tf.lite.TFLiteConverter.from_saved_model",
    "可能与...相关",
    "TFLite 转换器"
  ],
  [
    "TensorFlow Lite 转换器",
    "可能与...相关",
    "TensorFlow Lite 转换器"
  ],
  [
    "命令行工具",
    "可能与...相关",
    "命令行工具"
  ],
  [
    "FlatBuffers",
    "可能与...相关",
    "FlatBuffers"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "TensorFlow Lite"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "TensorFlow Lite 转换器"
  ],
  [
    "TensorFlow Lite",
    "可能与...相关",
    "MCU"
  ],
  [
    "TensorFlow 2.x 模型",
    "可能与...相关",
    "TensorFlow 2.x 模型"
  ],
  [
    "TensorFlow Lite 解释器",
    "可能与...相关",
    "TensorFlow Lite 解释器"
  ],
  [
    "GPU",
    "可能与...相关",
    "GPU"
  ],
  [
    "GPU 委托",
    "可能与...相关",
    "GPU 委托"
  ],
  [
    "量化",
    "可能与...相关",
    "量化"
  ],
  [
    "MobileNet V2",
    "可能与...相关",
    "MobileNet V2"
  ],
  [
    "train_generator",
    "可能与...相关",
    "val_generator"
  ],
  [
    "迁移学习",
    "可能与...相关",
    "迁移学习"
  ],
  [
    "瓶颈层",
    "可能与...相关",
    "瓶颈层"
  ],
  [
    "GlobalAveragePooling2D",
    "可能与...相关",
    "GlobalAveragePooling2D"
  ]
]